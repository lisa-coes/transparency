# Introduction

## Format

_Tipo documento:_ manual - revisión de literatura

_Formato de escritura:_ tipo manual, escritura formal pero con un tono experiencial y dirigida a un sujeto: "imegienese que ud....".

_Audiencia:_ académicos de las ciencias sociales que no necesariamente estén familiarizados con la ciencia abierta ni con R.

La introducción tiene los siguientes objetivos:

 - Que el lector logre asociar la transparencia y la reproducibilidad como componentes centrales del quehacer cientifico.
 - Hacer sentir al lector la necesidad de instruirse e n los tópicos relacionados a la ciencia abierta, especificamente en transparencia y reproducibilidad
 - Demarcar qué es lo que se hará y lo que no en el documento.

## Sections

### Paragraphs

**[_P1:_ Primer parrafo de enganche]**

**[_P2:_ ¿Qué es la ciencia? -> enfatizar la idea de necesidad de transparencia para un conocimiento cientifico de calidad]**

- Lo que separa el conocimiento cientifico del sentido común es la existencia de un método sistematico de observación, del cuál se desprenden afirmaciones sobre la realidad objetivamente verificables. El conocimiento cientifico no se trata solamente de la comprobación misma de estas afirmaciones, sino del ser capaz de mostrar el proceso, "la cocina", que llevó al conocimeinto construido.

- Principios de la ciencia: universalismo, comunalidad, desinterés, escepticismo organizado.

- De estos cuatro principios destacamos el escepticismo organizado: la ciencia no se basa en la _confianza_, sino en la credibilidad. Todo conocimiento cientifico tiene el potencial de ser puesto en tela de discusión. Por eso es que, para que pueda ser discutido, es fundamental que el conocimiento cientifico sea lo más transparente posible.

**[_P3:_ ¿Qué sucede cuándo no hay transparencia? -> crisis de reproducibilidad]**

- Básicamente, que un artículo cientifico no pueda ser reproducible implica que no puede ser sometido a discusión, y por lo tanto pierde credibilidad.

- Existen varios factores que contribuyen a la ciencia irreproducible (ver gráficos de Baker 2016 y QRP's de O Boyle 2017). Un factor muy importante es la cultura del "publica o perece" y el formato actual en el que se estructuran las revistas cientificas. Esto ha llevado, por ejemplo, a situciones de falseamiento de datos.

- Hasta ahora, las practicas reproducibles han sido consideradas como "buenas prácticas" por la agencia de financiación chilena, sin embargo, a partir de este año será un requesito para la postulación a proyectos.

**[_P4:_ ¿Cómo promover la transparencia?]**

- En este docuemnto no solo nos quedaremos en el diagnostico del problema, sino que también recopilaremos las principales recomendaciones de la literatura para promover la transparencia en las ciencias sociales. Enfatizaremos en las _TOP guidelines_ del _Center of open science_ logran sintetizar varios de estos elementos, siendo los siguientes:

1. Citación
2. Transparencia de datos
3. Transparencia de métodos análiticos (código)
4. Transparencia de los materiales
5. Transparencia del diseño y el análisis
6. Preregistro de estudios
7. Pre registro de planes de análisis
8. Replicación

**[_P5:_ ¿Cuál es la contribución de este documento?]**

- Primero, este documento hará una revisión de literatura relacionada a la transparencia. Se presentarán las razones y los beneficios por los cuales es conveniente adoptar la transparencia en la investigación en ciencias sociales.

- Segundo, se enfatizará la idea de reproducibilidad. Para esto, se discutirán dos elementos relacionados directamente a la reproducibilidad: análisis reproducible y preregistros. Se mostrarán distintos ejemplos para adoptar el análisis reproducible y distintos formatos de preregistro.

# Transparency

La sección de transparencia tiene los siguientes objetivos:

- Entregar una definición precisa de lo qué es lo que se entiende por transparencia
- Describir los principales argumentos por los cuales es conveniente adoptar los principios de transparencia
- Describir las dimensiones en las que se puede ser transparente
- Describir las formas en las que

## ¿Qué es la transparencia?
**[_P1:_ Definción de transparencia]**

- La transparencia incluye un conjunto de prácticas dentro del quehacer cientifico que permiten hacer la ciencia más reproducible, replicable y robusta.
- To conclude, open data is a prerequisite for verifiable research [@stodden_Trust_2011].

- Según @breznau_Does_2021:

> "La transparencia en la ciencia abierta es una forma de que todos los investigadores revelen el proceso, las ideas y materiales en los que se basa un argumento o teoría, y para apoyar una comunidad científica más ética, incluso si esto solo es posible antes de la realización de un estudio

- Se requiere transparencia para evaluar y reproducir los hallazgos, y también para la síntesis de la investigación y el metanálisis a partir de los datos brutos. [@aczel_consensusbased_2020]
-
## ¿Transparencia de qué?

**[_P3:_ Accesibilidad en los datos]**
**[_P3:_ Análisis reproducibles]**
**[_P3:_ Pregistros]**
**[_P3:_ ]**

- Cuando hablamos de transparencia en la ciencia podriamos aludir a varias dimensiones, por ejemplo:

Según @cruwellEasyStepsOpen2018
1. Ciencia abierta
2. Acceso abierto
3. Datos, materiales y código abierto
4. Análisis reproducible
5. Preregistro
6. Replicación
7. Enseñar ciencia abierta

Estandares según @:

1. Citación
2. Transparencia de datos
3. Transparencia de métodos análiticos (código)
4. Transparencia de los materiales
5. Transparencia del diseño y el análisis
6. Preregistro de estudios
7. Pre registro de planes de análisis
8. Replicación



## Actualmente ¿se adoptan estos principios de transparencia en las ciencias sociales?

**[_P3:_ Descripción prácticas poco transparentes -> QRP]**

- No no se adoptan, de hecho se ha diagnosticado una crisis de reproducibilidad en las ciencias sociales

- Según la opinión de @fanelli_Opinion_2018, la narrativa de una crisis en la ciencia no se sustenta empiricamente:

Se dice que la ciencia está en crisis debido a hallazgos poco confiables, baja calidad e integridad de la investigación, bajo poder estadístico y prácticas de publicación cuestionables causadas por la presión para publicar.

Fanelli cuestiona esta narrativa de “ciencia en crisis” al examinar críticamente la evidencia de la existencia de estos problemas.
Existen prácticas de investigación fraudulentas y cuestionables, pero es probable que no sean lo suficientemente comunes como para distorsionar seriamente la literatura científica.

La presión para publicar no se ha relacionado de manera concluyente con el sesgo científico o la mala conducta.

El bajo poder y la replicabilidad pueden diferir entre subcampos y metodologías, y pueden estar influenciados por la magnitud del tamaño del efecto real y la probabilidad previa de que la hipótesis sea cierta.

Hay poca evidencia que sugiera que la mala conducta o las prácticas de investigación cuestionables hayan aumentado en los últimos años.
La narrativa de “ciencia en crisis” no está bien respaldada por la evidencia y puede ser contraproducente, ya que fomenta valores que pueden usarse para desacreditar a la ciencia. Una narrativa de "nuevas oportunidades" o "revolución" puede ser más empoderadora para los científicos.

- Otros autores estan de acuerdo con la promoción de la transparencia, pero llaman a tener cuidado con sus consecuenicas. @lewandowsky_Research_2016 señala que:

> El progreso de la investigación exige transoarencia. Pero a medida que los científicos trabajan para aumentar el rigor, corren el riesgo de hacer que la ciencia sea más vulnerable a los ataques. La conciencia de las tácticas es supremo. Aquí, describimos formas de distinguir el escrutinio del acoso.

- De todos modos, existen una serie de autores que argumentan a favor de una crisis de reproducibilidad.

- El sesgo de publicación, los tamaños de muestra pequeños y la piratería p exageran los tamaños del efecto en la literatura, lo que contribuye a la crisis de replicación [@lindsay_Seven_2020]

- ¿Qué factores promueven eso? Son variados, van desde las prácticas de investigadores, hasta la cultura que actualmente impera en el mundo académico del publica o perece.

- Según @oboyle_Chrysalis_2017:
  * QRP
1. Eliminación o adición de datos después de pruebas de hipótesis.
2. Alterando los datos después de la prueba de hipótesis.
3. Supresión selectiva o adición de variables.
4. Invertir la dirección o reformular hipótesis para respaldar los datos
5. Eliminación o adición post hoc de hipótesis.

  *Motivos para caer en QRP

1. Anticipación a las reacciones de los revisores o al cumplimiento de las solicitudes de los revisores.
2. Listas de revistas y heurística de publicaciones.

  *Oportunidades para QRP
1. Prácticas de información y privacidad de datos.
2. Falta de replicación.

- Según @naturehumanbehaviour_Tell_2020:

Priorizar narrativas de investigación conclusivas por sobre las transparentes alberga una serie de practicas cuestionables (cita textual traducida):

1. Hipotetizar después de que se conocen los resultados
2. Reportar selectivamente aquellos resultados que confirman las predicciones iniciales
3. Excluir del reporte deinvestigación los estudios que den "messy results"

La cultura de la investigación actual se define por la presión de presentar los proyectos de investigación como narrativas concluyentes que no dejan lugar a la ambigüedad.

La presión para producir narrativas limpias representa una amenaza para la validez y contrarrestar la realidad de cómo se ve la ciencia.
Las narrativas limpias a menudo informan solo los resultados para confirmar las predicciones originales o excluir los hallazgos de la investigación que brindan resultados confusos.
Estas prácticas de investigación cuestionables crean una imagen distorsionada de la investigación que evita la acumulación de conocimientos

- Según @bishop_Rein_2019

1. El sesgo de publicación, el bajo poder estadístico, el p-hacking y HARKing (formular hipótesis después de que se conocen los resultados) son amenazas a la reproducibilidad de la investigación que dificultan la búsqueda de resultados significativos.
2. El sesgo de publicación perjudica a los pacientes.
3. La tendencia a no publicar resultados negativos confunde a los lectores y sesga los metanálisis.
4. El bajo poder estadístico también confunde a los lectores: cuando el tamaño de la muestra es pequeño, existe una baja probabilidad de que se detecte un efecto incluso si existe.
5. Se desperdician tiempo y recursos en estos estudios de escasa potencia.
6. EL p hacking ocurre cuando los investigadores realizan muchos análisis, pero solo informan los que son significativos.
7. HARKing está tan extendido que los investigadores pueden llegar a aceptarlo como una buena práctica. Los autores deben tener la libertad de realizar análisis exploratorios, pero no cuando los valores p se utilizan fuera del contexto que se utilizó para calcularlos.
8. Estos cuatro problemas son más antiguos que la mayoría de los investigadores jóvenes que trabajan en ellos. Los nuevos desarrollos pueden ayudar a combatir estos problemas:

- Según @chambers_Registered_2014:

El bajo poder, la alta tasa de selección, las hipótesis post-hoc, la falta de intercambio de datos, la cultura de la revista marcada por el sesgo de publicación y pocos estudios de replicación han contribuido a la crisis de reproducibilidad.

- Según @chambers_Registered_2013:

1. Los editores valoran los hallazgos novedosos y llamativos sobre los hallazgos genuinos, aumentando así las prácticas de investigación cuestionables.
2. Las decisiones editoriales son una causa de prácticas de investigación cuestionables, ya que toman decisiones basadas en resultados.

- Según @flier_Faculty_2017

La formación inadecuada, el aumento de la competencia, los problemas en la revisión y publicación por pares y, en ocasiones, la mala conducta científica son algunas de las variables detrás de la investigación irreproducible en el campo biomédico.

Las diversas causas dificultan la búsqueda de soluciones para el problema de la irreproducibilidad, especialmente, ya que deben ser implementadas por grupos independientes, incluidos patrocinadores y editores.

- Según @vankov_Article_2014:

Las encuestas de la literatura han demostrado consistentemente que los estudios psicológicos tienen un bajo poder estadístico y este problema ha experimentado poca o ninguna mejora en las últimas décadas. Vankov y col. examine dos argumentos de por qué este puede ser el caso.

La primera razón posible es que los investigadores pueden no apreciar la importancia del poder estadístico, ya que la prueba de significación de hipótesis nulas es un híbrido de dos teorías estadísticas: Fisher y Neyman y Pearson. Si bien los investigadores se adhieren fácilmente a la tasa de error de tipo I del 5%, prestan poca atención a la tasa de error de tipo II. Ambos deben tenerse en cuenta al evaluar si un resultado es verdadero.

Una segunda razón posible es que los científicos son humanos y responden a incentivos, como el prestigio de publicar un estudio transformador en una revista de gran prestigio. Sin embargo, producir tales obras es una estrategia de alto riesgo; Una opción más segura puede ser “cortar en rodajas de salami” las obras en varias publicaciones para aumentar las posibilidades de producir resultados publicables.

Para examinar el mérito de la primera razón, Vankov et al. se puso en contacto con los autores de los artículos publicados y les preguntó cuál era la justificación del tamaño de la muestra. Se encontró que un tercio de los autores contactados tenían creencias que normalmente actuarían para reducir el poder estadístico

- Según @aczel_consensusbased_2020:

Hay una falta de transparencia en la literatura, pero no debemos asumir la intención de ser engañoso o engañoso. Más bien, el razonamiento humano es propenso a sesgos (por ejemplo, sesgo de confirmación y razonamiento motivado) y pocas revistas preguntan sobre las prácticas estadísticas y metodológicas y la transparencia.

- Según @nosek_Promoting_2015:

> La transparencia, la apertura y la reproducibilidad se reconocen fácilmente como características vitales de la ciencia (1, 2). Cuando se les pregunta, la mayoría de los científicos adoptan estas características como normas y valores disciplinarios (3). Por lo tanto, uno podría esperar que estas valiosas características sean rutinarias en la práctica diaria. Sin embargo, un creciente cuerpo de evidencia sugiere que este no es el caso (4-6)

- Según @miguel_Promoting_2014:

> Existe una sensación cada vez mayor de que los incentivos, las normas y las instituciones bajo las cuales operan las ciencias sociales socavan los beneficios de un mejor diseño de la investigación. Los comentaristas señalan una estructura de recompensa disfuncional en la que los resultados estadísticamente significativos, novedosos y teóricamente ordenados se publican con más facilidad que los resultados nulos, repetidos o desconcertantes (3, 4).

> Los investigadores pueden seleccionar un subconjunto de resultados positivos de un estudio más amplio que, en general, muestre resultados mixtos o nulos (5) o presentar resultados exploratorios como si fueran pruebas de planes de análisis preespecificados (6)



## ¿Qué podemos hacer para promover la transparencia?

**[_P4:_ Recomendaciones de artículos e iniciativas]**

- En la literatura se hallan una serie de recomendaciones para promover la transparencia. En esta sección, dividiremos estas recomendaciones en las siguientes dimensiones: accesibilidad de datos, análsiis reproducible, preregistros, replicación, enseñar ciencia abierta y otras.

- Según @miguel_Promoting_2014:

Disclosure
Preregistros
Open data and materials

- Sugerencias para evitar caer en QRP [@oboyle_Chrysalis_2017:]
1. Clausula de ética de no haber participado en QRP al enviar manoescritos
2. Todo articulo original (p.ej tesis doctoral) debe estar disponible para descarga
3. Que las revistas cuenten con espacio dedicado a replicación.

- Según @lindsay_Seven_2020 podemos mejorar la transparencia y replicabilidad en la ciencia de la siguiente forma:

1. Diga la verdad. Sea honesto y defienda la investigación; si la idea se inspiró en datos, indíquelo. Informe el tamaño del efecto con intervalos de confianza del 95% a su alrededor.
2. Evalúe su comprensión de las herramientas estadísticas inferenciales. Necesitamos una mayor sofisticación estadística para que los investigadores prueben hipótesis sobre las poblaciones en función de sus muestras: recompensar la calidad y precisión de los métodos, no la cantidad y la ostentación de los resultados.
3. Considere la posibilidad de estandarizar aspectos de su enfoque para realizar una investigación de prueba de hipótesis. Cree un plan de investigación detallado que proporcione hipótesis a priori, planificación del tamaño de la muestra, reglas de exclusión de datos, análisis, transformaciones, covariables, etc. Sea transparente y registre un plan de investigación (cf. Prerregistro e Informes registrados).
4. Considere desarrollar un manual de laboratorio. Incluya procedimientos estandarizados en exclusión de datos, transformaciones de datos, limpieza de datos, autoría, convenciones de nomenclatura de archivos, etc.
5. Haga que sus materiales, datos y scripts de análisis sean transparentes. Deben ser localizables, accesibles, interoperables y reutilizables (FAIR).
6. Aborde las limitaciones sobre la generalidad de sus hallazgos. ¿En qué condiciones deberían sus resultados replicarse y no replicarse? La falta de replicación podría deberse a diferencias en los procedimientos, aunque el trabajo original no indicó que tales diferencias modularan el efecto.
7. Considere enfoques colaborativos para realizar investigaciones.

- Según @flier_Faculty_2017:

Las instituciones académicas pueden y deben mejorar para hacer que la ciencia sea más confiable. Una de las medidas más efectivas (pero menos discutidas) es cambiar la forma en que nombramos y promovemos a los miembros de nuestra facultad.

Los criterios de promoción han cambiado con el tiempo. Los comités ahora consideran qué tan bien participa un candidato en la ciencia de equipo, pero aún dependemos de métricas imperfectas para juzgar las publicaciones de investigación y nuestra capacidad para evaluar la confiabilidad y la precisión está poco desarrollada.

La reproducibilidad y la solidez se subestiman cuando se evalúa a los solicitantes de empleo y cuando se promueve a los miembros de la facultad.

- Aporte de @aczel_consensusbased_2020:

Las revistas pueden respaldar las prácticas abiertas ofreciendo insignias, utilizando las pautas de promoción de la transparencia y la apertura, promoviendo la disponibilidad de todos los elementos de investigación, incluidos los datos, materiales y códigos.

La lista de verificación de transparencia basada en consenso se puede enviar con el manuscrito para proporcionar información crítica sobre el proceso para evaluar la solidez de un hallazgo.

La lista de verificación se puede modificar eliminando, agregando y reformulando elementos con un alto nivel de aceptabilidad y consenso sin un fuerte argumento en contra para elementos individuales.

Los investigadores pueden explicar las opciones al final de cada sección. Hay una versión abreviada de 12 elementos para reducir las demandas de tiempo de los investigadores y facilitar una adopción más amplia que fomenta la transparencia y pide a los autores que completen una lista de 36 elementos.

**[_PX:_ Pregistros]**

- @szollosi_Preregistration_2020 se plantea en contra de los preregistros:

Los defensores del prerregistro argumentan que, entre otros beneficios, mejora el diagnóstico de las pruebas estadísticas. En la versión fuerte de este argumento, el prerregistro hace esto resolviendo problemas estadísticos, como las tasas de error familiar. En la versión débil, empuja a las personas a pensar más profundamente sobre sus teorías, métodos y análisis. Argumentamos en contra de ambos: el diagnóstico de las pruebas estadísticas depende completamente de qué tan bien los modelos estadísticos se mapean en las teorías subyacentes, por lo que mejorar las técnicas estadísticas hace poco por mejorar las teorías cuando el mapeo es débil. También hay pocas razones para esperar que el registro previo ayude espontáneamente a los investigadores a desarrollar mejores teorías (y, por lo tanto, mejores métodos y análisis).

- Según @chambers_Registered_2015:

1. Los preregistros permiten que las revisiones por pares se centren en la calidad y el rigor del diseño experimental en lugar de en resultados innovadores. Esto debería reducir las prácticas de investigación cuestionables, como los informes selectivos, las hipótesis post-hoc y el bajo poder estadístico.
2. Los preregistros no son una cura de una sola vez para los problemas de reproducibilidad en la ciencia y no representan una amenaza para los análisis exploratorios.

- Según @chambers_Registered_2014:
1. Los preregistros fomentan la claridad y la reproducción antes de que se lleve a cabo el experimento.
2. Los preregistros nos permiten publicar hallazgos positivos, negativos o nulos, produciendo así una imagen real de la literatura.
3. Los preregistros permiten la creatividad, la flexibilidad y la notificación de hallazgos inesperados

- Según @nosek_Registered_2014:

1. Los preregistros permiten análisis exploratorios y confirmatorios, pero se requiere una distinción. Sin embargo, se puede depositar más confianza en los análisis confirmatorios, ya que sigue un plan y asegura la interpretabilidad del valor p informado.
2. La replicación directa agrega datos que aumentan la precisión de las estimaciones del tamaño del efecto para la investigación metaanalítica. Sin replicación directa, significa que es difícil identificar falsos positivos.
3. Las réplicas conceptuales son más populares que las réplicas directas, ya que la primera conceptualiza un fenómeno a partir de su operacionalización original, contribuyendo así a nuestra comprensión teórica del efecto.
4. La replicación directa fomenta la generalización de los efectos, proporcionando evidencia de que el efecto no se debió a un error de muestreo, de procedimiento o contextual.

- Según @miguel_Promoting_2014:

> La objeción más común al movimiento hacia una mayor transparencia en la investigación se refiere al registro previo. Preocupados porque el prerregistro implica un rechazo de la investigación exploratoria, a algunos les preocupa que reprima la creatividad y los descubrimientos fortuitos. No estamos de acuerdo. El propósito de la preespecificación no es menospreciar el análisis exploratorio, sino liberarlo de la tradición de ser presentado como hipótesis formal.


**[_PX:_ Análisis reproducibles]**

- Según @peng_reproducibility_2015:

Hacer que la investigación sea reproducible
Hay dos componentes principales para un estudio reproducible:
1) que los datos brutos del experimento estén disponibles;
2) y que también se dispone del código estadístico y la documentación para reproducir el análisis.


**[_PX:_ Replicación]**
**[_PX:_ Enseñar ciencia abierta]**

## ¿Por qué adoptar los principios de transparencia?

**[_P5:_ Argumentos para transparencia]**

Beneficios según @rodriguez-sanchez_Ciencia_2016:

1. La utilización de código permite la automatización: ejecución de tareas repetitivas sin esfuerzo
2. Muy fácil corregir y regenerar resultados, tablas y figuras
3. Reducción drástica del riesgo de errores
4. Los flujos de trabajo reproducibles facilitan la colaboración
5. Mayor facilidad para escribir artículos al tener registro exhaustivo de todo el proceso de análisis
6. La publicación del código ayuda a detectar errores antes de la publicación definitiva
7. La publicación del código facilita el proceso de revisión
8. La publicación del código facilita la comprensión del artículo y evita malinterpretaciones
9. La reproducibilidad es un sello de calidad y aumenta la probabilidad de aceptación (cuando no es simplemente requerida)
10. La reproducibilidad aumenta el impacto de las publicaciones (citas, reconocimiento, reutilización, coautorías)
11. Ahorro de tiempo y esfuerzo al reutilizar código en otros proyectos

# Reproducibility

## ¿Qué es y por qué es importante?

## Criterios de reproducibilidad
