<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 ¿Por qué? | Transparencia en Investigación Social</title>
  <meta name="description" content="Documento de trabajo del equipo Transparencia para el Laboratorio de Ciencia Social Abierta" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 ¿Por qué? | Transparencia en Investigación Social" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/lisa-coes/transparency" />
  <meta property="og:image" content="https://github.com/lisa-coes/transparency/images/lisa-complete.png" />
  <meta property="og:description" content="Documento de trabajo del equipo Transparencia para el Laboratorio de Ciencia Social Abierta" />
  <meta name="github-repo" content="lisa-coes/transparency" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 ¿Por qué? | Transparencia en Investigación Social" />
  
  <meta name="twitter:description" content="Documento de trabajo del equipo Transparencia para el Laboratorio de Ciencia Social Abierta" />
  <meta name="twitter:image" content="https://github.com/lisa-coes/transparency/images/lisa-complete.png" />

<meta name="author" content="Investigador a cargo: Juan Carlos Castillo   Asistente de investigación: Julio Iturra   Pasante: Martín Venegas Márquez" />


<meta name="date" content="2021-09-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="images/lisa.ico" type="image/x-icon" />
<link rel="prev" href="sobre-la-transparencia.html"/>
<link rel="next" href="qué-y-quién.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="assets/lisa.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="images/favicon.jpg"></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Punto de partida: la transparencia en el proceso de investigación</a></li>
<li class="chapter" data-level="1" data-path="sobre-la-transparencia.html"><a href="sobre-la-transparencia.html"><i class="fa fa-check"></i><b>1</b> Sobre la transparencia</a>
<ul>
<li class="chapter" data-level="1.1" data-path="por-qué.html"><a href="por-qué.html"><i class="fa fa-check"></i><b>1.1</b> ¿Por qué?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="por-qué.html"><a href="por-qué.html#prácticas-cuestionables-de-investigación-qrp"><i class="fa fa-check"></i><b>1.1.1</b> Prácticas cuestionables de investigación (QRP)</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="qué-y-quién.html"><a href="qué-y-quién.html"><i class="fa fa-check"></i><b>1.2</b> ¿Qué? y ¿Quién?</a></li>
<li class="chapter" data-level="1.3" data-path="cómo.html"><a href="cómo.html"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="cómo.html"><a href="cómo.html#preregistros"><i class="fa fa-check"></i><b>1.3.1</b> Preregistros</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="herramientas-para-los-diseños-transparentes.html"><a href="herramientas-para-los-diseños-transparentes.html"><i class="fa fa-check"></i><b>2</b> Herramientas para los diseños transparentes</a>
<ul>
<li class="chapter" data-level="2.1" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html"><i class="fa fa-check"></i><b>2.1</b> Plantillas de preregistro</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html#plantillas-genéricas"><i class="fa fa-check"></i><b>2.1.1</b> Plantillas Genéricas</a></li>
<li class="chapter" data-level="2.1.2" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html#plantillas-para-diseños-experimentales-y-previas-a-recolección-de-datos"><i class="fa fa-check"></i><b>2.1.2</b> Plantillas para diseños experimentales y previas a recolección de datos</a></li>
<li class="chapter" data-level="2.1.3" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html#plantillas-para-datos-secundarios"><i class="fa fa-check"></i><b>2.1.3</b> Plantillas para datos secundarios</a></li>
<li class="chapter" data-level="2.1.4" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html#plantillas-para-estudios-de-replicación"><i class="fa fa-check"></i><b>2.1.4</b> Plantillas para estudios de replicación</a></li>
<li class="chapter" data-level="2.1.5" data-path="plantillas-de-preregistro.html"><a href="plantillas-de-preregistro.html#plantillas-para-registered-reports"><i class="fa fa-check"></i><b>2.1.5</b> Plantillas para <em>registered reports</em></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="otras-herramientas.html"><a href="otras-herramientas.html"><i class="fa fa-check"></i><b>2.2</b> Otras herramientas</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="otras-herramientas.html"><a href="otras-herramientas.html#registered-reports"><i class="fa fa-check"></i><b>2.2.1</b> Registered Reports</a></li>
<li class="chapter" data-level="2.2.2" data-path="otras-herramientas.html"><a href="otras-herramientas.html#transparency-checklist"><i class="fa fa-check"></i><b>2.2.2</b> Transparency Checklist</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i><b>3</b> Referencias</a></li>
<li class="chapter" data-level="4" data-path="anexos.html"><a href="anexos.html"><i class="fa fa-check"></i><b>4</b> Anexos</a></li>
<li class="divider"></li>
<li><a href="https://github.com/lisa-coes" target="blank">LISA-COES <i class="fa fa-github"></i></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Transparencia en Investigación Social</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <!--script src="https://kit.fontawesome.com/6a26f47516.js"></script-->
  <script src="assets/hideOutput.js"></script>
  <link href="assets/lisa.css" rel="stylesheet">
</head>
        


<div class="hero-image-container"> 
  <img class= "hero-image" src="images/lisa-complete.png">
</div>
<div id="por-qué" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> ¿Por qué?</h2>
<div style="text-align: justify">

<p>La pregunta del <strong>por qué</strong> es necesario avanzar hacia la transparencia encuentra su respuesta en la existencia de prácticas de investigación que merman la credibilidad de los hallazgos científicos. A modo de entender qué es lo problemático de ciertas prácticas, es que <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span> proponen el concepto de <em>Conducta Responsable de Investigación (RCR, por sus siglas en inglés)</em> cómo un ideal que engloba prácticas éticas e integras dentro de la investigación científica (ver Figura N° <a href="por-qué.html#fig:rcr">1.2</a>). Según los autores, la distinción entre la ética y la integridad recae en que la primera tiene que ver con seguir principios morales dentro de la investigación (e.g. usar consentimientos informados), en cambio, la segunda está más relacionada el seguimiento de códigos de conductas y estándares profesionales <span class="citation">(<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz 2019</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:rcr"></span>
<img src="input/images/rcr.png" alt="Conducta Responsable de Investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006" width="100%" />
<p class="caption">
Figura 1.2: Conducta Responsable de Investigación. Imagen de <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> basada en <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span>
</p>
</div>
<div style="text-align: justify">

<p>Las prácticas de investigación se pueden evaluar en un continuo que representa cuánto adhieren los investigadores a los principios de integridad científica <span class="citation">(<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006</a>)</span>. La Figura N° <a href="por-qué.html#fig:grad">1.3</a> esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derecha el peor comportamiento (FFP). Las FPP son una abreviación en lengua inglesa para referirse a <em>Fabrication, Falsification, Plagiarism</em> (Invención, Falsificación y Plagio), también conocidas como <em>mala conducta académica</em>. En el medio del continuo están las <em>prácticas cuestionables de investigación</em> (QRP, por sus siglas en inglés) las cuáles refieren a “acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación” <span class="citation">(<em>National Academies of Science</em> 1992 en <a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006, 58</a>)</span>. Las QRP se caracterizan porque tienen el potencial de dañar la ciencia, en tanto las FFP la dañan directamente.</p>
<div class="figure" style="text-align: center"><span id="fig:grad"></span>
<img src="input/images/grad.png" alt="Gradación del comportamiento integro en investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006" width="100%" />
<p class="caption">
Figura 1.3: Gradación del comportamiento integro en investigación. Imagen de <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> basada en <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span>
</p>
</div>
<div style="text-align: justify">

<p>La mala conducta académica implica la violación de los principios de integridad científica. Esto implica el falseamiento de datos de cualquier forma: invención de datos, alteración de gráficos o tablas, etc. El caso de Diderik Stapel presentado en la introducción de este capítulo es un ejemplo que cabe dentro del concepto de mala conducta académica. Según la literatura, la prevalencia de este tipo de prácticas no es alta <span class="citation">(e.g. <a href="#ref-fanelli_How_2009" role="doc-biblioref">Fanelli 2009</a>; <a href="#ref-john_Measuring_2012" role="doc-biblioref">John, Loewenstein, y Prelec 2012</a>)</span>, sino que más bien son casos aislados <span class="citation">(ver <a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz 2019, 23-128</a> para una revisión)</span>. En contraste, como veremos a continuación, las QRP han demostrado ser más prevalentes.</p>
<div id="prácticas-cuestionables-de-investigación-qrp" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Prácticas cuestionables de investigación (QRP)</h3>
<div style="text-align: justify">

<p>Existen una serie de estudios que han intentado medir directamente la prevalencia de estas prácticas a través de encuestas. <span class="citation"><a href="#ref-fanelli_How_2009" role="doc-biblioref">Fanelli</a> (<a href="#ref-fanelli_How_2009" role="doc-biblioref">2009</a>)</span> hizo un metaanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez (FFP) y que un 33.7% había realizado alguna vez una QRP como “borrar puntos de los datos basados en un sentimiento visceral”. Unos años más tarde, <span class="citation"><a href="#ref-john_Measuring_2012" role="doc-biblioref">John, Loewenstein, y Prelec</a> (<a href="#ref-john_Measuring_2012" role="doc-biblioref">2012</a>)</span> efectuaron otro estudio similar, demostrando que un 36.6% de quienes participaron alguna vez habían practicado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicólogos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipótesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Este estudio ha sido replicado en Italia <span class="citation">(<a href="#ref-agnoli_Questionable_2017" role="doc-biblioref">Agnoli et al. 2017</a>)</span>, en Alemania <span class="citation">(<a href="#ref-fiedler_Questionable_2016" role="doc-biblioref">Fiedler y Schwarz 2016</a>)</span> y en Brasil <span class="citation">(<a href="#ref-rabelo_Questionable_2020" role="doc-biblioref">Rabelo et al. 2020</a>)</span>, con resultados similares.</p>
<div style="text-align: justify">

<p>Más recientemente, han emergido estudios similares en otras áreas disciplinarias. Por ejemplo, a través de encuestas online <span class="citation"><a href="#ref-makel_Both_2021" role="doc-biblioref">Makel et al.</a> (<a href="#ref-makel_Both_2021" role="doc-biblioref">2021</a>)</span> logran constatar que existe una prevalencia considerable de las QRP en el campo de investigación educacional. De los participantes de la muestra un 10% admitió haber rellenado datos faltantes (NA’s) y un 67% señaló alguna vez haber omitido ciertos análisis de manera intencional. Siguiendo el mismo método, en el campo de la investigación comunicacional se ha encontrado evidencia parecida: 9% de los encuestados señala haber imputado datos faltantes sin reportarlo, un 34% declaró alguna vez haber excluido casos extremos de forma arbitraria y un 60% señala no haber reportado análisis con variables clave que no funcionaron <span class="citation">(<a href="#ref-bakker_Questionable_2020" role="doc-biblioref">Bakker et al. 2020</a>)</span>. Del mismo modo, en los estudios cuantitativos sobre criminología existe un uso extendido de las QRP: un 87% de la muestra de <span class="citation"><a href="#ref-chin_Questionable_2021" role="doc-biblioref">Chin et al.</a> (<a href="#ref-chin_Questionable_2021" role="doc-biblioref">2021</a>)</span> ha utilizado múltiples QRP, siendo el reporte selectivo de resultados el más común (53%). Por último, fuera del área de las ciencias sociales, pero siguiendo la misma línea, <span class="citation"><a href="#ref-fraser_Questionable_2018" role="doc-biblioref">Fraser et al.</a> (<a href="#ref-fraser_Questionable_2018" role="doc-biblioref">2018</a>)</span> también hallan evidencia a favor de la existencia de distintas QRP en el campo de la ecología y evolución.</p>
<div style="text-align: justify">

<p>Los estudios mencionados arriba corresponden a la evidencia existente sobre la medición de QRP a través de encuestas. A modo de resumen, la Tabla N° <a href="por-qué.html#tab:tabqrp2">1.1</a> adaptada del trabajo de <span class="citation"><a href="#ref-chin_Questionable_2021" role="doc-biblioref">Chin et al.</a> (<a href="#ref-chin_Questionable_2021" role="doc-biblioref">2021</a>)</span> agrupa la información que hemos revisado (y más), ordenándose por prácticas, campos de estudio y los artículos correspondientes a cada campo de estudio. Los números dentro de las casillas representan el porcentaje de prevalencia de cada práctica reportado por los participantes del estudio, y entre paréntesis el número de casos de la muestra. Los guiones significan que este estudio no incluyó esa práctica en el cuestionario.</p>
<table style="width:100%;">
<caption><span id="tab:tabqrp2">Tabla 1.1: </span> Porcentajes de prevelanecia por QRP según distintos trabajos.. <!-- Label+titulo de tabla en syntax Markdown pura --></caption>
<colgroup>
<col width="27%" />
<col width="9%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th>Práctica</th>
<th>Psicología</th>
<th>Psicología</th>
<th>Psicología</th>
<th>Ecología</th>
<th>Evolución</th>
<th>Educación</th>
<th>Comunicación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td><span class="citation"><a href="#ref-john_Measuring_2012" role="doc-biblioref">John, Loewenstein, y Prelec</a> (<a href="#ref-john_Measuring_2012" role="doc-biblioref">2012</a>)</span></td>
<td><span class="citation"><a href="#ref-agnoli_Questionable_2017" role="doc-biblioref">Agnoli et al.</a> (<a href="#ref-agnoli_Questionable_2017" role="doc-biblioref">2017</a>)</span></td>
<td><span class="citation"><a href="#ref-rabelo_Questionable_2020" role="doc-biblioref">Rabelo et al.</a> (<a href="#ref-rabelo_Questionable_2020" role="doc-biblioref">2020</a>)</span></td>
<td><span class="citation"><a href="#ref-fraser_Questionable_2018" role="doc-biblioref">Fraser et al.</a> (<a href="#ref-fraser_Questionable_2018" role="doc-biblioref">2018</a>)</span></td>
<td><span class="citation"><a href="#ref-fraser_Questionable_2018" role="doc-biblioref">Fraser et al.</a> (<a href="#ref-fraser_Questionable_2018" role="doc-biblioref">2018</a>)</span></td>
<td><span class="citation"><a href="#ref-makel_Both_2021" role="doc-biblioref">Makel et al.</a> (<a href="#ref-makel_Both_2021" role="doc-biblioref">2021</a>)</span></td>
<td><span class="citation"><a href="#ref-bakker_Questionable_2020" role="doc-biblioref">Bakker et al.</a> (<a href="#ref-bakker_Questionable_2020" role="doc-biblioref">2020</a>)</span></td>
</tr>
<tr class="even">
<td>Omitir estudios o variables ni significativas</td>
<td>46 (485)</td>
<td>40 (217)</td>
<td>55 (232)</td>
<td>-</td>
<td>-</td>
<td>62 (783)</td>
<td>60</td>
</tr>
<tr class="odd">
<td>Subreportar resultados</td>
<td>63 (486)</td>
<td>48 (219)</td>
<td>22 (232)</td>
<td>64</td>
<td>64</td>
<td>67 (871)</td>
<td>64</td>
</tr>
<tr class="even">
<td>Subreportar condiciones</td>
<td>28 (484)</td>
<td>16 (219)</td>
<td>35 (232)</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Muestreo selectivo</td>
<td>56 (490)</td>
<td>53 (221)</td>
<td>22 (232)</td>
<td>37</td>
<td>51</td>
<td>29 (806)</td>
<td>23</td>
</tr>
<tr class="even">
<td>Excluir datos selectivamente</td>
<td>38 (484)</td>
<td>40 (219)</td>
<td>20 (232)</td>
<td>24</td>
<td>24</td>
<td>25 (806)</td>
<td>34</td>
</tr>
<tr class="odd">
<td>Excluir covariables selectivamente</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>42 (773)</td>
<td>46</td>
</tr>
<tr class="even">
<td>Cambiar análisis selectivamente</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>50 (811)</td>
<td>45</td>
</tr>
<tr class="odd">
<td>HARK</td>
<td>27 (489)</td>
<td>37 (219)</td>
<td>9 (232)</td>
<td>49</td>
<td>54</td>
<td>46 (880)</td>
<td>46</td>
</tr>
<tr class="even">
<td>Redondear valores p</td>
<td>22 (499)</td>
<td>22 (221)</td>
<td>18 (232)</td>
<td>27</td>
<td>18</td>
<td>29 (806)</td>
<td>24</td>
</tr>
<tr class="odd">
<td>Mal orientar respecto a los efectos de sociodemográficos</td>
<td>3 (499)</td>
<td>3 (223)</td>
<td>4 (232)</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="even">
<td>Esconder problemas</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>24 (889)</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Esconder imputaciones</td>
<td>1 (495)</td>
<td>2 (220)</td>
<td>1 (232)</td>
<td>5</td>
<td>2</td>
<td>10 (898)</td>
<td>9</td>
</tr>
</tbody>
</table>
<div style="text-align: justify">

<p>Cómo se puede ver en la Tabla N° <a href="por-qué.html#tab:tabqrp2">1.1</a>, las encuestas sobre QRP han incluido varias prácticas relativas al tratamiento y análisis de los datos. No obstante, consideramos que exiten tres términos que, en su mayoría, logran sintetizar esta tabla y que están relacionados a la transparencia en los diseños de investigación. Estas son: 1) los sesgos de publicación, 2) el <em>p-hacking</em> y el 3) <em>HARKing</em>.</p>
<p><strong>Sesgo de publicación</strong></p>
<div style="text-align: justify">

<p>El <strong>sesgo de publicación</strong> ocurre cuando el criterio determinante para que un artículo sea publicado es que sus resultados sean significativos, en desmedro de la publicación de resultados no significativos. Un ejemplo ilustrativo que usan <span class="citation"><a href="#ref-christensen_Transparent_2019" role="doc-biblioref">G. S. Christensen, Freese, y Miguel</a> (<a href="#ref-christensen_Transparent_2019" role="doc-biblioref">2019</a>)</span> para explicar esta práctica es el cómic <em>xkcd</em> títulado <em>Significant</em>. En el comic (Figura N <a href="por-qué.html#fig:significant">1.4</a>) se puede observar que un personaje corre gritando que las gominolas (<em>jellybeans</em>) causan acné, a lo que el otro personaje llama a los científicos para que prueben esta hipótesis, resultando no significativa. Ante esto, nuevamente el personaje inicial plantea que podría depender del tipo de gominola, y es aquí donde se aprecia lo ilustrativo del cómic: aparecen 20 paneles, cada uno representando una prueba de hipótesis entre una gominola de determinado color y al acné. 19 de las pruebas resultan no significativas, y una (el color verde) resulta significativa. El cómic termina con una portada con el titular de la única prueba de hipótesis que arrojó resultados significativos.</p>
<div class="figure" style="text-align: center"><span id="fig:significant"></span>
<img src="http://es.xkcd.com/site_media/strips/significant.png" alt="Comic _Significant_ de xkcd" width="75%" />
<p class="caption">
Figura 1.4: Comic <em>Significant</em> de xkcd
</p>
</div>
<div style="text-align: justify">

<p>El cómic anterior muestra cómo es que un hallazgo de investigación sufre del sesgo de publicación. Al publicarse únicamente el resultado significativo e ignorándose los otros 19 no significativos, cualquier lector tendería a pensar que efectivamente las gominolas verdes causan acné, cuando probablemente sea una coincidencia. <span class="citation"><a href="#ref-rosenthal_file_1979" role="doc-biblioref">Rosenthal</a> (<a href="#ref-rosenthal_file_1979" role="doc-biblioref">1979</a>)</span> fue de los primeros trabajos en llamar la atención respecto de esta práctica, adjudicando el concepto de <em>file drawer problem</em> (en español: problema del cajón de archivos), el que hace alusión a los resultados que se pierden o quedan “archivados” dentro de un cuerpo de literatura. Desde ese estudio en adelante varios autores han contribuido con evidencia empírica sobre el sesgo de publicación. Por ejemplo, el estudio de <span class="citation"><a href="#ref-franco_Publication_2014" role="doc-biblioref">Franco, Malhotra, y Simonovits</a> (<a href="#ref-franco_Publication_2014" role="doc-biblioref">2014</a>)</span> logra cuantificar esta situación encontrando que los resultados nulos tienen un 40% menos de probabilidades de ser publicados en revistas científicas, en comparación a estudios con resultados significativos. Es más, muchas veces los resultados nulos ni siquiera llegan a ser escritos: más de un 60% de los experimentos que componen la muestra del estudio de <span class="citation"><a href="#ref-franco_Publication_2014" role="doc-biblioref">Franco, Malhotra, y Simonovits</a> (<a href="#ref-franco_Publication_2014" role="doc-biblioref">2014</a>)</span> nunca llegaron a ser escritos, en contraste al menos del 10% de resultados significativos.</p>
<div style="text-align: justify">

<p>El principal problema del sesgo de publicación es que puede impactar en la credibilidad de cuerpos enteros de literatura. Por ejemplo, en economía se han hecho varios metaanálisis que han buscado estimar el sesgo de publicación en distintos cuerpos de literatura <span class="citation">(e.g. <a href="#ref-brodeur_Star_2016" role="doc-biblioref">Brodeur et al. 2016</a>; <a href="#ref-vivalt_Heterogeneous_2015" role="doc-biblioref">Vivalt 2015</a>; <a href="#ref-viscusi_Role_2014" role="doc-biblioref">Viscusi 2014</a>)</span>. Uno de los trabajos más concluyentes es el de <span class="citation"><a href="#ref-doucouliagos_Are_2013" role="doc-biblioref">Doucouliagos y Stanley</a> (<a href="#ref-doucouliagos_Are_2013" role="doc-biblioref">2013</a>)</span>, quienes efectúan un meta análisis de 87 artículos de meta análisis en economía. En este trabajo encuentran que más de la mitad de los cuerpos de literatura revisados sufren de un sesgo “sustancial” o “severo”. Sí bien en economía se ha avanzado mucho en este tipo de estudios, también a partir del desarrollo de distintos métodos de detección, se ha podido diagnosticar el sesgo de publicación en importantes revistas en sociología y ciencias políticas <span class="citation">(<a href="#ref-gerber_Publication_2008" role="doc-biblioref">A. S. Gerber y Malhotra 2008</a>; <a href="#ref-gerber_Statistical_2008" role="doc-biblioref">A. Gerber y Malhotra 2008</a>)</span>.</p>
<p><strong>P-hacking</strong></p>
<div style="text-align: justify">

<p>Otra práctica bastante cuestionada es el <em>p-hacking</em>. El p-hacking suele englobar muchas de las prácticas que vimos en un inicio, especialmente las que refieren al manejo de datos: excluir datos arbitrariamente, redondear un valor p, recolectar más datos posterior a hacer pruebas de hipótesis etc. Lo que tienen todas estas prácticas en común y lo que define el p-hacking es que se da cuando el procesamiento de los datos tiene por objetivo obtener resultados significativos. Si el sesgo de publicación afecta la credibilidad de un cuerpo de literatura, el p-hacking afecta a la credibilidad de los artículos mismos, ya que al forzar la significancia estadística la probabilidad de que en realidad estemos frente a un falso positivo aumenta. Un trabajo que da sustento a esta idea es el de <span class="citation"><a href="#ref-simmons_FalsePositive_2011" role="doc-biblioref">Simmons, Nelson, y Simonsohn</a> (<a href="#ref-simmons_FalsePositive_2011" role="doc-biblioref">2011</a>)</span>, quienes calculan la probabilidad de obtener un falso positivo (error Tipo I) de acuerdo con el nivel de <em>grados de libertad</em> que son utilizados por parte de los investigadores. El resultado principal es que a medida que aumenta el uso de grados de libertad, la posibilidad de obtener un falso positivo aumenta progresivamente.</p>
<div style="text-align: justify">

<p>El p-hacking también contribuye a sesgar cuerpos enteros de literatura. Para diagnosticar esto se ha utilizado una herramienta denominada <em>p-curve</em>, la cual “describe la densidad de los <em>p-values</em> reportados en una literatura, aprovechando el hecho de que si la hipótesis nula no se rechaza (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1” <span class="citation">(<a href="#ref-christensen_Transparent_2019" role="doc-biblioref">G. S. Christensen, Freese, y Miguel 2019, 67</a>.)</span>. De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de valors p debería estar cargada a la izquierda (siendo precisos, asimétrica a la derecha), en cambio, si existe sesgo por p-hacking la distribución de p-values estaría cargada a la derecha (asimetría a la izquierda). <span class="citation"><a href="#ref-simonsohn_Pcurve_2014" role="doc-biblioref">Simonsohn, Nelson, y Simmons</a> (<a href="#ref-simonsohn_Pcurve_2014" role="doc-biblioref">2014</a>)</span> proponen esta herramienta y la prueban en dos muestras de artículos de la <em>Journal of Personality and Social Psychology (JPSP)</em>. Las pruebas estadísticas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipótesis, esto es: los artículos que presentaban solamente resultados con covariables resultaron tener una p-curve cargada a la derecha (asimétrica a la izquierda).</p>
<p><strong>HARKing</strong></p>
<div style="text-align: justify">

<p>Por último, pero no menos importante está la práctica del <em>HARKing</em>. El nombre es una nomenclatura en lengua inglesa para <em>Hypothesizing After the Results are Known</em>, que literalmente significa establecer las hipótesis del estudio una vez que se conocen los resultados <span class="citation">(<a href="#ref-kerr_HARKing_1998" role="doc-biblioref">Kerr 1998</a>)</span>. El principal problema de esta práctica es que confunde los dos tipos de razonamiento que están a la base de la ciencia: el exploratorio y el confirmatorio. El objetivo principal del razonamiento exploratorio es plantear hipótesis a partir del análisis de los datos, en cambio, el razonamiento confirmatorio busca plantear hipótesis basado en teoría y contrastar esas hipótesis con datos empíricos. Como señala <span class="citation"><a href="#ref-nosek_preregistration_2018" role="doc-biblioref">Nosek et al.</a> (<a href="#ref-nosek_preregistration_2018" role="doc-biblioref">2018</a>)</span>, cuando se confunden ambos tipos de análisis y se hace pasar un razonamiento exploratorio como confirmatorio se está cometiendo un sesgo inherente, ya que se está generando un razonamiento circular: se plantean hipótesis a partir del comportamiento de los datos y se confirman las hipótesis con esos mismos datos.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-abrilruiz_Manzanas_2019" class="csl-entry">
Abril Ruiz, Angel. 2019. <em><span>Manzanas podridas: Malas prácticas de investigación y ciencia descuidada</span></em>.
</div>
<div id="ref-agnoli_Questionable_2017" class="csl-entry">
Agnoli, Franca, Jelte M. Wicherts, Coosje L. S. Veldkamp, Paolo Albiero, y Roberto Cubelli. 2017. <span>«Questionable Research Practices among Italian Research Psychologists»</span>. <em>PLOS ONE</em> 12 (3): e0172792. <a href="https://doi.org/10.1371/journal.pone.0172792">https://doi.org/10.1371/journal.pone.0172792</a>.
</div>
<div id="ref-bakker_Questionable_2020" class="csl-entry">
Bakker, Bert N., Kokil Jaidka, Timothy Dörr, Neil Fasching, y Yphtach Lelkes. 2020. <span>«Questionable and Open Research Practices: Attitudes and Perceptions among Quantitative Communication Researchers»</span>. <span>PsyArXiv</span>. <a href="https://doi.org/10.31234/osf.io/7uyn5">https://doi.org/10.31234/osf.io/7uyn5</a>.
</div>
<div id="ref-brodeur_Star_2016" class="csl-entry">
Brodeur, Abel, Mathias Lé, Marc Sangnier, y Yanos Zylberberg. 2016. <span>«Star <span>Wars</span>: <span>The Empirics Strike Back</span>»</span>. <em>American Economic Journal: Applied Economics</em> 8 (1): 1-32. <a href="https://doi.org/10.1257/app.20150044">https://doi.org/10.1257/app.20150044</a>.
</div>
<div id="ref-chin_Questionable_2021" class="csl-entry">
Chin, Jason M., Justin T. Pickett, Simine Vazire, y Alex O. Holcombe. 2021. <span>«Questionable <span>Research Practices</span> and <span>Open Science</span> in <span>Quantitative Criminology</span>»</span>. <em>Journal of Quantitative Criminology</em>. <a href="https://doi.org/10.1007/s10940-021-09525-6">https://doi.org/10.1007/s10940-021-09525-6</a>.
</div>
<div id="ref-christensen_Transparent_2019" class="csl-entry">
Christensen, Garret S., Jeremy Freese, y Edward Miguel. 2019. <em>Transparent and Reproducible Social Science Research: How to Do Open Science</em>. <span>Oakland, California</span>: <span>University of California Press</span>.
</div>
<div id="ref-doucouliagos_Are_2013" class="csl-entry">
Doucouliagos, Chris, y T. D. Stanley. 2013. <span>«Are <span>All Economic Facts Greatly Exaggerated</span>? <span>Theory Competition</span> and <span>Selectivity</span>»</span>. <em>Journal of Economic Surveys</em> 27 (2): 316-39. <a href="https://doi.org/10.1111/j.1467-6419.2011.00706.x">https://doi.org/10.1111/j.1467-6419.2011.00706.x</a>.
</div>
<div id="ref-fanelli_How_2009" class="csl-entry">
Fanelli, Daniele. 2009. <span>«How <span>Many Scientists Fabricate</span> and <span>Falsify Research</span>? <span>A Systematic Review</span> and <span>Meta</span>-<span>Analysis</span> of <span>Survey Data</span>»</span>. <em>PLOS ONE</em> 4 (5): e5738. <a href="https://doi.org/10.1371/journal.pone.0005738">https://doi.org/10.1371/journal.pone.0005738</a>.
</div>
<div id="ref-fiedler_Questionable_2016" class="csl-entry">
Fiedler, Klaus, y Norbert Schwarz. 2016. <span>«Questionable <span>Research Practices Revisited</span>»</span>. <em>Social Psychological and Personality Science</em> 7 (1): 45-52. <a href="https://doi.org/10.1177/1948550615612150">https://doi.org/10.1177/1948550615612150</a>.
</div>
<div id="ref-franco_Publication_2014" class="csl-entry">
Franco, A., N. Malhotra, y G. Simonovits. 2014. <span>«Publication Bias in the Social Sciences: <span>Unlocking</span> the File Drawer»</span>. <em>Science</em> 345 (6203): 1502-5. <a href="https://doi.org/10.1126/science.1255484">https://doi.org/10.1126/science.1255484</a>.
</div>
<div id="ref-fraser_Questionable_2018" class="csl-entry">
Fraser, Hannah, Tim Parker, Shinichi Nakagawa, Ashley Barnett, y Fiona Fidler. 2018. <span>«Questionable Research Practices in Ecology and Evolution»</span>. <em>PLOS ONE</em> 13 (7): e0200303. <a href="https://doi.org/10.1371/journal.pone.0200303">https://doi.org/10.1371/journal.pone.0200303</a>.
</div>
<div id="ref-gerber_Publication_2008" class="csl-entry">
Gerber, Alan S., y Neil Malhotra. 2008. <span>«Publication <span>Bias</span> in <span>Empirical Sociological Research</span>: <span>Do Arbitrary Significance Levels Distort Published Results</span>?»</span>. <em>Sociological Methods &amp; Research</em> 37 (1): 3-30. <a href="https://doi.org/10.1177/0049124108318973">https://doi.org/10.1177/0049124108318973</a>.
</div>
<div id="ref-gerber_Statistical_2008" class="csl-entry">
Gerber, Alan, y Neil Malhotra. 2008. <span>«Do <span>Statistical Reporting Standards Affect What Is Published</span>? <span>Publication Bias</span> in <span>Two Leading Political Science Journals</span>»</span>. <em>Quarterly Journal of Political Science</em> 3 (3): 313-26. <a href="https://doi.org/10.1561/100.00008024">https://doi.org/10.1561/100.00008024</a>.
</div>
<div id="ref-john_Measuring_2012" class="csl-entry">
John, Leslie K., George Loewenstein, y Drazen Prelec. 2012. <span>«Measuring the <span>Prevalence</span> of <span>Questionable Research Practices With Incentives</span> for <span>Truth Telling</span>»</span>. <em>Psychological Science</em> 23 (5): 524-32. <a href="https://doi.org/10.1177/0956797611430953">https://doi.org/10.1177/0956797611430953</a>.
</div>
<div id="ref-kerr_HARKing_1998" class="csl-entry">
Kerr, Norbert L. 1998. <span>«<span>HARKing</span>: <span>Hypothesizing After</span> the <span>Results</span> Are <span>Known</span>»</span>. <em>Personality and Social Psychology Review</em> 2 (3): 196-217. <a href="https://doi.org/10.1207/s15327957pspr0203_4">https://doi.org/10.1207/s15327957pspr0203_4</a>.
</div>
<div id="ref-makel_Both_2021" class="csl-entry">
Makel, Matthew C., Jaret Hodges, Bryan G. Cook, y Jonathan A. Plucker. 2021. <span>«Both <span>Questionable</span> and <span>Open Research Practices Are Prevalent</span> in <span>Education Research</span>»</span>. <em>Educational Researcher</em>, marzo, 0013189X211001356. <a href="https://doi.org/10.3102/0013189X211001356">https://doi.org/10.3102/0013189X211001356</a>.
</div>
<div id="ref-nosek_preregistration_2018" class="csl-entry">
Nosek, Brian A., Charles R. Ebersole, Alexander C. DeHaven, y David T. Mellor. 2018. <span>«The Preregistration Revolution»</span>. <em>Proceedings of the National Academy of Sciences</em> 115 (11): 2600-2606. <a href="https://doi.org/10.1073/pnas.1708274114">https://doi.org/10.1073/pnas.1708274114</a>.
</div>
<div id="ref-rabelo_Questionable_2020" class="csl-entry">
Rabelo, André L. A., Jéssica E. M. Farias, Maurício M. Sarmet, Teresa C. R. Joaquim, Raquel C. Hoersting, Luiz Victorino, João G. N. Modesto, y Ronaldo Pilati. 2020. <span>«Questionable Research Practices among <span>Brazilian</span> Psychological Researchers: <span>Results</span> from a Replication Study and an International Comparison»</span>. <em>International Journal of Psychology</em> 55 (4): 674-83. <a href="https://doi.org/10.1002/ijop.12632">https://doi.org/10.1002/ijop.12632</a>.
</div>
<div id="ref-rosenthal_file_1979" class="csl-entry">
Rosenthal, Robert. 1979. <span>«The File Drawer Problem and Tolerance for Null Results.»</span>. <em>Psychological Bulletin</em> 86 (3): 638-41. <a href="https://doi.org/10.1037/0033-2909.86.3.638">https://doi.org/10.1037/0033-2909.86.3.638</a>.
</div>
<div id="ref-simmons_FalsePositive_2011" class="csl-entry">
Simmons, Joseph P., Leif D. Nelson, y Uri Simonsohn. 2011. <span>«False-<span>Positive Psychology</span>: <span>Undisclosed Flexibility</span> in <span>Data Collection</span> and <span>Analysis Allows Presenting Anything</span> as <span>Significant</span>»</span>. <em>Psychological Science</em> 22 (11): 1359-66. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a>.
</div>
<div id="ref-simonsohn_Pcurve_2014" class="csl-entry">
Simonsohn, Uri, Leif D. Nelson, y Joseph P. Simmons. 2014. <span>«P-Curve: <span>A</span> Key to the File-Drawer»</span>. <em>Journal of Experimental Psychology: General</em> 143 (2): 534-47. <a href="https://doi.org/10.1037/a0033242">https://doi.org/10.1037/a0033242</a>.
</div>
<div id="ref-steneck_Fostering_2006" class="csl-entry">
Steneck, Nicholas H. 2006. <span>«Fostering Integrity in Research: <span>Definitions</span>, Current Knowledge, and Future Directions»</span>. <em>Science and Engineering Ethics</em> 12 (1): 53-74. <a href="https://doi.org/10.1007/PL00022268">https://doi.org/10.1007/PL00022268</a>.
</div>
<div id="ref-viscusi_Role_2014" class="csl-entry">
Viscusi, W. Kip. 2014. <span>«The <span>Role</span> of <span>Publication Selection Bias</span> in <span>Estimates</span> of the <span>Value</span> of a <span>Statistical Life</span>»</span>. Working {{Paper}} 20116. Working <span>Paper Series</span>. <span>National Bureau of Economic Research</span>. <a href="https://doi.org/10.3386/w20116">https://doi.org/10.3386/w20116</a>.
</div>
<div id="ref-vivalt_Heterogeneous_2015" class="csl-entry">
Vivalt, Eva. 2015. <span>«Heterogeneous <span>Treatment Effects</span> in <span>Impact Evaluation</span>»</span>. <em>American Economic Review</em> 105 (5): 467-70. <a href="https://doi.org/10.1257/aer.p20151015">https://doi.org/10.1257/aer.p20151015</a>.
</div>
</div>
<hr>
<center> 
  <div class="footer">
      Laboratorio de Ciencia Social Abierta <a href="https://lisa-coes.netlify.app/"> (LISA) </a> del Centro de Estudios de Conflicto y Cohesión Social (COES) <a href="https://coes.cl/"></a>
      <br>
      Para más información puedes contactárnos <a href= "lisa@coes.cl"> en nuestro correo </a>
  </div>
</center>

            </section>

          </div>
        </div>
      </div>
<a href="sobre-la-transparencia.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="qué-y-quién.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["transparency.pdf", "transparency.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
