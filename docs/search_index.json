[["index.html", "Transparencia y Reproducibilidad en Investigación Social Capítulo 1 Introducción", " Transparencia y Reproducibilidad en Investigación Social Julio Iturra y Martín Venegas 2021-06-25 Capítulo 1 Introducción Imagine que usted es un chef, y como tal disfruta enormemente del arte de la cocina. Como amante de la cocina, cada vez que alguna celebración especial se avecina, es su tradición el preparar sus mejores recetas para sus seres queridos. Sin embargo, en esta ocación en particular, la celebración se llevará a cabo en un restaurante, lo que implica que la preparación de la comida no depende de usted. Dudoso, accede, sin embargo, en su mente ronda la siguiente pregunta ¿cómo puedo tener la certeza de que se seguirán los procedimientos adecuados para que la comida sea de calidad? Pues, estimado lector, es esta la misma pregunta que está a la base de la generación del conocimiento científico. La ciencia, al igual que la cocina, no se trata solamente de los productos. Un plato de comida no aparece por arte de magia, sino que requiere el seguimiento riguroso de una receta. Usar los ingredientes adecuados, los gramajes apropiados y seguir los tiempos de cocción que dicta la receta no solo contribuyen a preparar un buen plato de comida, sino que hacen posible que ese plato pueda ser reproducido cada vez que sea necesario. Entonces, como buen chef, la respuesta a la pregunta no es tan compleja: necesitamos ser capaces de evaluar el proceso de preparación de la comida para asegurarnos de que es el adecuado. Dicho de otro modo, el proceso de preparación debe ser transparente y estar abierto al escrutinio. En el caso de la comida, que el restaurante cuente con una cocina abierta o construida en torno a ventanales bastaría para lograr este objetivo. Sin embargo, dentro del campo de la ciencia ¿cómo logramos que el proceso de producción del conocimiento científico esté abierto al escrutinio público? Esta pregunta puede ser algo engañosa ¿acaso los procesos de investigación en la ciencia no están ya abiertos al escrutinio público? La narrativa actual pareciese sugerir que no. En el último tiempo ha primado el diagnostico de que la ciencia está viviendo una crisis, donde polémicas situaciones de malas prácticas académicas han salido a la luz. Un ejemplo de estas malas prácticas es el falseamiento de datos. Uno de los casos más emblemáticos es el de Diderik Stapel, una figura académica con alto prestigio en el campo de la psicología social a quién se le acusó y confirmó de falseamiento de datos. Más de 10 años de investigación y 150 artículos -algunos de ellos en las revistas más prestigiosas- fueron puestos en duda a raíz de las malas prácticas de Stapel. Así también el trabajo de muchos colegas y estudiantes fue desacreditado. El caso del ex doctor Stapel acabó en la revocación de su doctorado, la retracción de 58 artículos de investigación y, prácticamente, el fin de su carrera académica. Casos como el de Diderik Stapel existen muchos (ver Abril Ruiz 2019), sin embargo, no son las prácticas más recurrentes. Dentro de la investigación científica existen una serie de prácticas que caen en un terreno gris cuando se trata de su evalución ética, estas son las llamadas prácticas cuestionables de investigación. La preocupación dentro de la comunidad cientifica es que la acumulación y la poca fiscalización de estas prácticas lleven a una ciencia poco transparente, con dificultad en torno a la reproducibilidad de los análisis y de sus resultados, y que a la larga se pierda la confianza en el quehacer científico. La perdida de la confianza en el quehacer cientifico afecta el objetivo de las ciencias sociales. Generalmente se tiene la concepción de que es parte de las tareas de los cientificos sociales el contribuir al bienestar de la sociedad por la vía de las herramientas de investigación. Esta es la noción de las ciencias sociales como un bien público (Thibodeaux 2016). Bajo esa idea, los efectos de una crisis de credibilidad tienen dos posibles efectos concretos en las ciencias sociales. Primero, la falta de credibilidad podría afectar la confianza en los hallazgos y en las discplinas que componen las ciencias sociales. Ya existe evidencia sobre un incremento de desconfianza hacia los cientificos en países como Estados Unidos (Motta 2018) y sumarle una crisis de la ciencia a esa situación solo generaría un ambiente mucho más complejo. Segundo, y estrechamente relacionado a lo anterior, una perdida de credibilidad en la ciencia podría impactar en la elaboración de políticas sociales, mal orientando las prioridades y los recursos del país. Si se quieren evitar estas stuaciones, es necesario tomar cartas en el asunto y orientar los esfuerzos a devolverle la credibilidad a las ciencias sociales. Este manual busca contribuir a una ciencia social más creíble, basandose en el marco de la ciencia abierta. La ciencia abierta se entiende como: la práctica de la ciencia de manera que otros puedan colaborar y contribuir, donde los datos de la investigación, las notas de laboratorio y otros procesos de investigación estén disponibles libremente, en términos que permitan la reutilización, redistribución y reproducción de la investigación y sus datos y métodos subyacentes. (FORSTER, Open Science Teaching Resource) Dentro de la ciencia abierta, nos centraremos en dos conceptos: transparencia y reproducibilidad. Si seguimos la metafora de la cocina que planteamos en un principio, la transparencia y la reproducibilidad son dos conceptos similares, pero no identicos. La transparencia implicaría la posibilidad de evaluar y poner en discusión la receta y la ejecución de la misma. En cambio, la reproducibilidad apuntaría a que la receta sea lo suficientemente clara y precisa para que el mismo plato, con el mismo sabor, pueda ser preparado por cualquier persona que contase con los ingredentes y recursos necesarios. En el campo de las ciencias, esta distinción la hacemos entre: 1) la transparencia de los procesos de producción científica (e.g. transparentar el plan de análisis) y 2) la reproducibilidad de los análisis en los artículos (e.g. código de procesamiento y análisis de datos permite reproducir el artículo). Este manual estará estructurado en torno a estas dos conceptos. Relacionado al primer concepto (transparencia), haremos un barrido un tanto más detallado sobre la crisis de la reproducibilidad que aquí hemos mencionado brevemente. Ahondaremos en los factores que contribuyen a su reproducción, a las razones éticas por el cuales es necesario hacer un cambio y en las recomendaciones que se pueden seguir para adoptar ciertos principios de transparencia. En el caso del segundo concepto (reproducibilidad), nos centraremos en los análisis reproducibles, teniendo un carácter mucho más práctico. Presentaremos las distintas consideraciones que hay que tener para que un análisis sea fácilmente reproducible, desde tipos de flujos de trabajo hasta herramientas especificas que faciliten la reproducibilidad de los análisis. Estimado investigador o investigadora de las ciencias sociales, este documento va dirijido a usted. Independiente de su disciplina, de su trayectoria académica o de su conocimiento previo con respecto a estas temáticas, en este manual tenemos dos simples objetivos. El primero es que usted pueda convencerse de que, efectivamente, es necesario dar un giro en la forma que hacemos ciencia actualmente y que la adopción de prácticas relacionadas a la ciencia abierta son el primer paso en ese giro. El segundo es poder instruirlo en esa adopción de prácticas, particularmente en lo que respecta a la transparencia y reproducibilidad. Al final de este manual, usted será capaz tanto de argumentar por qué la transparencia y la reproducibilidad son un paso importante en el avance de las ciencia sociales, así como también contará con una serie de herramientas para llevar esto al quehacer académico del día a día. References "],["transparencia.html", "Capítulo 2 Transparencia 2.1 ¿Qué es la transparencia? Un concepto multidimensional 2.2 ¿Cuál es el problema? La crisis de credibilidad en las ciencias sociales 2.3 ¿Qué podemos hacer? Recomendaciones, prácticas y experiencias", " Capítulo 2 Transparencia La presente sección tiene trabaja en torno al concepto de transparencia, basandose en los siguientes objetivos: Entregar una definición precisa de qué se entiende por transparencia Exponer las razones que llevan a considerar necesaria una promoción de la transparencia Describir las formas en las que se puede promover la transparencia Al final de esta sección el lector tendrá un manejo del concepto de transparencia y su relevancia para promover una ciencia social abierta. 2.1 ¿Qué es la transparencia? Un concepto multidimensional En términos generales, la transparencia se puede pensar cómo la cualidad de algo que se puede ver a través de él (RAE). Por ejemplo, el vidrio de una ventana hace posible ver con claridad lo que está del otro lado, sin embargo, si la ventana comienza a perder su transparencia la observación se torna más difícil. Más importante aun, la perdida de claridad causa una ambigüedad en la observación dando la posibilidad de emitir conclusiones erroneas sobre el otro lado de la ventana. Lo que antes era claramente un gato, una ventana poco transparente podría llevar hacer concluir que es un perro o cualquier otro tipo de animal. Este ejemplo entrega un punto de partida para reflexionar la transparencia en las ciencias sociales: a medida que aumentamos la transparencia podemos discernir con mayor claridad si estamos ante hallazgos científicos creíbles. El concepto de transparencia ha tomado protagonismo en las ciencias sociales. Cada vez son más los autores que abogan por hacer una ciencia social transparente, así como también las iniciativas que buscan promover la adopción de principios transparentes. No obstante, cabe preguntarse ¿qué es exactamente lo que se está promoviendo? o más específicamente ¿cómo se está entendiendo la transparencia en la literatura? Por ejemplo, Breznau (2021) entiende la transparencia como una forma en los investigadores pueden revelar el proceso, ideas y materiales que sustentan un argumento con tal de contribuir a una comunidad científica más ética. También, Aczel et al. (2020) proponen la transparencia como un principio que permite evaluar y reproducir los hallazgos científicos, asi como también sintetizar investigaciones y contribuir a la ejecución de metanálisis. Estas formulaciones ayudan a ir comprendiendo lo que se dice actualmente en la literatura sobre transparencia, pero no son una presentación exhaustiva del concepto. En esta sección presentaremos dos fuentes que ayudan a comprender la complejidad que significa el concepto de transparencia. La primera será la taxonomía propuesta por Elliott (2020), y la segunda serán las TOP Guidelines (Guías para la promoción de la apertura y la transparencia) (Brian A. Nosek et al. 2014). Figura 2.1: Taxonomía de Transparencia La taxonomía de Elliott (2020) tiene por objetivo sintetizar la complejidad del concepto de transparencia y las distintas formas que puede tomar. La taxonomía se basa en cuatro grandes preguntas: ¿por qué?, ¿quienes? ¿qué? y ¿cómo? Cada una de estas preguntas tiene al menos una dimensión asociada. La primera pregunta se refiere a los propósitos por los cuales adoptar la transparencia; la segunda pregunta apunta a la audiencia que se beneficia de la adopción de transparencia; la tercera pregunta hace alusión al contenido qué es transparentado y la cuarta pregunta hace alusión cuatro distintas dimensiones sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y lugar. También, se añade una dimensión relacionada a los peligros de la transparencia en investigación. Una representación gráfica puede verse en la Figura N° 2.1. En la Figura N° 2.2 se presenta una versión detallada de las dimensiones de la taxonomía en conjunto a una lista no exhaustiva de variaciones dentro de cada dimensión. Por ejemplo, la dimensión del propósito sintetiza varios de los puntos que ya se han señalado en la literatura sobre ciencia abierta. En general, los propósitos están orientados a mejorar la credibilidad de la ciencia, ya sea en si misma (e.g. facilitación del reanálisis de resultados) o ya sea en su rol instrumental (e.g. promover el desarrollo de política pública de calidad). Otra dimensión relevante a destacar es el contenido de lo que se hace transparente, donde según Elliott (2020) las variaciones van de lo más concreto como los datos, métodos y materiales hasta algo más complejo como los juicios de valor. Más adelante en el documento trataremos especialmente la transparencia de los datos, métodos y materiales. Figura 2.2: Variaciones por dimensión de transparencia Otro tratamiento extensivo de la idea de transparencia se da en las TOP Guidelines. Estos son principios que buscan alcanzar un formato de investigación reproducible a tracés del aumento de la transparencia en el proceso y los productos de investigación (Brian A. Nosek et al. 2014). Estos principios sirven de guía a las revistas académicas para poder adherir progresivamente al ideal de transparencia en la ciencia. Son ocho principios: Citación Transparencia de datos Transparencia de métodos análiticos (código) Transparencia de los materiales Transparencia del diseño y el análisis Preregistro de estudios Pre registro de planes de análisis Replicación A grandes rasgos, el principio de citación propone que las normas de citado deben ampliarse también a los datos y códigos, permitiendo reconocer su autoría intelectual (B. A. Nosek et al. 2015). Los principios de transparencia de datos, métodos análiticos, materiales y diseño y análisis (2 a 5) refieren a la transparencia en su forma más concreta: la apertura del proceso de investigación para su evaluación. El detalle puesto a los principios responde a la generelabizilidad que se le busca dar a los principios. Por ejemplo, un estudio observacional cuantitativo no tiene material que transparentar, pero si datos y métodos análiticos. Asi también, un estudio cualitativo quizás no tenga código que transparentar, pero si un diseño y una bitacora detalla del proceso de análisis. En el caso de los principios relacionados al pre-registro, B. A. Nosek et al. (2015) argumenta que registrar los estudios los hace más descubribles, incluso si no son públicados. Asi también, los preregistros del plan de análisis contribuyen a distinguir entre los análisis confirmatorios y explotatorios (ver Brian A. Nosek et al. (2018) para un manejo detalado del tema). Por último, el principios de replicación fomenta las oportunidades para la corrección de artículos y redirecciona la investigación en vías más prometedoras (B. A. Nosek et al. 2015). Cada uno de estos principios cuenta con tres niveles, que sirven para medir el grado de inclusión de la transparencia por parte de una revista cientifica. La Figura N° 2.3 muestra cada nivel en relación el principio correspondiente. Se añade un nivel 0 que no cumple los estandares de transparencia con la finalidad de tener una comparación. Por ejemplo, para los estandares de transparencia del método de análisis (código), el nivel 1 dicta que las revistas deben solicitar la existencia del código de análisis, en cambio, el nivel 3 es más estricto en plantear que el código de análisis debe estar almacenado en un repositorio confiable y que el análisis será reproducido durante el proceso de revisión. El mismo método se puede aplicar para la el preregistro del plan de análisis. En el nivel 1 las revistas promueven el uso de preregistros, en cambio, en el nivel 3 los preregistros son obligatorios y también reconocidos. En suma, las TOP Guideliness son una iniciativa que contribuye a la apertura en la ciencia cambiando los requerimientos de las revistas. Los dos ejemplos entregados (la taxonomía y las TOP Guideliness) perimiten comprender con un poco más de detalle el concepto de transparencia. Sin embargo, aun queda la interrogante del por qué. ¿Cuál es la problemática que lleva a considerar necesaria la adopción de la transparencia? En breve, la respuesta es la crisis en las ciencias, y especificamente en las ciencia sociales. Figura 2.3: Variaciones por dimensión de transparencia 2.2 ¿Cuál es el problema? La crisis de credibilidad en las ciencias sociales En los últimos años, ha venido tomando fuerza la idea de que existe una crisis en la ciencia. Se han utilizado distintos nombres para aludir a esta idea. Algunos han hablado de una crisis de reproducibilidad (e.g. Baker 2016), siendo el principal problema que el formato actual de publicación cientifica no permite reproducir los hallazgos. Otros usan el término de crisis de replicabilidad (e.g. witkowski and Dompnier 2017), donde se argumenta que el principal problema es la falta de replicaciones de estudios científicos. También se ha usado el término de crisis de credibilidad (e.g. Bergh et al. 2017; Carrier 2017), aludiendo a que la evidencia científica ha ido perdiendo su carácter de fiable o veraz, ya sea por prácticas poco éticas, como también por acumulación de errores en los procesos inevstigativos. Sea el concepto que se use, la narrativa instalada es que existe una crisis y que hay que encaminar los esfuerzos en abordarla. Una de las fuentes más comunes para dar cuenta de la existencia de una crisis de reproducibilidad es una encuesta online realizada por la revista Nature. En esta encuesta, Baker (2016) logró obtener las opiniones de 1,576 investigadores de discplinas de las ciencias naturales sobre tópicos relacionados a la reproducibilidad en las ciencias, tales como sus factores y soluciones. El resultado principal muestra que un 52% de los investigadores encuestados creen que hay una crisis significativa, y un 38% creen que hay una ligera crisis. Es decir, un 90% de los encuestados está de acuerdo en la existencia una crisis. Cuándo se les pregunta por los factores que contribuyen a esta crisis, un 60% de los investigadores están de acuerdo en que la cultura del pública o perece y el reporte selectivo de resultados siempre o casi siempre contribuyen la crisis. Si bien la encuesta no es una muestra representativa de toda la comunidad cientifica, presenta una panoramica que lleva a, por lo menos, considerar la crisis de la ciencia como tema a investigar. Actualmente, existe un cuerpo de literatura que se ha dedicado a debatir e intentar demostrar la existencia de una crisis de credibilidad en las ciencias -y en las ciencias sociales-. Esta literatura se ha centrado en buscar los factores que contribuirían a la crisis, así como también en desarrollar distintas herramientas, métodos y prácticas para revertirla. En esta sección señalaremos los factores que con mayor frecuencia se señalan en la literatura. Para esquematizar de mejor manera la presentación de estos factores y la evidencia existente, es que utilizaremos el esquema conceptual de Steneck (2006). El esquema parte de una distinción básica entre la ética en investigación y la integridad en investigación, englobando ambas bajo el gran concepto de Conducta Responsable de Investigación (RCR) (ver Figura N° 2.4. A grandes rasgos, la RCR se puede entender como el llevar a cabo la investigación de forma que se cumplan las responsabilidades profesionales de los investigadores, tal y como las definen sus organizaciones profesionales, las instituciones para las que trabajan y, en su caso, el gobierno y el público (Steneck 2006)1. Figura 2.4: Conducta Responsable de Investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) Dentro de este concepto, la ética de investigación está relacionada al comportamiento académico visto desde la óptica de los principios morales (Steneck 2006), lo que se expresa en tópicos sobre el uso de datos, los consentimientos informados, el trato con pacientes en el caso de las ciencias biomedicas, por dar algunos ejemplos. La definición que ofrece Steneck (2006) señala que la ética de investigación se define como el estudio crítico de los problemas morales asociados o que surgen en el curso de la investigación (p.56) En cámbio, la integridad en investiación se entiende como poseer y adherirse firmemente a las normas profesionales, tal y como las señalan las organizaciones profesionales, las instituciones de investigación y, en su caso, el gobierno y el público (Steneck 2006, 56). A diferencia de la ética de investigación, el concepto de identidad está regido por los estándares profesionales más que por los principios morales, su función espantear una guía clara para la conducta inevestigativa, de ahí que sea el concepto utilizado por distintos códigos de conducta. Figura 2.5: Gradación del comportamiento integro en investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) Habiendonos situando dentro del concepto de integridad en la investigación, podemos pasar a delinear las principales prácticas que atentan contra él y que se han propuesto como factores que contribuyen a la crisis en la ciencia. Tanto Steneck (2006) como distintos códigos de conducta de universidades e instituciones de financiamiento [] plantean una gradación de prácticas de acuerdo en qué tanto atentan contra la integridad en investigación. La Figura N° 2.5 esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derechaa el peor comportamiento (FFP). Las FPP son un abreviación en lengua inglésa para referirse a Fabrication, Falsification, Plagiarism (Invención, Falsificación y Plagio). Las tres prácticas que componen la abreviación también se conocen como mala conducta académica-. En el medio de la gradación están las prácticas cuestionables de investigación (QRP, por sus siglas en inglés) las cuáles refieren a acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación (National Academies of Science 1992 en Steneck 2006, 58). A diferencia de las FFP, las QRP son prácticas que tienen el potencial de dañar la ciencia y no que la dañan directamente (como las FFP). En base a estas distinciones, presentaremos algunas situaciones y evidencia que dan cuenta de la FFP y las QRP. 2.2.1 Mala conducta académica (FFP) La mala conducta académica suelen ser situaciones que alcanzan gran conbertura mediatica y que no están exentas de polémicas. El libro de Abril Ruiz (2019) presenta una serie de situaciones, en distintas discplinas y años, en las que investigadores han sido descubiertos cometiendo mala conducta. Las situaciones son variadas, existen casos de manipulación de imagenes [], exageración de lo registros de laboratorio, o de plano la invención de conjuntos de datos enteros. En esta sección veremos el caso de Diderik Stapel como ejemplo de malas prácticas de investigación y su relación con la transparencia en la investigación. 2.2.1.1 Diderik Stapel Probablemente, el caso de Diderik Stapel sea uno de los más emblématicos y representativos de este problema. Diderik Stapel era un investigador de la Tilburg University que se dedicaba al campo de la psicologóa social. Su carrera se caracterizó por una trayectoria ejemplar, obtuvo su M.A en psicolgía y comunicaciones el año 1991, se doctoró en psicología social el año 1997 y trabajó como profesor asociado primero en la University of Gronigen (2000-2006) y dede el 2006 en la Tilburg University. Fue fundador del Tilburg Institute for Behavioral Economics Research, del cuál el 2010 se convirtió en decano. Así también, fue galardonado con el premio a la trayectoria académica por la Social of Experimental Social Psychology. En breve, Stapel era una figura de alto estatus en el mundo académico, entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas cientificas, algunas de las más prestigiosas (e.g. Science). Sin embargo, el año 2011 se confirmó que gran parte de su trayectoria académica era una farsa. Después de la verificación de su culpa ante acusaciones de malas prácticas, la carrera de Diderik Stapel acabó. Fue desvinculado de la Tilburg University, se le rebocó su título de doctorado y toda su trayectoria académica fue investigada acusiociamente. El informe final de la investigación encontró que más de 50 de sus artículos eran fraudulentos. De hecho, Stapel ocupa el tercer lugar en Retraction Watch, con 58 de sus artículos retractados. A efectos de este escrito, lo que más destacable es que Stapel cometió conductas de mala conducta académica durante más de 15 años. La pregunta es ¿cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o co-autores se dio cuenta de sus malas prácticas? La respuesta breve es por la falta de transparencia durante el proceso de investigación. Los artículos periodisticos que han profundizado en el caso (e.g. Carey 2011) han relatado parte del proceso investigativo de Stapel. Dentro de los procesos de producción y análisis de datos, Stapel se caracterizaba por hacer todo el trabajo solo y a puertas cerradas. Es decir, nadie más que él tenía acceso a los datos brutos, ni támpoco a la ejecución de las pruebas estadísticas. Generalmente, Stapel compartía con sus colegas y alumnos de doctorado la base de datos lista, con las pruebas estadísticas ya hechas y, claro está, con resultados significativos. Estas prácticas no causaron sospechas durante muchos años, es más, a muchos de sus estudiantes les parecía una práctica normal y eficiente. Además, con el estatus de Stapel ¿qué podría estar mal? Sin embargo, era a raíz de esta práctica que Stapel tenía la oportunidad de inventar y falsificar datos a su conveniencia. Esto explica en gran parte de su trayectoría académica llena de grandes hallazgos. El caso de Stapel deja un punto base sobre la mesa: la falta de transparencia en el proceso investigativo dio cabida a la mala conducta académica. Cómo nadie más colaboraba con el procesamiento de datos, ni támpoco parecía extraño que asi fuera, las oportunidades para la falsificación de los datos estaba abierta. Ahora, esta no es necesariamente una relación de causalidad, la falta de transparencia no tiene porque terminar en conductas como fabricación o falsificación de datos. Sin embargo, tal y como lo argumentan (OBoyle, Banks, and Gonzalez-Mulé 2017) si son una oportunidad para violaciones a la integridad cientifíca más sutiles, tales como las QRP. 2.2.2 Prácticas cuestionables de investigación (QRP) Últimamente, el concepto de QRP ha sido bastante abordado en la literatura. Distintos autores han argumentado cómo y por qué las QRP pueden afectar a la credibilidad de la ciencia en su conjunto, y cómo la transparencia puede ser un principio que mitigue esta relación. Los aportes han ido desde opiniones, reflexiones o revisiones de literatura, hasta estudios empíricos que han buscado estimar la prevalencia de estas prácticas y su impacto. En esta sección haremos dos cosas. Primero, veremos algunas de las prácticas especificas que han sido categorizadas como QRP2 y segundo, presentaremos la evidencia que ha buscado cuantificar o estimar estas prácticas y ver su impacto en la ciencia. La primera lista de prácticas que presentamos proviene del Código Europeo de Conducta para la Integridad en la Investigación de la ALLEA. La lista, traducida y textual de Abril Ruiz (2019), es la siguiente: Manipular la autoría o denigrar el papel de otros investigadores en las publicaciones. Volver a publicar partes sustanciales de publicaciones propias anteriores, incluidas las traducciones, sin reconocer o citar debidamente el original (autoplagio). Citar de forma selectiva para mejorar los propios resultados o para complacer a los editores, los revisores o los colegas. Retener resultados de la investigación. Permitir que los patrocinadores pongan en peligro la independencia en el proceso de investigación o en la presentación de resultados con el fin de introducir sesgos. Ampliar de manera innecesaria la bibliografía de un estudio. Acusar a un investigador de conducta indebida u otras infracciones de forma maliciosa. Tergiversar los logros de la investigación. Exagerar la importancia y la relevancia práctica de los resultados. Retrasar u obstaculizar inadecuadamente el trabajo de otros investigadores. Emplear la experiencia profesional propia para alentar a que se incumpla la integridad de la investigación. Ignorar supuestos incumplimientos de la integridad de la investigación cometidos por terceros o encubrir reacciones inadecuadas a conductas indebidas u otro tipo de incumplimientos por parte de las instituciones Establecer publicaciones o brindar apoyo a publicaciones que no cumplen el proceso de control de calidad de la investigación (publicaciones abusivas) Otro trabajo que presenta una lista sistematizada de QRP es el de Martinson, Anderson, and de Vries (2005). La lista, textual y traducida de Abril Ruiz (2019) es la siguiente (incluye algunas FFP): Falsificar o (cocinar) datos de investigación. Ignorar los aspectos importantes de los requerimientos de las personas participantes. No divulgar adecuadamente la participación en empresas cuyos productos se basan en la investigación de uno. Relaciones con estudiantes, sujetos de investigación o clientes que pueden ser interpretadas como cuestionables. Usar ideas de otros sin obtener permiso o dar crédito Uso no autorizado de información confidencial en relación con la propia investigación. No presentar datos que contradicen una propia investigación previa. Eludir ciertos aspectos menores de los requerimientos de las personas participantes. Pasar por alto el uso de datos cuestionables o de interpretaciones cuestionables que otros hacen. Cambiar el diseño, la metodología o los resultados de un estudio como respuesta a la presión de una fuente de financiación. Publicar los mismos datos o resultados en dos o más publicaciones. Asignar inapropiadamente los crédios de autoría. Retener detalles de la metodología o los resultados en artículos o propuestas Usar diseños de investigación inadecuados o inapropiados. Eliminar observaciones o puntos de datos de los análisis basados en la intuición de que eran inexactos. Mantener registros inadecuados relacionados con los proyectos de investigación. Otro ejemplo es el de John, Loewenstein, and Prelec (2012), quienes en su estudio sistematizan las prácticas en la siguiente lista -textual y traducida por Abril Ruiz (2019)-: En un paper, no fueron reportadas todas las variables dependientes de un estudio. Decidir si recopilar más datos después de ver si los resultados fueron significativos. En un paper, no fueron reportadas todas las condiciones del estudio. Dejar de recopilar datos antes de lo esperado porque se encontró el resultado que uno esperaba. En un paper, redondear un valor p (por ejemplo, reportar que un p-value de 0,054 es menor a 0,05. En un paper, selectivamente reportar estudios que (funcionaron). En un paper, decidir si excluir datos después de analizar el impacto en los resultados. En un paper, reportar un hallazgo inesperado como previsto desde el principio. En un documento, afirmar que los resultados no se ven afectados por variables demográficas (por ejemplo, el género), cuando uno no está realmente seguro (o sabe que lo hacen). Falsificar datos Otra lista, aunque menos extensiva, es la de OBoyle, Banks, and Gonzalez-Mulé (2017): Eliminación o adición de datos después de pruebas de hipótesis. Alterando los datos después de la prueba de hipótesis. Supresión selectiva o adición de variables. Invertir la dirección o reformular hipótesis para respaldar los datos Eliminación o adición post hoc de hipótesis La mayoría o la totalidad de las prácticas presentadas acá han sido nombradas de distintas formas a lo largo de los años. La lista presentada por Abril Ruiz (2019) hace un buen resumen de los términos: Intentional bias in Research: sesgos que investigadores introducen en la investigación. Fudging, massaging o cooking: procesar los datos con tal de obtener resultados desados (e.g. que se cumpla una hipotésis que originalmente no se cumpliría). Este concepto suele caer dentro de las FFP. Drylabbing: reportar experimentos que nunca se realizaron Cherry picking data: reportar resultados que confirman hipotésis e ignorar los que la contradicen Salami publication o salami slicing: dividir una invesigación en pequeñas partes y publicar las partes por separado, con tal de contar con más publicaciones. Publication bias: publicar una investigación solo si el resultado es significativo. Verification bias: repetir un experimento hasta obtener resultados deseados o extraer casos con el mismo objetivo. Data fishing o p-hacking: realización de multiples pruebas estadísticas para hallar patrones significativos. HARKing3: plantear las hipotesis una vez habiendo analizado los resultados, y reportar el proceso inverso. Una vez contamos con un paneo general sobre qué situaciones particulares caben dentro del concepto de QRP (y también de FFP), podemos pasar a revisar la evidencia en turno a su prevalencia. Una de las fuentas más citadas para una primera aproximación a la cuantificación de las QRP es el estudio de John, Loewenstein, and Prelec (2012). En este estudio se encuestaron a más de 2000 psicologos sobre su implicación con las QRP. El procedimiento consistió en preguntar sobre las 10 malas prácticas de investigación más comunes. Las preguntas sobre cada QRP estaban divididas en tres formatos: primero, relacionados a su propio comportamiento; segundo, relacionado al comportamiento de otros psicologos y tercero, el porcentaje de psicologos que creían que admitiría haber cometido QRP. Adicionalmente, a aquellos que admitieron haber prácticado alguna QRP se les preguntó acerca de las justificaciones para hacerlo. Los resultados mostraron que un 36.6% de quienes participaron alguna vez habían práctiado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicologos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipotesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Otro estudio, algo más antiguo en cuanto a fecha -en comparación a John, Loewenstein, and Prelec (2012)-, pero más potente en cuanto a resultados es el de Fanelli (2009). En este estudio se hizo un metanálisis en varios idiomas sobre artículos que incluyeran palabras relacionadas a las malas prácticas en investigación (e.g. research misconduct) y que hubieran sido publicados entre 1988 y 2005. De un conjunto de referencias inicial de 3276, se seleccionaron 21 artículos. El criterio de inclusión era que fueran artículos cuantitativos de encuestas que preguntaran directamente sobre malas prácticas (como el de John, Loewenstein, and Prelec (2012)). Los principales resultados son los siguientes: en promedio, un 1.97% de investigadores admite haber fabricado datos al menos una vez; un 33.7% admite haber realizado QRP como borrar puntos de los datos basados en un sentimiento visceral. Cuando se les pregunta por los comportamientos de otros, un 14% consiera que sus colegas caen en FFP y un 72% en QRP. Un estudio que se aleja de la encuesta directa sobre prácticas, pero que contribuye estimando cuál es el potencial de que una QRP afecte los resultados de un artículo es el de Simmons, Nelson, and Simonsohn (2011). En detalle, los autores buscan calcular el likelihood de obtener un falso positivo (error Tipo I) de acuerdo a al nivel de manipulación intencionada de los datos. El procedimiento consistió en calcular 15.000 muestras de 20 observaciones por condición de tratamiento para un experimento hipotetico y determinaron cuatro posibles ajustes a los datos: 1) plantear dos variables dependientes correlacionadas, 2) incrementar la muestra entre 20 y 30 casos según condición de tratamiento, 3) controlar por una variable sociodemográfica (género) o plantear una interacción genero y condición de tratamiento y 4) flexibilidad en eliminar alguna condición de tratamiento. Como se puede ver en la Figura N° 2.6, el resultado principal es que a medida que aumenta la cantidad de manipulación en los datos, el likelihood de obtener un falso positivo aumenta progresivamente. Una situación en donde se realicen los cuatro ajustes planteados tiene un 60.7% de likelihood de encontrar un falso positivo. Figura 2.6: Likekihood de obtener un falso positivo según nivel de manipulación de datos. Imagen de Simmons, Nelson, and Simonsohn (2011) Una herramienta que se ha utilizado para estimar la existencia de p-hacking en los cuerpos de literatura es la p-curve. La p-curve describe la densidad de los p-values reportados en una literatura, aprovechando el hecho de que si la hipótesis nula fuera verdadera (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1 (Christensen, Freese, and Miguel 2019, 67.). De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de p-values debería ser asimetrica a la derecha, en cambio, si existe sesgo por p-hacking la distribución de p-values estaría distribuida de forma asimetrica a la izquierda. Simonsohn, Nelson, and Simmons (2014) proponen esta herramienta y la prueban en dos muestras de artículos de la Journal of Personality and Social Psychology (JPSP). Las pruebas estadísitcas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipotesis, en detalle, los artículos que presentaban solamente resultados con covariables, resultaron tener una p-curve asimetrica a la izquierda. Además del p-hacking, en la literatura también se habla del sesgo de publicación. Como se mencionó, el sesgo de publicación se refiere al reporte selectivo de resultados significativos, dejando sin reportar los no significativos. El estudio de Franco, Malhotra, and Simonovits (2014) busca cuantificar esta situación, especificamente en ciencias sociales. En su estudio encontraron un patrón interesante: estudios donde la hipotesis principales arrojan resultados nulos son 40% menos probables de ser publicados en una revista cientifica, en contraste a estudios que arrojen resultados significativos (Christensen, Freese, and Miguel 2019, 41). Los descriptivos se pueden ver en la Figura N° 2.7. Figura 2.7: Porcentajes de publicación de acuerdo a significancia de resultados. Imagen de Christensen, Freese, and Miguel (2019).  Parrafo final de la seccion que vuelva a conectar los factores con la idea de crisis 2.3 ¿Qué podemos hacer? Recomendaciones, prácticas y experiencias 2.3.1 Recomendaciones 2.3.2 Experiencias 2.3.3 Herramientas References "],["reproducibilidad.html", "Capítulo 3 Reproducibilidad", " Capítulo 3 Reproducibilidad We describe our methods in this chapter. "],["palabras-finales.html", "Capítulo 4 Palabras finales", " Capítulo 4 Palabras finales Hemos aprendido sobre transparencia y reproducibilidad. "],["references.html", "References", " References "]]
