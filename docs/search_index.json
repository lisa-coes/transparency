[["index.html", "Transparencia y Reproducibilidad en Investigación Social Capítulo 1 Introducción", " Transparencia y Reproducibilidad en Investigación Social Documento de trabajo Investigador a cargo: Juan Carlos Castillo Asistente de investigación: Julio Iturra Pasante: Martín Venegas Márquez 24 agosto 2021 Capítulo 1 Introducción Imagine que usted es un chef, y como tal, disfruta enormemente de las artes culinarias. Como amante de la cocina, cada vez que alguna celebración especial se avecina, es tradición preparar sus mejores recetas para sus invitados. Sin embargo, en esta ocasión, la celebración se llevará a cabo en un restaurante, lo cual implica que la preparación de la comida no depende de usted. Con bastantes dudas, usted accede, teniendo en mente la siguiente pregunta: ¿Cómo puedo tener certeza de que se seguirán los procedimientos adecuados para que la preparación sea de calidad? Pues, estimado lector, es esta la pregunta que subyace a todo el proceso que engloba al conocimiento científico. La ciencia, al igual que la cocina, no se trata solamente de los productos. Una preparación no aparece por generación espontánea, sino que requiere el seguimiento riguroso de una receta, donde usamos los ingredientes, las cantidades y tiempos de cocción adecuados. Esta receta no solo contribuye a la preparación de la comida, sino que hace posible que dicho plato pueda ser reproducido cada vez que se lo desee, garantizando el mismo resultado. Entonces, como buen chef, la respuesta a la pregunta no es tan compleja: necesitamos ser capaces de evaluar el proceso de elaboración de la comida para asegurarnos de que es el adecuado. Dicho de otro modo, el proceso de preparación debe ser transparente y estar abierto al escrutinio de otros cocineros expertos, como también para quienes estén adentrándose en la cocina. En el caso de la comida, que el restaurante cuente con una cocina abierta o construida en torno a ventanales bastaría para lograr este objetivo. Sin embargo, dentro del campo de la ciencia ¿cómo logramos que el proceso de producción del conocimiento científico esté abierto al escrutinio público? Esta pregunta puede ser algo engañosa ¿acaso los procesos de investigación en la ciencia no están ya abiertos al escrutinio público? La narrativa actual pareciese sugerir que no. En el último tiempo ha primado el diagnostico de que la ciencia está viviendo una crisis, donde polémicas situaciones de malas prácticas académicas han salido a la luz. Un ejemplo de estas malas prácticas es el falseamiento de datos. Uno de los casos más emblemáticos es el de Diderik Stapel, una figura académica con alto prestigio en el campo de la psicología social a quién se le acusó y confirmó de falseamiento de datos. Más de 10 años de investigación y 150 artículos -algunos de ellos en las revistas más prestigiosas- fueron puestos en duda a raíz de las malas prácticas de Stapel. Así también el trabajo de muchos colegas y estudiantes fue desacreditado. El caso del ex doctor Stapel acabó en la revocación de su doctorado, la retracción de 58 artículos de investigación y, prácticamente, el fin de su carrera académica. Casos como el de Diderik Stapel existen muchos (ver Abril Ruiz 2019), sin embargo, no son las prácticas más recurrentes. Dentro de la investigación científica existen una serie de prácticas que caen en un terreno gris cuando se trata de su evaluación ética, estas son las llamadas prácticas cuestionables de investigación. La preocupación dentro de la comunidad científica es que la acumulación y la poca fiscalización de estas prácticas lleven a una ciencia poco transparente, con dificultad en torno a la reproducibilidad de los análisis y de sus resultados, y que a la larga se pierda la confianza en el quehacer científico. La perdida de la confianza en el quehacer científico afecta el objetivo de las ciencias sociales. Generalmente se tiene la concepción de que es parte de las tareas de los científicos sociales el contribuir al bienestar de la sociedad por la vía de las herramientas de investigación. Esta es la noción de las ciencias sociales como un bien público (Thibodeaux 2016). Bajo esa idea, los efectos de una crisis de credibilidad tienen dos posibles efectos concretos en las ciencias sociales. Primero, la falta de credibilidad podría afectar la confianza en los hallazgos y en las disciplinas que componen las ciencias sociales. Ya existe evidencia sobre un incremento de desconfianza hacia los científicos en países como Estados Unidos (Motta 2018) y sumarle una crisis de la ciencia a esa situación solo generaría un ambiente mucho más complejo. Segundo, y estrechamente relacionado a lo anterior, una perdida de credibilidad en la ciencia podría impactar en la elaboración de políticas sociales, mal orientando las prioridades y los recursos del país. Si se quieren evitar estas situaciones, es necesario tomar cartas en el asunto y orientar los esfuerzos a devolverle la credibilidad a las ciencias sociales. Este manual busca contribuir a una ciencia social más creíble, basándose en el marco de la ciencia abierta. La ciencia abierta se entiende como: la práctica de la ciencia de manera que otros puedan colaborar y contribuir, donde los datos de la investigación, las notas de laboratorio y otros procesos de investigación estén disponibles libremente, en términos que permitan la reutilización, redistribución y reproducción de la investigación y sus datos y métodos subyacentes. (FORSTER, Open Science Teaching Resource) Dentro de la ciencia abierta, nos centraremos en dos conceptos: transparencia y reproducibilidad. Si seguimos la metáfora de la cocina que planteamos en un principio, la transparencia y la reproducibilidad son dos conceptos similares, pero no idénticos. La transparencia implicaría la posibilidad de evaluar y poner en discusión la receta y la ejecución de esta. En cambio, la reproducibilidad apuntaría a que la receta sea lo suficientemente clara y precisa para que el mismo plato, con el mismo sabor, pueda ser preparado por cualquier persona que contase con los ingredientes y recursos necesarios. En el campo de las ciencias, esta distinción la hacemos entre: 1) la transparencia de los procesos de producción científica (e.g. transparentar el plan de análisis) y 2) la reproducibilidad de los análisis en los artículos (e.g. código de procesamiento y análisis de datos permite reproducir el artículo). Este manual estará estructurado en torno a estos dos conceptos. Relacionado al primer concepto (transparencia), haremos un barrido un tanto más detallado sobre la crisis de la reproducibilidad que aquí hemos mencionado brevemente. Ahondaremos en los factores que contribuyen a su reproducción, a las razones éticas por el cuales es necesario hacer un cambio y en las recomendaciones que se pueden seguir para adoptar ciertos principios de transparencia. En el caso del segundo concepto (reproducibilidad), nos centraremos en los análisis reproducibles, teniendo un carácter mucho más práctico. Presentaremos las distintas consideraciones que hay que tener para que un análisis sea fácilmente reproducible, desde tipos de flujos de trabajo hasta herramientas específicas que faciliten la reproducibilidad de los análisis. Estimado investigador o investigadora de las ciencias sociales, este documento va dirigido a usted. Independiente de su disciplina, de su trayectoria académica o de su conocimiento previo con respecto a estas temáticas, en este manual tenemos dos simples objetivos. El primero es que usted pueda convencerse de que, efectivamente, es necesario dar un giro en la forma que hacemos ciencia actualmente y que la adopción de prácticas relacionadas a la ciencia abierta son el primer paso en ese giro. El segundo es poder instruirlo en esa adopción de prácticas, particularmente en lo que respecta a la transparencia y reproducibilidad. Al final de este manual, usted será capaz tanto de argumentar por qué la transparencia y la reproducibilidad son un paso importante en el avance de las ciencias sociales, así como también contará con una serie de herramientas para llevar esto al quehacer académico del día a día. References "],["transparencia.html", "Capítulo 2 Transparencia", " Capítulo 2 Transparencia El movimiento de ciencia abierta viene aparejado de muchos conceptos que, desde distintas veredas, buscan mejorar la ciencia. Esto es lo que en este libro hemos tratado cómo componentes. Uno de los conceptos centrales dentro de la ciencia abierta, y nuestro primer componente es el de transparencia. El concepto de transparencia está al alero de toda publicación científica o iniciativa relacionada a la ciencia abierta. Está en el título de informes y artículos, así cómo en el nombre de organizaciones y proyectos, pero ¿qué significa? o mejor dicho ¿transparencia de qué? Ciertamente la transparencia puede aludir a muchas cosas, es uno de esos conceptos que abarca mucho pero clarifica poco, por lo que para poder siquiera hablar de él es necesario tomar una posición sobre qué tipo de transparencia estamos hablando. A raíz de lo anterior es que en este capítulo presentaremos una perspectiva de cómo es posible entender la transparencia en las ciencias sociales. Nuestro argumento se puede resumir en la respuesta a las siguientes tres preguntas: ¿Transparencia de qué? Del diseño de investigación, lo que incluye desde hipótesis hasta planes de análisis. ¿Por qué adoptarla? Existen prácticas de investigación que merman la credibilidad de los resultados científicos y promover prácticas transparentes puede mitigar esa relación. ¿Qué herramientas existen? Los pre registros, informes registrados y otros son prácticas que pueden promover la transparencia. A continuación, presentamos el argumento detrás de cada una de estas respuestas. "],["transparencia-de-qué.html", "2.1 ¿Transparencia de qué?", " 2.1 ¿Transparencia de qué? Comencemos por lo básico. ¿Qué significa que algo sea transparente? Según la Real Academia Española la transparencia es la cualidad de un cuerpo que permite ver a través de él. Un ejemplo para llevar esta definición a la práctica es el vidrio de una ventana. La transparencia del vidrio nos permite ver con claridad lo que está el otro lado, como por ejemplo un paisaje. Es decir, dada la cualidad transparente de la ventana, podemos analizar con detalle qué compone el paisaje: cuántos árboles hay, cómo está el clima, cuántos animales hay etc. Pero, ¿qué ocurre cuándo la transparencia del vidrio se va perdiendo? La respuesta es simple, pero potente: la claridad con la que veíamos el paisaje se va difuminando. Esta pérdida de claridad puede dar como resultado que nuestra observación del paisaje se torne ambigua y errónea, o dicho de otro modo, cada vez será más difícil evaluar qué es lo que efectivamente está en el paisaje. Desde este ejemplo se puede plantear un símil con la ciencia; el paisaje equivale al proceso de producción científica, y el vidrio representa la claridad con la que podemos analizar este proceso. De esta manera, la base de la idea de transparencia es que permite analizar con claridad un fenómeno, una situación, o en este caso, un proceso. Entonces, ya tenemos una primera respuesta: la transparencia puede ser una cualidad de un proceso de producción científica, una cualidad que ciertamente se ve cómo positiva. Pensemos en cuándo le solicitamos transparencia a las entidades públicas en las finanzas o en la producción de leyes, básicamente estamos demandando algo similar: que el actuar de la entidad sea transparente, con tal de que la ciudadanía lo pueda evaluar con claridad. Quizás el ejemplo más claro son las cuentas públicas que año a año efectúa el gobierno de Chile, o también la ley de transparencia, donde cualquier ciudadano puede presentar un requerimiento para ver los documentos que respaldan una compra del gobierno o la producción de una ley. Avancemos de los ejemplos anecdóticos al tema que nos convoca ¿Qué implica un proceso científico transparente? Algunos investigadores ya han planteado sus posturas respecto a esta pregunta. Por ejemplo, Breznau (2021) entiende la transparencia como una forma en que los investigadores pueden revelar el proceso, ideas y materiales que sustentan un argumento o una teoría, con tal de contribuir a una comunidad científica más ética. Otra perspectiva es la de Aczel et al. (2020), quienes proponen a la transparencia como un principio que permite evaluar y reproducir los hallazgos científicos, así como también a sintetizar investigaciones y contribuir a la ejecución de metaanálisis. Klein et al. (2018) proponen que la credibilidad de los productos científicos dependen de la transparencia en la que se basan y que, en consecuencia, avanzar hacia la transparencia simplemente significa adoptar ciertas prácticas de gestión de la investigación que la hagan menos propensa a errores y más reproducibles. Estas perspectivas ofrecen una primera aproximación a las implicancias de un proceso científico transparente, no obstante, no representan una presentación exhaustiva del concepto. Entonces ¿qué es la transparencia? Para introducir el concepto de una forma que demuestre su multidimensionalidad de manera simple es que nos basamos en la taxonomía de Elliott (2020). La taxonomía se estructura en torno a cuatro preguntas: ¿por qué?, ¿quién? ¿qué? y ¿cómo? Cada una de estas preguntas tiene al menos una dimensión asociada. La primera pregunta (¿por qué?) se refiere a los propósitos por los cuales es necesario adoptar la transparencia; la segunda pregunta (¿quién?) apunta a la audiencia que está recibiendo la información; la tercera pregunta (¿qué?) hace alusión al contenido qué es transparentado y la cuarta pregunta (¿cómo?) consiste en cuatro dimensiones distintas sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y espacios. También, la taxonomía propone una dimensión sobre las amenazas que podrían afectar a las iniciativas que busquen promover la transparencia. Una representación gráfica puede verse en la Figura N° 2.1. Figura 2.1: Taxonomía de Transparencia Para comprender mejor la taxonomía la Tabla N° 2.1 presenta una versión detallada de cada dimensión en conjunto a una lista no exhaustiva de variaciones. Al igual que la Figura N° 2.1, la tabla está organizada en dimensiones asociadas a una pregunta, la diferencia es que aquí se añaden ciertas situaciones que ejemplifican cada dimensión de la transparencia, además de que hemos añadido la pregunta ¿Qué podría afectar iniciativas de transparencia? para comunicar de mejor manera la dimensión de amenazas. Partiendo por la dimensión del propósito la cual sintetiza varios de los puntos que ya se han señalado en la literatura sobre ciencia abierta: la transparencia contribuye a formar una ciencia más replicable, facilita la interacción crítica, facilita el reanálisis de resultados, entre otros. La mayoría de estos propósitos están estrechamente relacionados con el horizonte de una ciencia con mayor credibilidad, cuestión que profundizaremos en breve. Luego, la dimensión de la audiencia nos muestra distintos sujetos que podrían recibir la información transparentada, como otros científicos, desarrolladores de política pública o también el público general. La dimensión de los contenidos es quizás la más importante a efectos de proponer una definición de transparencia. De hecho, es esta dimensión la que logra responder a la pregunta que hemos planteado en un principio: ¿transparencia de qué? Según la taxonomía, los distintos contenidos que pueden ser transparentados van desde cosas complejas como los juicios de valor o factores que podrían influenciar las interpretaciones de resultados, hasta otras más concretas como datos, métodos y materiales. Es en esta última en la que nosotros queremos enfatizar. Cuando se piensa en la transparencia de los datos, métodos y materiales, se pueden plantear dos formas de entenderla. Por un lado, está el planteamiento de que la transparencia de un proceso de investigación científico se da a través del libre acceso de sus datos y materiales. Es decir, con tal de que los datos y otros aspectos importantes del estudio estén disponibles públicamente ya es suficiente para denominar a ese estudio cómo transparente. Por otro lado, está la perspectiva de que también es necesario transparentar el diseño de investigación, lo que incluye las hipótesis, las formas de medir las variables y el plan de análisis, entre otros. Específicamente, se busca dejar a disposición del público el diseño de investigación previo a efectuarlo, con tal de robustecer el argumento de que los resultados no fueron alterados posterior a los análisis. Sí bien ambas perspectivas las consideramos en el libro (en el presente componente de transparencia y en el último de datos abiertos), es en la transparencia de los diseños de investigación donde focalizamos las energías en el presente capítulo. Además de las tres dimensiones anteriores, contamos con cuatro dimensiones que están asociadas a la pregunta por el ¿cómo? promover la transparencia. La primera dimensión es la de los actores que tienen el potencial de promover la transparencia, tales como periodistas o científicos. La segunda dimensión se trata de los espacios donde la transparencia puede ser promovida, donde algunos ejemplos son la divulgación científica, reportes de agencias gubernamentales o los repositorios que albergan la información transparentada. En tercer lugar, está el marco temporal en donde se puede optar por promover la transparencia. Aquí es variado, la transparencia puede ser ejercida tanto antes, durante o después del proceso de investigación a través de herramientas distintas y con implicancias distintas. Por ejemplo, en este documento nos centramos en la transparencia del diseño de investigación a través de los preregistros, lo que, generalmente, cabría dentro del antes de la investigación. Por último, están los mecanismos a través de los cuáles la transparencia puede ser ejercida, como en las colaboraciones interdisciplinares o en iniciativas gubernamentales. La última dimensión sobre las amenazas trata sobre ciertas situaciones que podrían afectar las iniciativas sobre transparencia. Un ejemplo bastante esclarecedor es cuando se organiza una iniciativa para promover la transparencia en la investigación (e.g. un taller) y se acaba causando más confusión dado el exceso de información. Es por eso que, tener en cuenta estas amenazas permite anticipar los posibles problemas y orientar la ejecución de las iniciativas para evitarlos. Por ejemplo, este capítulo busca presentar la información relevante sobre la transparencia de la forma más simple posible, con tal de evitar abrumar y/o confundir al lector. Tabla 2.1: Variaciones por cada dimensión de transparencia Pregunta Dimensión Variaciones ¿Por qué? Proposito Facilitar el reanalisis de los resultados Hacer a la ciencia más replicable Promover la innovación Mantener la rendición de cuentas de los expertos Facilitar la interacción crítica Promover el desarrollo de política pública de alta calidad Permitir al público tomar decisiones de acuerdo a sus valores Promover la integridad ¿Quién? Audiencia Cientificos haciendo la investigación Otros cientificos Desarrolladores de política pública Políticos Periodistas Grupos de interés Público general ¿Qué? Contenido Datos, métodos, código y materiales Interpretaciones de los datos, metodos, y codigos para no especialistas Juicios de valor, factores que los influencian o sus implicancias Deliberaciones que subyacen a los reportes ¿Cómo? Actores Cientificos que desarrollaron la investigación Otros científicos de la misma disciplina u otras Periodistas Sociedades cientificas Agencias gubernamentales Organizaciones no gubernamentales y de la sociedad civil Espacios Comunicación desde los cientificos (oral o escrita, incluyendo las redes sociales) Registros o repositorios Divulgación cientifica Reportes de agencias gubernamentales Reportes de agencias no gubernamentales o grupos de la comunidad Marco temporal Antes de que la investigación comience Durante el proceso de investigación Inmediatamente después de que los datos fueron recolerados Despés de la publicación Durante o después de las revisiones o el análisis de la investigación Mecanismos Discusiones entre cientificos (orales o escritas) Colaboraciones interdisciplinares Colaboraciones con miembros de la comunidad Organos asesores gubernamentales y otras iniciativas Procedimientos contradictorios (e.g. cortes científicas) ¿Qué podría afectar iniciativas de transparencia? Amenazas Dañar compañías Violación de privacidad Generación de escepticismo inapropiado Crear un falso sentido de confianza Causar confusión Facilitación de esfuerzos para acosar o mal guiar. En síntesis, un proceso de investigación transparente es uno que se puede evaluar con claridad y facilidad, tal y cómo cuando podemos evaluar la gestión de un ente público a raíz de leyes de transparencia. A partir de la taxonomía de Elliott (2020), hemos podido comprender el por qué, qué, quién y cómo del concepto de transparencia. Hemos hecho énfasis respecto de los contenidos que se están transparentando y señalado que tanto la apertura de datos como la transparencia en los diseños de investigación son una característica de un proceso de investigación transparente. Sin embargo, no hemos profundizado en la dimensión del por qué. ¿Por qué habría de invertir tiempo y energía en aprender nuevas herramientas y/o prácticas para hacer que la ciencia sea más transparente. Pues, la comunidad de adherentes a la ciencia abierta y la literatura asociada han adoptado el discurso de que efectivamente es necesario cambiar la forma que estamos haciendo hoy en día. Ha emergido la narrativa de que la ciencia está en crisis. ¿Por qué adoptarla? En los últimos años, ha tomado fuerza la idea de que existe una crisis en la ciencia. No obstante, las perspectivas sobre qué es lo que está en crisis son variadas. Algunos la denominan una crisis de reproducibilidad (R. Peng 2015; An 2018; França y Monserrat 2019), otros una crisis de replicabilidad (Anvari y Lakens 2018) y otros de credibilidad (Gall, Ioannidis, y Maniadis 2017; Byington y Felps 2017). Así también, otros argumentan que no existe suficiente evidencia para hablar de una crisis en la ciencia (Fanelli 2018). Independiente de sí se use la terminología de la crisis o no, la literatura es consistente respecto a que sí existen ciertas características de la academia y la investigación que, cambiandolas, podrían contribuir a una ciencia más creíble y de mayor calidad, la pregunta es ¿qué se puede cambiar para mejorar la ciencia? Actualmente, existe un cuerpo de literatura que gira en torno a la pregunta recién planteada. Varios estudios han orientado sus esfuerzos a esclarecer cuáles son los factores que podrían estar influenciando una posible crisis de la ciencia. Al respecto, Baker (2016) hizo una encuesta donde preguntaba a investigadores de distintas disciplinas sobre la existencia de esta crisis y sus factores. En relación a sus resultados es posible plantear dos tipos de factores. El primero, de corte más estructural, está relacionado al modelo de producción científica actual, donde los incentivos por publicar (Angell 1986), los criterios de ascenso en la jerarquía académica (Flier 2017) y el formato de la revisión por pares contribuyen (Chambers 2013) a generar una cultura del pública o perece que fuerza a los investigadores a aumentar su productividad académica y facilita que caigan en prácticas cuestionables de investigación (QRP). El segundo factor, de corte más individual, está relacionado a la flexibilidad que tienen los investigadores a la hora de realizar investigaciones, generando la oportunidad para que también emerjan QRP (G. S. Christensen, Freese, y Miguel 2019; OBoyle, Banks, y Gonzalez-Mulé 2017). En suma, ambos factores parecen tener algo en común: existen ciertas prácticas de investigación que afectan la credibilidad de la ciencia, por lo que la apuesta de muchos está en que identificandolas y proponiendo prácticas alternativas podemos mejorar la calidad de la ciencia (e.g. Miguel et al. 2014; Chin et al. 2021). En este capítulo buscamos contribuir a esa apuesta. Para esquematizar de mejor manera qué es lo problemático de ciertas prácticas, es que utilizamos el esquema conceptual de Steneck (2006). El esquema parte de una distinción básica entre la ética en investigación y la integridad en investigación, englobando ambas bajo el concepto de Conducta Responsable de Investigación (RCR) (ver Figura N° 2.2. A grandes rasgos, la RCR se puede entender como llevar a cabo la investigación de forma que se cumplan las responsabilidades profesionales de los investigadores, tal y como las definen sus organizaciones profesionales, las instituciones para las que trabajan y, en su caso, el gobierno y el público (Steneck 2006). En palabras simples, una conducta íntegra es atenerse a un conjunto de reglas sobre conducta científica. Figura 2.2: Conducta Responsable de Investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) Dentro de la RCR, la ética de investigación está relacionada al comportamiento académico visto desde la óptica de los principios morales (Steneck 2006), lo que se expresa en tópicos como el uso de datos, los consentimientos informados o el trato con los participantes de un estudio, por dar algunos ejemplos. La definición que ofrece Steneck (2006) señala que la ética de investigación se define como el estudio crítico de los problemas morales asociados o que surgen en el curso de la investigación (p.56) En cambio, la integridad en investigación se entiende como poseer y adherirse firmemente a las normas profesionales, tal y como las señalan las organizaciones profesionales, las instituciones de investigación y, en su caso, el gobierno y el público (Steneck 2006, 56). Esto quiere decir que, a diferencia de la ética de investigación, el concepto de integridad está regido por estándares profesionales más que por principios morales, su función es plantear una guía clara para la conducta investigativa, de ahí que sea el concepto utilizado por distintos códigos de conducta (ver Abril Ruiz 2019). Figura 2.3: Gradación del comportamiento integro en investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) Habiéndonos situado dentro del concepto de integridad en la investigación, podemos pasar a delinear las principales prácticas que atentan contra él. Tanto Steneck (2006) como distintos códigos de conducta de universidades e instituciones de financiamiento (ver Abril Ruiz 2019) evalúan las prácticas de investigación en un continuo, que representa cuánto adhieren los investigadores a los principios de integridad científica. La Figura N° 2.3 esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derecha el peor comportamiento (FFP). Las FPP son una abreviación en lengua inglesa para referirse a Fabrication, Falsification, Plagiarism (Invención, Falsificación y Plagio), también conocidas como mala conducta académica-. En el medio del continuo están las prácticas cuestionables de investigación (QRP, por sus siglas en inglés) las cuáles refieren a acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación (National Academies of Science 1992 en Steneck 2006, 58). Las QRP se caracterizan porque tienen el potencial de dañar la ciencia, en tanto las FFP la dañan directamente. Comprendidos ambos conceptos, veamos las situaciones que podrían categorizarse como FFP y las que podrían concebirse como QRP. Mala conducta académica (FFP) La mala conducta académica suelen ser situaciones polémicas y que muchas veces alcanzan gran cobertura mediática. El libro de Abril Ruiz (2019) hace una revisión de una serie de situaciones, en distintas disciplinas y años, en las que investigadores han sido descubiertos cometiendo prácticas que atentan directamente a la ciencia (ver pp. 23-128). Las situaciones son variadas: existen casos de manipulación de imágenes, exageración de registros de laboratorio, o de plano la invención de conjuntos de datos enteros. En esta sección veremos el caso de Diderik Stapel como ejemplo de malas prácticas de investigación y plantearemos la relación que tiene con la transparencia en la investigación. El caso de Diderik Stapel Probablemente, el caso de Diderik Stapel sea uno de los más emblemáticos y representativos de este problema. Diderik Stapel era un investigador de la Tilburg University que se dedicaba al campo de la psicología social. Su carrera se caracterizó por una trayectoria ejemplar, obtuvo su M.A en psicología y comunicaciones el año 1991, se doctoró en psicología social el año 1997 y trabajó como profesor asociado primero en la University of Gronigen (2000-2006) y desde el 2006 en la Tilburg University. Fue fundador del Tilburg Institute for Behavioral Economics Research, del cuál el 2010 se convirtió en decano. Así también, fue galardonado con el premio a la trayectoria académica por la Social of Experimental Social Psychology. En breve, Stapel era una figura de alto estatus en el mundo académico, entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas científicas, algunas de las más prestigiosas (e.g. Science). Sin embargo, el año 2011 se confirmó que gran parte de su trayectoria académica era una farsa. Después de la verificación de su culpa ante acusaciones de malas prácticas, la carrera de Diderik Stapel acabó. Fue desvinculado de la Tilburg University, se le revocó su título de doctorado y toda su trayectoria académica fue investigada acusiociamente. El informe final de la investigación encontró que más de 50 de sus artículos eran fraudulentos. De hecho, Stapel está dentro de las diez figuras con más artículos retractados (58) en Retraction Watch (https://retractionwatch.com/), una plataforma que se dedica a sistematizar y mantener una lista actualizada sobre retracciones de artículos. A efectos de este escrito, lo que más destacable es que Stapel cometió conductas de mala conducta académica durante más de 15 años. La pregunta es ¿cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o coautores se dio cuenta de sus malas prácticas? Pues, la respuesta tiene que ver con el concepto central de este capítulo: por la falta de transparencia durante el proceso de investigación. Los artículos periodísticos que han profundizado en el caso han relatado parte del proceso investigativo de Stapel (e.g. Carey 2011). Dentro de los procesos de producción y análisis de datos, Stapel se caracterizaba por hacer todo el trabajo solo y a puertas cerradas. Es decir, nadie más que él tenía acceso a los datos brutos, ni tampoco a la ejecución de las pruebas estadísticas. Generalmente, Stapel compartía con sus colegas y alumnos de doctorado la base de datos lista, con las pruebas estadísticas ya hechas y, claro está, con resultados estadísticamente significativos. Estas prácticas no causaron sospechas durante muchos años, es más, a muchos de sus estudiantes les parecía una práctica normal y eficiente. Además, con el estatus de Stapel ¿qué podría estar mal? Sin embargo, era a raíz de esta práctica que Stapel tenía la oportunidad de inventar y falsificar datos a su conveniencia. Esto explica en gran parte su trayectoria académica llena de grandes hallazgos y una producción académica increíble. El caso de Stapel deja un punto importante sobre la mesa: la falta de transparencia en el proceso investigativo dio cabida a la mala conducta académica. Cómo nadie más colaboraba con el procesamiento de datos, ni tampoco parecía extraño que así fuera, las oportunidades para la falsificación de los datos estaban abiertas. Ahora, esta no es necesariamente una relación de causalidad, la falta de transparencia no tiene por qué terminar en conductas como fabricación o falsificación de datos. Sin embargo, tal y como lo argumentan OBoyle, Banks, y Gonzalez-Mulé (2017) si son una oportunidad para violaciones a la integridad científica más sutiles, tales como las QRP. Prácticas cuestionables de investigación (QRP) Comencemos desde lo general. ¿Qué son las QRP? Como vimos anteriormente, son prácticas que están en el medio del continuo de integridad en la investigación, es decir, no son ni la mejor ni la peor conducta en lo que refiere a integridad en la investigación. El principal problema de las QRP es que alteran el proceso del método científico asociado al contraste de hipótesis (Bergkvist 2020). En la literatura, existen una variedad de términos que se utilizan para describir las prácticas cuestionables (e.g. salami slicing, p_hacking), así como también distintas listas de prácticas que han emitido instituciones. Abril Ruiz (2019) hace una recopilación y traducción de distintos códigos de conducta de distintas universidades y organismos, el cuál nosotros sistematizamos en la Tabla N° 2.2. Esta tabla tiene por finalidad mostrar de una manera esquemática prácticas que alguna vez se han considerado cuestionables. Partiremos describiendo esta tabla con la finalidad de que el lector o lectora se vaya formando una idea de la amplia gama de prácticas cuestionables que existen, para luego pasar a especificar aquellas prácticas que tienen estrecha relación con la transparencia en los diseños de investigación. La sistematización que hacemos de las prácticas presentadas por Abril Ruiz (2019) se divide en cuatro dimensiones. La primera dimensión refiere a todas aquellas QRP que afectan el diseño de investigación y el procesamiento de los datos de un artículo, como por ejemplo eliminar datos después de las pruebas de hipótesis, suprimir o adicionar selectivamente variables o reformular las hipótesis para que calcen con los resultados. En cambio, la segunda dimensión apunta a los aspectos relacionados a la redacción, el reporte y la publicación de la investigación. En este apartado, podemos apreciar QRP que se relacionan al reporte selectivo de información (e.g. metodológica o de resultados) o a la forma en la que está escrito los resultados (e.g. exagerar la importancia de los resultados o tergiversar los logros de la investigación). La tercera dimensión se circunscribe al área de la propiedad intelectual y la autoría, donde las QRP tienen que ver con el uso de ideas sin dar crédito, o la asignación inapropiada de las autorías. Por último, identificamos una dimensión que tiene que ver con las relaciones con otros en el campo científico, donde las QRP se expresan en el incentivo o encubrimiento a cometer otro tipo de QRP, entre otros. Tabla 2.2: Algunas situaciones de QRP Dimensión Práctica Diseño y procesamiento Ignorar ciertos aspectos de los requerimientos de las personas participantes. Pasar por alto el uso de datos cuestionables o de interpretaciones cuestionables que otros hacen. Cambiar partes de un estudio como respuesta a la presión de una fuente de financiación Eliminar observaciones de los análisis basados en la intuición de que eran inexactos. Redondear un valor p (por ejemplo, reportar que un p-value de 0,054 es menor a 0,05) Eliminación, adición o alteración de datos después de pruebas de hipótesis. Supresión selectiva o adición de variables. Invertir la dirección o reformular hipótesis para respaldar los datos Redacción, reporte y publicación Ampliar de manera innecesaria la bibliografía de un estudio. Tergiversar los logros de la investigación. Exagerar la importancia y la relevancia práctica de los resultados. Retener detalles de la metodología de investigación (e.g. no reportar todas las variables dependientes de un estudio) Retener resultados de la investigación (e.g. no presentar datos que contradicen una propia investigación previa). Establecer publicaciones o brindar apoyo a publicaciones que no cumplen el proceso de control de calidad de la investigación Publicar los mismos datos o resultados en dos o más publicaciones. Selectivamente reportar estudios que funcionaron. Reportar hallazgos inesperados como previstos desde el principio. Afirmar que los resultados no se ven afectados por variables demográficas cuando uno no está realmente seguro (o sabe que lo hacen). Citación y autoría Manipular la autoría o denigrar el papel de otros investigadores en las publicaciones. Asignar inapropiadamente los crédios de autoría. Volver a publicar partes sustanciales de publicaciones propias anteriores, incluidas las traducciones, sin citar debidamente el original (autoplagio). Citar de forma selectiva para mejorar los propios resultados o para complacer a los editores, los revisores o los colegas. Usar ideas de otros sin obtener permiso o dar crédito Uso no autorizado de información confidencial en relación con la propia investigación. Relaciones con otros Permitir que los patrocinadores pongan en peligro la independencia en el proceso de investigación con el fin de introducir sesgos. Acusar a un investigador de conducta indebida u otras infracciones de forma maliciosa. Retrasar u obstaculizar inadecuadamente el trabajo de otros investigadores. Emplear la experiencia profesional propia para alentar a que se incumpla la integridad de la investigación. Ignorar supuestos incumplimientos de la integridad de la investigación cometidos por terceros o encubrir reacciones inadecuadas a conductas indebidas. No divulgar adecuadamente la participación en empresas cuyos productos se basan en la investigación de uno. Relaciones con estudiantes, sujetos de investigación o clientes que pueden ser interpretadas como cuestionables. No es difícil imaginar que las QRP que engloba la Tabla N° 2.2 hayan ocurrido alguna vez. Probablemente, hemos escuchado la historia de algún conocido que se vio envuelto en cualquiera de estas situaciones o nosotros hemos sido parte de alguna de estas situaciones en algún momento de nuestra carrera académica. Sin embargo, más allá de la ocurrencia anecdótica de estas situaciones, es relevante preguntarse ¿son algo que ocurre seguido? Existen una serie de estudios que han intentado medir directamente la prevalencia de estas prácticas a través de encuestas. Fanelli (2009) hizo un metaanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez (FFP) y que un 33.7% había realizado alguna vez una QRP como borrar puntos de los datos basados en un sentimiento visceral. Unos años más tarde, John, Loewenstein, y Prelec (2012) efectuaron otro estudio similar, demostrando que un 36.6% de quienes participaron alguna vez habían practicado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicólogos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipótesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Este estudio ha sido replicado en Italia (Agnoli et al. 2017), en Alemania (Fiedler y Schwarz 2016) y en Brasil (Rabelo et al. 2020). Más recientemente, han emergido estudios similares en otras áreas disciplinarias. Por ejemplo, a través de encuestas online Makel et al. (2021) logran constatar que existe una prevalencia considerable de las QRP en el campo de investigación educacional. De los participantes de la muestra un 10% admitió haber rellenado datos faltantes (NAs) y un 67% señaló alguna vez haber omitido ciertos análisis de manera intencional. Siguiendo el mismo método, en el campo de la investigación comunicacional se ha encontrado evidencia parecida: 9% de los encuestados señala haber imputado datos faltantes sin reportarlo, un 34% declaró alguna vez haber excluido casos extremos de forma arbitraria y un 60% señala no haber reportado análisis con variables clave que no funcionaron. Del mismo modo, en los estudios cuantitativos sobre criminología existe un uso extendido de las QRP: un 87% de la muestra de Chin et al. (2021) ha utilizado múltiples QRP, siendo el reporte selectivo de resultados el más común (53%). Por último, fuera del área de las ciencias sociales, pero siguiendo la misma línea, Fraser et al. (2018) también hallan evidencia a favor de la existencia de distintas QRP en el campo de la ecología y evolución. Los estudios mencionados arriba corresponden a la evidencia existente sobre la medición de QRP a través de encuestas. A modo de resumen, la Tabla N ?? elaborada por Chin et al. (2021) agrupa la información que hemos revisado (y más), ordenándose por prácticas, campos de estudio y los artículos correspondientes a cada campo de estudio. Los números dentro de las casillas representan el porcentaje de prevalencia de cada práctica reportado por los participantes del estudio, y entre paréntesis el número de casos de la muestra. Los asteriscos significan que este estudio no incluyó esa práctica en el cuestionario. Práctica Psicología Psicología Psicología Ecología Evolución Educación Comunicación John et al. (2012) Agnoli et al. (2017) Rabelo et al. (2020) Fraser et al. (2018) Fraser et al. (2018) Makel et al. (2021) Bakker et al. (2020) Omitir estudios o variables ni significativas 46 (485) 40 (217) 55 (232) * * 62 (783) 60 Subreportar resultados 63 (486) 48 (219) 22 (232) 64 64 67 (871) 64 Subreportar condiciones 28 (484) 16 (219) 35 (232) * * * * Muestreo selectivo 56 (490) 53 (221) 22 (232) 37 51 29 (806) 23 Excluir datos selectivamente 38 (484) 40 (219) 20 (232) 24 24 25 (806) 34 Excluir covariables selectivamente * * * * * 42 (773) 46 Cambiar análisis selectivamente * * * * * 50 (811) 45 HARK 27 (489) 37 (219) 9 (232) 49 54 46 (880) 46 Redondear valores p 22 (499) 22 (221) 18 (232) 27 18 29 (806) 24 Mal orientar respecto a los efectos de sociodemográficos 3 (499) 3 (223) 4 (232) * * * * Esconder problemas * * * * * 24 (889) * Esconder imputaciones 1 (495) 2 (220) 1 (232) 5 2 10 (898) 9 Cómo hemos visto en la Tabla X y en la Tabla Y, existen muchas prácticas que podrían categorizarse cómo cuestionables. No obstante, hay algunas prácticas que queremos destacar aquí dado que están relacionadas con la transparencia en los diseños de investigación. Estas son: 1) los sesgos de publicación, 2) el p hacking y el 3) HARKing. Sesgo de publicación El sesgo de publicación significa que un artículo es publicado en base a sus resultados. Específicamente, el sesgo de publicación ocurre cuando el criterio determinante para que un artículo sea publicado es que sus resultados sean significativos, en desmedro de la publicación de resultados no significativos. Un ejemplo ilustrativo que usan G. S. Christensen, Freese, y Miguel (2019) para explicar esta práctica es el cómic xkcd títulado Significant. En el comic (Figura N 2.4) se puede observar que un personaje corre gritando que las gominolas (jellybeans) causan acné, a lo que el otro personaje llama a los científicos para que prueben esta hipótesis, resultando no significativa. Ante esto, nuevamente el personaje inicial plantea que podría depender del tipo de gominola, y es aquí donde se aprecia lo ilustrativo del cómic: aparecen 20 paneles, cada uno representando una prueba de hipótesis entre una gominola de determinado color y al acné. 19 de las pruebas resultan no significativas, y una (el color verde) resulta significativa. El cómic termina con una portada con el titular de la única prueba de hipótesis que arrojó resultados significativos. Figura 2.4: Comic Significant de xkcd El cómic anterior muestra cómo es que un hallazgo de investigación sufre del sesgo de publicación. Al publicarse únicamente el resultado significativo e ignorándose los otros 19 no significativos, cualquier lector tendería a pensar que efectivamente las gominolas verdes causan acné, cuando probablemente sea una coincidencia. Rosenthal (1979) fue de los primeros trabajos en llamar la atención respecto de esta práctica, adjudicando el concepto de file drawer problem (en español: problema del cajón de archivos), el que hace alusión a los resultados que se pierden o quedan archivados dentro de un cuerpo de literatura. Desde ese estudio en adelante varios autores han contribuido con evidencia empírica sobre el sesgo de publicación. Por ejemplo, el estudio de Franco, Malhotra, y Simonovits (2014) logra cuantificar esta situación encontrando que los resultados nulos tienen un 40% menos de probabilidades de ser publicados en revistas científicas, en comparación a estudios con resultados significativos. Es más, muchas veces los resultados nulos ni siquiera llegan a ser escritos: más de un 60% de los experimentos que componen la muestra del estudio de Franco, Malhotra, y Simonovits (2014) nunca llegaron a ser escritos, en contraste al menos del 10% de resultados significativos. El principal problema del sesgo de publicación es que puede impactar en la credibilidad de cuerpos enteros de literatura. Por ejemplo, en economía se han hecho varios metaanálisis que han buscado estimar el sesgo de publicación en distintos cuerpos de literatura (e.g. Brodeur et al. 2016; Vivalt 2015; Viscusi 2014). Uno de los trabajos más concluyentes es el de Doucouliagos y Stanley (2013), quienes efectúan un meta análisis de 87 artículos de meta análisis en economía. En este trabajo encuentran que más de la mitad de cuerpos de literatura revisados sufren de un sesgo sustancial o severo. Sí bien en economía se ha avanzado mucho en este tipo de estudios, también a partir del desarrollo de distintos métodos de detección, se ha podido diagnosticar el sesgo de publicación en importantes revistas en sociología y ciencias políticas (A. S. Gerber y Malhotra 2008; A. Gerber y Malhotra 2008). P-hacking Otra práctica bastante cuestionada es el p-hacking. El p-hacking suele englobar muchas de las prácticas que vimos en un inicio, especialmente las que refieren al manejo de datos: excluir datos arbitrariamente, redondear un valor p, recolectar más datos posterior a hacer pruebas de hipótesis etc. Lo que tienen todas estas prácticas en común y lo que define el p-hacking es que se da cuando el procesamiento de los datos tiene por objetivo obtener resultados significativos. Si el sesgo de publicación afecta la credibilidad de un cuerpo de literatura, el p-hacking afecta a la credibilidad de los artículos mismos, ya que al forzar la significancia estadística la probabilidad de que en realidad estemos frente a un falso positivo aumenta. Un trabajo que da sustento a esta idea es el de Simmons, Nelson, y Simonsohn (2011), quienes calculan la posibilidad de obtener un falso positivo (error Tipo I) de acuerdo con el nivel de grados de libertad que son utilizados por parte de los investigadores. El resultado principal es que a medida que aumenta el uso de grados de libertad, la posibilidad de obtener un falso positivo aumenta progresivamente. El p-hacking también contribuye a sesgar cuerpos enteros de literatura. Para diagnosticar esto se ha utilizado una herramienta denominada p-curve, la cual describe la densidad de los p-values reportados en una literatura, aprovechando el hecho de que si la hipótesis nula no se rechaza (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1 (G. S. Christensen, Freese, y Miguel 2019, 67.). De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de valors p debería estar cargada a la izquierda (siendo precisos, asimétrica a la derecha), en cambio, si existe sesgo por p-hacking la distribución de p-values estaría cargada a la derecha (asimetría a la izquierda). Simonsohn, Nelson, y Simmons (2014) proponen esta herramienta y la prueban en dos muestras de artículos de la Journal of Personality and Social Psychology (JPSP). Las pruebas estadísticas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipótesis, especificamente: los artículos que presentaban solamente resultados con covariables resultaron tener una p-curve cargada a la derecha (asimétrica a la izquierda). HARKing Por último, pero no menos importante existe la práctica del HARKing. El nombre es una nomenclatura en lengua inglesa: Hypothesizing After the Results are Known, que literalmente significa establecer las hipótesis del estudio una vez que se conocen los resultados (Kerr 1998). El principal problema de esta práctica es que confunde los dos tipos de razonamiento que están a la base de la ciencia: el exploratorio y el confirmatorio. El objetivo principal del razonamiento exploratorio es plantear hipótesis a partir del análisis de los datos, en cambio, el razonamiento confirmatorio busca plantear hipótesis basado en teoría y contrastar esas hipótesis con datos empíricos. Como señala Brian A. Nosek et al. (2018), cuando se confunden ambos tipos de análisis y se hace pasar un razonamiento exploratorio como confirmatorio se está cometiendo un sesgo inherente, ya que se está generando un razonamiento circular: se plantean hipótesis a partir del comportamiento de los datos y se confirman las hipótesis con esos mismos datos. References "],["qué-se-ha-hecho.html", "2.2 ¿Qué se ha hecho?", " 2.2 ¿Qué se ha hecho? Tanto en las ciencias sociales, como en otras disciplinas han ido emergiendo una variedad de recomendaciones que contribuyen a la adopción de la transparencia. Por ejemplo, Crüwell et al. (2018) propone formar investigadores y estudiantes a partir de la promoción de siete principales tópicos: entender la ciencia abierta; acceso abierto; la importancia de los datos, material y código abierto, los análisis reproducibles; los pre-registros; la replicación y, por último, la enseñanza de la ciencia abierta. Cada uno de estos tópicos son un paso para lograr avanzar hacia una ciencia más abierta y transparente. De forma similar, Miguel et al. (2014) enfatiza en tres ideas: el disclosure (divulgación), los pre-registros y los datos y materiales abiertos. La divulgación consta de que los investigadores deben declarar todo tipo de procesamiento realizada a los datos y detallar como se llégó a las muestras finales. Los preregistros son una forma de ser más transparente con los procedimientos y dividir los tipos de formulación de hipótesis. Los datos y materiales abiertos permiten que otros investigadores puedan reproducir el trabajo, hacer otras pruebas de hipótesis, identificar malas prácticas etc. También Lindsay (2020) discute los efectos que tienen el sesgo de publicación y otras prácticas similares en la credibilidad de la ciencia, proponiendo siete pasos para mejorar la transparencia: decir la verdad, por ejemplo, si la idea de investigación surgió analizando datos plantearlo de esa manera; evaluar la comprensión de la estadística inferencial; estandarizar la aproximación para probar las hipótesis, por ejemplo, realizar un plan de análisis; hacer un manual de laboratorio (en el caso de diseños experimentales); hacer abiertos los materiales, datos y análisis; abordar las limitaciones de la generalidad de las conclusiones; y por último, considerar enfoques colaborativos para conducir investigaciones. A su vez, OBoyle, Banks, y Gonzalez-Mulé (2017) proponen tres simples consejos para hacer la ciencia más transparente: incluir una clausula ética en el envío de manuscritos que declaren no haber cometido QRP, qué todo artículo original (e.g. tesis doctoral) debe estar disponible para descarga y que las revistas cuenten con un espacio dedicado a replicación. Una propuesta sistemática para adoptar la transparencia, que incluye varias de las recomendaciones mencionadas son las Transparency and Openess Promotion (TOP) Guidelines (Guías para la Promoción de la Transparencia y la Accesibilidad). Estos son principios que buscan alcanzar un formato de investigación reproducible a través del aumento de la transparencia en el proceso y los productos de investigación (Brian A. Nosek et al. 2014). Estos principios sirven de guía tanto para la adopción de buenas prácticas en los investigadores, como para que las revistas académicas puedan adherir progresivamente al ideal de transparencia en la ciencia. Son ocho principios: Citación Transparencia de datos Transparencia de métodos analíticos (código) Transparencia de los materiales Transparencia del diseño y el análisis Preregistro de estudios Preregistro de planes de análisis Replicación A grandes rasgos, el principio de citación propone que las normas de citado deben ampliarse también a los datos y códigos, permitiendo reconocer su autoría intelectual (B. A. Nosek et al. 2015). Los principios de transparencia de datos, métodos analíticos, materiales y diseño y análisis (2 a 5) refieren a la transparencia en su forma más concreta: la apertura del proceso de investigación para su evaluación. El detalle puesto a los principios responde a la generalidad que se le busca dar a los principios. Por ejemplo, un estudio observacional cuantitativo no tiene material que transparentar, pero si datos y métodos analíticos. Así también, un estudio cualitativo quizás no tenga código que transparentar, pero si un diseño y una bitácora detalla del proceso de análisis. En el caso de los principios relacionados al preregistro, B. A. Nosek et al. (2015) argumenta que registrar los estudios los hace más descubribles, incluso si no son publicados. Así también, los preregistros del plan de análisis contribuyen a distinguir entre los análisis confirmatorios y exploratorios (ver Brian A. Nosek et al. (2018) para un manejo detallado del tema). Por último, el principio de replicación fomenta las oportunidades para la corrección de artículos y redirecciona la investigación en vías más prometedoras (B. A. Nosek et al. 2015). Cada uno de estos principios cuenta con tres niveles, que sirven para medir el grado de inclusión de la transparencia por parte de una revista científica (ver B. A. Nosek et al. 2015 para detalle). La adopción de prácticas transparentes va desde el nivel 1, siendo lo menos transparente, hasta el nivel 3 siendo lo más transparente. Se añade un nivel 0 que no cumple los estándares de transparencia con la finalidad de tener una comparación. Por ejemplo, para los estándares de transparencia del método de análisis (código), el nivel 1 dicta que las revistas deben solicitar la existencia del código de análisis, en cambio, el nivel 3 es más estricto en plantear que el código de análisis debe estar almacenado en un repositorio confiable y que el análisis será reproducido durante el proceso de revisión. El mismo método se puede aplicar para la el preregistro del plan de análisis. En el nivel 1 las revistas promueven el uso de preregistros, en cambio, en el nivel 3 los preregistros son obligatorios y también reconocidos. En suma, las TOP Guideliness son una iniciativa que contribuye a la apertura en la ciencia proponiendo nuevas prácticas para los requerimientos de las revistas. Como podemos ver, en general las recomendaciones sobre transparencia giran en torno a los preregistros, los datos y materiales abiertos y la replicación. En la siguiente sección profundizaremos en los preregistros como una forma de aumentar la transparencia durante el proceso de investigación. References "],["herramientas-para-los-diseños-transparentes.html", "2.3 Herramientas para los diseños transparentes", " 2.3 Herramientas para los diseños transparentes Nuestra principal apuesta para promover la transparencia en los diseños de investigación son los pre registros, por lo que es a lo que le dedicaremos más espacio del capítulo. De todos modos, también revisaremos un par de herramientas que pueden complementar el uso de pre-registros. Esperamos que, posterior a esta sección, el lector pueda ser capaz de utilizar estas herramientas para sus investigaciones. 2.3.1 Preregistros Los preregistros son una marca temporal sobre las decisiones del diseño, el método y el análisis de un artículo científico y se suelen hacer antes del levantamiento de datos (Stewart et al. 2020). Básicamente, preregistrar un artículo o un proyecto implica que un grupo de investigadores dejarán por escrito una pauta de investigación a la cual se atendrán lo más posible cuando desarrollen la investigación, especialmente la recopilación y el análisis de los datos. Ahora ¿por qué habría de hacer algo así? Llevar a cabo una investigación ya es lo suficientemente complejo como para añadirle una tarea adicional. La respuesta es que, cómo señalamos en secciones anteriores, los preregistros son una herramienta que permite hacerle frente a las QRP y, a la larga, contribuir a la realización de una ciencia de mayor calidad. Ciertamente, los preregistros no son la respuesta a cada una de las QRP existentes, pero si son una herramienta eficaz para evitar las más frecuentes. En secciones anteriores hablamos de los sesgos de publicación, el p-hacking y el HARKing pues, cada uno de ellos puede ser evitado a partir de un preregistro. Primero, vimos que el sesgo de publicación se trataba de publicar selectivamente los resultados de investigación: resultados que no hayan sido significativos, o hipótesis que no funcionaron simplemente se omiten. Sin embargo, cuando existe un documento como un preregistro, el cual deja estipulado claramente las hipótesis que deben ponerse a prueba y los análisis que se emplearan para ello, se torna más difícil reportar selectivamente los resultados. Dicho de otra forma, cuando existe una pauta a la cual apegarse, la discrecionalidad en el reporte de los resultados disminuye. En el caso del p-hacking, el efecto del preregistro es parecido. Cómo vimos, el p hacking consistía en abusar de las pruebas estadísticas para obtener resultados significativos. Abusar en el sentido de buscar toda vía posible para obtener un valor p que confirme las hipótesis planteadas. El hecho de preregistrar el plan de análisis y el procesamiento que se le efectuara a las variables permite evitar este tipo de búsqueda intencionada: como hay una guía que seguir, cualquier desviación debe ser justificada. En esta misma línea, un preregistro evita el HARKing ya que las hipótesis están previamente planteadas y no es posible cambiarlas una vez que se han visto los resultados. En suma, el plantear un registro a priori de la investigación, disminuye la flexibilidad que suele dar paso a las QRP. Si bien los preregistros pueden ser una herramienta en contra de las QRP, existen resquemores de los que es preciso hacerse cargo. Una de las principales preocupaciones es que el uso de preregistros tendería a coartar la creatividad y la producción de conocimiento exploratoria (Moore 2016). La lógica es que, como cada parte de la investigación debe ser registrada detalladamente previo a la recopilación, no queda espacio para la espontaneidad durante el análisis de datos. Nada puede estar más lejos del sentido de un preregistro. Más que inhibir la investigación exploratoria, el objetivo de especificar una pauta a priori es poder separar lo que es la investigación confirmatoria (pruebas de hipótesis) y la exploratoria (generación de hipótesis) (Brian A. Nosek et al. 2018). En ese sentido, es posible la investigación exploratoria bajo el modelo de preregistros, solo que hay que especificarla como tal. Una segunda creencia es que realizar un preregistro añade un nivel de escrutinio mayor del necesario, es decir, como se conoce cada detalle, la investigación se vuelve un blanco fácil de críticas. Sin embargo, la situación es todo lo contrario (Moore 2016), por ejemplo, haber preregistrado un plan de análisis para una regresión logística binaria con datos que originalmente eran ordinales hará más creíble los resultados, ya que quienes evalúen la investigación tendrán pruebas de que el nivel de medición no se cambió solo para obtener resultados significativos. Una tercera idea en torno a los preregistros es que conllevan una gran inversión de tiempo y energía. Si bien es cierto que se añade un paso más al proceso de investigación, el avance en la temática ha logrado que existan una variedad de plantillas que hacen el proceso más rápido y eficiente. Desde una lógica racional, el tiempo que toma este paso nuevo en la investigación es un costo bajo en contraste a los beneficios que trae. Una característica principal de los preregistros es que deben ser efectuados previo a la recolección de datos. Este requisito es lo que permite asegurar la credibilidad de los resultados, ya que, si no hay datos que alterar, entonces las probabilidades de que ocurra una QRP son básicamente nulas. Generalmente, para las ciencias médicas o la psicología experimental (disciplinas donde cada vez se usan más los preregistros), esto no suele ser un problema ya que se utilizan diseños experimentales. Los diseños experimentales se apegan al método científico clásico: se plantean hipótesis basadas en la teoría, se diseña un experimento para probar esas hipótesis y luego se recopilan y analizan los datos para ver si dan soporte a las hipótesis planteadas. Sin embargo, ¿qué ocurre cuando trabajamos con datos preexistentes? En muchas disciplinas de las ciencias sociales los diseños experimentales son una pequeña fracción del conjunto de la literatura (e.g. según Card, DellaVigna, y Malmendier 2011 en 2010, un 3% de los artículos en las mejores revistas de economía eran experimentales), donde lo que prima son los diseños observacionales, los que suelen trabajar con datos administrativos o generados a partir de censos o encuestas. A diferencia de los estudios experimentales, los cuales deben generar de primera fuente el experimento que les permita testear sus hipótesis, en los estudios observacionales se utilizan datos ya existentes, lo cual afecta al principal componente de credibilidad de los preregistros: nada puede asegurar que los datos fueron analizados antes de la escritura del preregistro y que, por ejemplo, las hipótesis se están planteando una vez conocidos los patrones significativos (HARKing). De ahí que nace la pregunta sobre la posibilidad (y la utilidad) de utilizar preregistros en estudios con datos preexistentes. En la literatura sobre preregistros se han discutido los desafíos que implica preregistrar estudios que utilicen datos preexistentes (e.g. Editors 2014). Existen posturas que proponen que, en realidad, no existe una forma creíble para preregistrar este tipo de estudios (G. Christensen y Miguel 2018). No obstante, otras posturas han profundizado en las situaciones en las que aún es posible preregistrar estudios con datos elaborados previamente. Burlig (2018) propone tres escenarios donde el preregistro de datos observacionales es valioso. El primero es, básicamente, cuando los investigadores que diseñaron la investigación generan sus propios datos, en este caso, los investigadores sí pueden elaborar un preregistro previo a la recolección de datos. El segundo escenario se da cuando se preregistra un estudio que tiene como objeto de interés un suceso que aún no ha ocurrido, lo que se conoce como estudios prospectivos. Por ejemplo, un grupo de investigadores puede estar interesado en el efecto que tendrá la introducción de una ley en las prácticas sociales, o el efecto de un tratado en las variaciones del PIB. Para esos casos, el preregistro aún mantiene su validez original ya que, si bien los datos ya existen, no es posible hacer los análisis antes del preregistro porque el evento de interés no ha ocurrido. El tercer escenario ocurre cuando los datos existen, pero no están abiertos al público. En estos casos, es la accesibilidad lo que determina la credibilidad del preregistro. Por ejemplo, el grupo de investigadores que elaboraron los datos pueden establecer que serán accesibles con previo contacto y que se solicitará un preregistro. Por ende, en orden de analizar los datos, los investigadores interesados deberán elaborar un preregistro para utilizar los datos. Según Mertens y Krypotos (2019), también se pueden adoptar ciertas prácticas para asegurar la credibilidad de un preregistro con datos secundarios. Dos de ellas son: que el grupo de investigadores que analiza los datos sea distinto e independiente de quien propuso el diseño de investigación y que el equipo realice sintaxis de análisis con datos simulados, con tal de demostrar que las hipótesis ya existían previas a acceder a los datos. En suma, lo que permite mantener el efecto puro de un preregistro, es que los datos no hayan sido observados por ningún integrante del grupo de investigación que los analizará (Brian A. Nosek et al. 2018). El principio básico de un preregistro entonces es que los datos no deben haber sido observados previos al análisis. Sin embargo, según Brian A. Nosek et al. (2018) aún pueden existir ciertos sesgos en el planteamiento de hipótesis a raíz de cosas como el reporte de resultados descriptivos de la base de datos o las recomendaciones sobre cómo aproximarse a la base de datos. Este tipo de influencias son un poco más sutiles y es difícil deshacerse completamente de ellas. Es por esto que, quizás la recomendación más transversal y a la vez simple para preregistrar análisis con datos secundarios, es ser sincero y detallado respecto a lo que se ha hecho y lo que no (Brian A. Nosek et al. 2018). Si es que se ha leído el reporte descriptivo sobre la base de datos, estipularlo como tal. Es preciso transparentar cualquier tipo de aproximación a los datos previo haberlos analizados. Para lograr este nivel de detalle y ser eficiente con los tiempos y la comunicación hacia otros investigadores, es que existen plantillas predeterminadas para preregistrar distintos tipos de artículos. A continuación, describiremos algunas de las más usadas. 2.3.2 Manos a la obra: cómo utilizar un preregistro En la práctica, preregistrar un artículo es básicamente sintetizar la información importante sobre nuestra investigación en una plantilla estandarizada y alojar ese documento en un lugar público. Por lo que el primer paso para elaborar un preregistro es elegir la plantilla correcta. Existen plantillas estandarizadas, que están estructuradas de tal forma que son útiles para preregistrar estudios de cualquier disciplina, así como también existen plantillas dedicadas a una disciplina o un conjunto de ellas. En la Tabla N° 2.3 se pueden ver algunas de las plantillas más usadas según Stewart et al. (2020). Primero está el conjunto de plantillas que ofrece el Open Science Framework (OSF) dependiendo de las características específicas del estudio. Luego, encontramos a la plantilla de AsPredicted que se caracteriza por su simpleza: son solo nueve preguntas que buscan recopilar la información sustancial para el preregistro de un artículo. También, están las plantillas de PROSPERO, ISRCTN y Bio-Protocol que se utilizan más en el campo de las ciencias biológicas o médicas. PROSPERO se focaliza en artículos de tipo review que tengan relación con la medicina, en tanto IRCTN busca ser una primera instancia de registro para ensayos clínicos. Bio-Protocol por su parte busca dejar el registro de protocolos detallados en la investigación biológica, con tal de complementar la sección de Método en los artículos. Las plantillas de AEA RCT, RIDIE y EGAP están más relacionadas a las ciencias sociales y áreas afines. La AEA RCT se focaliza en diseños experimentales para ciencias sociales, en tanto RIDIE es una herramienta para evaluaciones de impacto. EGAP busca ser una plantilla específica para temas de gobernanza y política. Como podemos ver, todas las plantillas tienen su campo de aplicación, sin embargo, aquí nos centraremos en las dos más universales y conocidas: OSF y AsPredicted. Tabla 2.3: Plantillas de preregistro Plantilla Proposito Discplina/Área Open Science Framework (OSF) Pre-registration Múltiples plantillas para preregistrar una amplia gama de estudios Cualquiera AsPredicted Plantilla de preregistro estandarizada Cualquiera PROSPERO Registros de protocolos de estudio para revisiones sistemáticas con un resultado relacionado con la salud Salud y asistencia social, bienestar, salud pública, educación, delincuencia, justicia y desarrollo internacional International Standard Randomised Controlled Trials Number (ISRCTN) Registro de ensayos clínicos primarios reconocido por la OMS y el ICMJE Cualquier estudio de investigación clínica Bio-Protocol Revista de protocolos en línea revisada por pares que pone a disposición de los interesados protocolos detallados en línea Ciencias biológicas American Economic Association Registry For Randomized Controlled Trials (AEA RCT) Registro de ensayos controlados aleatorios Economía, ciencias políticas y otras ciencias sociales Registry for International Development Impact Evaluations (RIDIE) Registro prospectivo de evaluaciones de impacto de políticas y programas de desarrollo en países de renta baja y media Ciencias sociales Evidence in Governance and Politics (EGAP) Registro de experimentos y estudios de observación Gobernanza y política Como bien se ha señalado en otras partes de este libro, el Open Science Framework (OSF) es tanto una herramienta para la colaboración, que permite hacer públicos distintos tipos de proyectos; como un modelo de flujo de trabajo que hace más eficiente el proceso de investigación al centralizar herramientas como GitHub, Google Docs etc. Dentro de estas funciones se encuentra la el servicio de preregistros. En la línea de lo que hemos señalado hasta ahora, con este servicio OSF busca fomentar la transparencia y reproducibilidad en la investigación. Vamos viendo paso a paso como ingresar un preregistro en OSF. El primer paso es acceder a la sección especifica de preregistros de la página de OSF, la cual se encuentra en el siguiente link: https://osf.io/prereg/. Para usar este servicio es necesario tener una cuenta, cuestión que no profundizaremos aquí. Si entramos al link con una cuenta recién hecha, la apariencia de la página será algo como la Figura N° 2.5. En la página veremos una barra superior con opciones asociadas a la cuenta y en el centro veremos un gran botón azul con forma rectangular el cual nos da la opción de comenzar un preregistro. En el caso de acceder con una cuenta que ya tiene proyectos, OSF nos dará la opción de preregistrar un proyecto ya existente. Seleccionemos Start a new preregistration, le damos un nombre y hacemos click en Continue, lo que nos llevará a la siguiente página, representada en la Figura N° 2.6. En la página, podemos ver que hemos creado un proyecto nuevo en OSF, el cual nos da la opción de preregistrarlo haciendo click en el botón New registration. Figura 2.5: Preregistros en OSF Figura 2.6: Preregistros en OSF 2 En la Figura N° 2.7 podemos ver dos cosas. Primero, la descripción de lo que está haciendo OSF al comenzar un nuevo preregistro, lo que en pocas palabras es una versión no modificable del proyecto al momento que hacemos el preregistro. Tal y como dice la página es una versión congelada. En segundo lugar, también se aprecia una serie de opciones para preregistrar, estas son las plantillas que habíamos mencionado anteriormente. OSF nos ofrece distintas plantillas de acuerdo con el carácter que tiene nuestro estudio. Una breve descripción de cada una es la siguiente: OSF Preregistration: Es la plantilla estándar, en la cual se hacen una serie de preguntas relativas al muestreo, diseño y planes de análisis. Open-Ended Registration: Consiste en una síntesis narrativa de la investigación a preregistrar. No hay un minimo de palabras para el documento. Qualitative Preregistration: Plantilla elaborada por la comunidad de investigadores cualitativos para preregistrar estudios cualitativos. Secondary Data Preregistration: También consiste en una serie de preguntas relativas al muestro, diseño y planes de análisis, con algunas pequeñas variaciones. Registered Report Protocol Preregistration: Hace unas cuantas preguntas relativas al estudio y permite adjuntar el manuscrito. Esta plantilla se utiliza cuando se está intentando publicar en una revista que adhiere al modelo de Registered Reports. OSF-Standard Pre-Data Collection Registration: Plantilla que sigue el modelo estándar, pero que agrega algunas preguntas más específicas sobre recolección de datos. Por ejemplo, pregunta si la recolección de datos está en curso o si se ha hecho algún análisis de los datos hasta ahora. Preregistration Template from AsPredicted.org: Plantilla estandarizada de AsPredicted. Simplifica el proceso de preregistro en 9 preguntas clave sobre el estudio. Replication Recipe (Brandt et al., 2013): Post-Completion: Se trata de una plantilla para estudios de replicación, específicamente estudios que ya finalizaron. Replication Recipe (Brandt et al., 2013): Pre-Registration: Se trata de una plantilla para estudios de replicación que aún no han comenzado. Pre-Registration in Social Psychology (van t Veer &amp; Giner-Sorolla, 2016): Pre-Registration: Plantilla de preregistro para estudios específicamente de la subdisciplina Psicología Social. Figura 2.7: Preregistros en OSF De todas estas plantillas veremos el detalle de tres de ellas: OSF Preregistration, Secondary Data Preregistration y Preregistration Template from AsPredicted.org. Una vez escojamos una plantilla, la página se verá como la Figura N° 2.8. Esta sección es transversal a todas las plantillas y consiste en el registro de los metadatos. Específicamente, OSF nos solicitará que registremos: Título del preregistro Una breve descripción Contribuyentes La categoría. Generalmente está en categoría Project, pero dependiendo de lo que estemos preregistrando, podemos cambiarlo a Data, Software, Analysis, entre otros. Areas discplinares, como Arts and Humanities, Business, Social and Behavioral Sciences entre otras. Tags. Los tags sirven para facilitar la búsqueda del preregistro Figura 2.8: Metadatos para preregistros 2.3.2.1 OSF Preregistration Esta plantilla incluye ocho tópicos para rellenar con la información del estudio, estos son: Información del estudio: Principalmente solicita listar de forma concisa y detallada las hipótesis que serán puestas a prueba. Se solicita reportar si la hipótesis es direccional o no, y en el caso de serlo, especificar el sentido de la dirección. Si el estudio incluye moderaciones o mediaciones, plantearlas en hipótesis aparte. Plan del diseño: En esta sección se hacen cuatro preguntas importantes. La primera es sobre el tipo del estudio, donde se solicita especificar si el estudio es de tipo experimental, observacional, un metaanálisis u otro. En segundo lugar, está el blinding, el cual trata sobre quienes están en conocimiento de las condiciones de tratamiento en el caso de un diseño experimental. En el caso de un diseño experimental no aplica. En tercer lugar, se pregunta sobre el diseño del estudio, donde se solicita la mayor cantidad de detalles posibles respecto a este tópico. Por último, se solicita especificar cuál será el tipo de aleatorización (en el caso de un diseño experimental). Plan del muestreo: En esta sección, la plantilla requiere rellenar información respecto a la existencia de datos, los procedimientos de recolección de datos y sobre el tamaño de la muestra. En el caso de la existencia de datos, se nos solicita que marquemos de las siguientes situaciones la que más se acerca al estado de nuestro estudio: Registro previo a la creación de datos Registro previo a cualquier observación humana de los datos Registro previo a acceder a los datos Registro previo al análisis de los datos Registro tras el análisis de los datos En el caso de trabajar con datos existentes la plantilla da una opción para detallar los pasos necesarios que se han tomado para asegurar que no conocemos el comportamiento de los datos. Por ejemplo, cómo es que se ha limitado la accesibilidad de los datos, o quiénes han revisado los datos y quienes no. En lo que respecta a los procedimientos de análisis, la plantilla solicita especificar cómo es que se han recolectado los datos y cuáles han sido los criterios de exclusión. En el caso de muestras que involucren seres humanos, se deben reportar todo tipo de incentivos a la participación. Por último, se pregunta por el tamaño de muestra y si se ha realizado algún análisis de poder estadístico Variables: En esta sección se preguntan tres cosas. La primera es sobre, en el caso de los estudios experimentales, cómo se manipularán los niveles de tratamiento de las variables. Segundo, la plantilla requiere especificar cómo es que se medirán las variables, tanto la variable dependiente como los predictores. En tercer lugar, en el caso de construir índices, se pide detallar lo más posible su construcción. Plan de análisis: En esta sección se busca el mayor detalle posible para le plan de análisis con tal de que sirva de guía para la reproducción o replicación del artículo. Partiendo por los modelos estadísticos, la plantilla solicita especificar la herramienta principal de análisis de datos (e.g. regresión múltiple) en conjunto a las variables que se incluirán (dependientes, independientes, controles, términos de interacción etc.). Otro componente importante para especificar son las transformaciones a los datos, incluyendo recodificaciones, centrados o cualquier procedimiento que cambie el formato original de la variable. También, la plantilla solicita especificar cuáles serán los criterios de inferencia estadística (e.g. valores p o intervalos de confianza). Por último, la plantilla requiere especificar cómo se determinará la exclusión de datos, cómo se trabajarán los datos perdidos y detallar los análisis exploratorios en caso de que existiesen. Otro: Esta es la última sección de la plantilla, donde se da la opción al investigador o investigadora de añadir cualquier información importante que hasta ahora no ha sido reportada. 2.3.2.2 Secondary Data Preregistration Esta plantilla es similar a la que acabamos de revisar, la principal diferencia es que está enfocada en el preregistro de datos secundarios, por lo que todas las opciones que veíamos en la plantilla general de OSF que hacían referencia a datos primarios ya no existen. Recomendamos esta plantilla a investigadores que usen datos secundarios ya que hace más simple el proceso de preregistro al enfocarse en las preguntas que realmente se asemejan a la situación del investigador. La plantilla se compone de siete puntos. El primero también consiste en especificar los metadatos del estudio, como por ejemplo en nombre del proyecto, el área del conocimiento en el que se circunscribe etc. Información del estudio: Básicamente implica especificar las preguntas y las hipótesis que orientan el estudio. Descripción de los datos: Esta sección es característica de esta plantilla, ya que nos pregunta directamente sobre características de la base de datos a utilizar. En detalle, recaba información sobre el nombre de la base de datos, una descripción general de ella y cuál será el subconjunto de datos en caso de que corresponda. También se solicita especificar qué tipo de base de datos es (e.g. longitudinal), si es que existen restricciones para el acceso y describir el procedimiento de elaboración de la base de datos. Por último, se nos solicita adjuntar el libro de códigos correspondiente y si este no existe, adjuntar cualquier archivo de la base de datos que permita conocer su composición. Variables: En esta sección las preguntas no son muy distintas de la plantilla que acabamos de revisar. En general, se solicita especificar la manipulación de las variables (no aplica para estudios observacionales), la forma de medición de las variables, la unidad de análisis y cuáles serán los procedimientos para tratar con casos perdidos y extremos. Conocimiento de los datos: Esta sección es característica de esta plantilla. A grandes rasgos, se nos pide dos cosas. Primero, que listemos los documentos con los cuales hayamos trabajado y que estén basados en la base de datos que utilizaremos (e.g. publicaciones, working papers, presentaciones de conferencia). Segundo, reportar cualquier conocimiento previo que tengamos del uso de la base de datos, especialmente las variables que sean relevante para el análisis propuesto. Este conocimiento de la base puede venir de publicaciones previas, de reportes de resultados o del libro de códigos, por dar algunos ejemplos. Análisis: En esta sección se pregunta sobre toda característica de nuestro análisis de datos, partiendo por el tipo de modelos estadístico que utilizaremos para probar las hipótesis. Se nos solicita que por cada hipótesis detallemos la herramienta de análisis. Luego, se nos preguntan detalles cómo: el tamaño de efecto de interés para nuestro análisis, el poder estadístico, los criterios de inferencia (e.g. valores p o factores bayesianos), las pruebas de robustez que se efectuarán y si es que realizaremos algún tipo de análisis exploratorio. 2.3.2.3 AsPredicted La plantilla de AsPredicted es quizás una de las más conocidas para hacer preregistros, dado que está estandarizada y puede ser utilizada en cualquier disciplina. Esta plantilla la podemos encontrar tanto en OSF, como en la misma página de AsPredicted, en este caso, mostraremos cómo es el proceso en la página original. Partimos por entrar a la página de AsPredicted, donde veremos algo como la Figura N° 2.9. Acá se nos da la opción de crear un preregistro, de ver los que ya hemos hecho (si es que ese es el caso) y también una breve descripción de AsPredicted. A grandes rasgos, la página nos dice que AsPredicted es una plataforma que busca facilitar el preregistro de estudios por parte de los investigadores a través de nueve simples preguntas. La página genera un documento .pdf y una URL asociada. También, cuenta cómo funciona el preregistro. Básicamente, un autor elabora un preregistro de un estudio y los coautores reciben un mail para aprobar ese preregistro. Una vez aprobado por todos los autores, el preregistro queda alojado en la plataforma de manera privada, y no cambia hasta que un autor decida hacerlo público. Además, en caso de que el estudio entre en revisión por pares, se puede enviar una versión anónima del preregistro. Por último, nos entrega una recomendación sobre qué hacer en el caso de que el proceso de investigación no haya podido apegarse totalmente a lo predicho. Figura 2.9: Página de inicio de AsPredicted Para elaborar un preregistro debemos hacer click en el rectángulo azul que dice Create. Una vez hecho eso, nos pedirá una dirección de email para continuar. Cuando ingresemos un email, nos enviará un enlace al email que hayamos ingresado, con ese enlace podremos comenzar el preregistro. Una vez hayamos entrado en el enlace, veremos la plantilla de preregistro. Lo primero que aparece es una sección donde debemos escribir los emails de los autores colaboradores del estudio. También, nos da la opción de añadir otros emails además del que hemos introducido. Una vez pasada esta parte, ya nos encontramos con las preguntas del preregistro, las cuales son las siguientes: Recogida de datos. ¿Se han recogido ya datos para este estudio? Hipótesis. ¿Cuál es la pregunta principal que se plantea o la hipótesis que se pone a prueba en este estudio? Variable dependiente. Describa la(s) variable(s) dependiente(s) clave especificando cómo se medirán. Condiciones. ¿Cuántos y qué condiciones se asignarán a los participantes? Análisis. Especifique exactamente qué análisis realizará para examinar la pregunta/hipótesis principal. Valores atípicos y exclusiones. Describa exactamente cómo se definirán y tratarán los valores atípicos, así como su(s) regla(s) precisa(s) para excluir las observaciones. Tamaño de la muestra. ¿Cuántas observaciones se recogerán o qué determinará el tamaño de la muestra? Otros. ¿Hay algo más que quiera preinscribir? Nombre. Poner un título a este preregistro de AsPredicted Finalmente. A efectos de registro, indíquenos el tipo de estudio que está preinscribiendo. Las preguntas son bastante auto explicativas, pero no está de más entregar algunos detalles adicionales. En la pregunta de recolección de datos, las opciones son tres: Sí, se han recolectado datos, No, no se han recolectado datos y Es complicado. Es importante mencionar que, en esta plantilla, la respuesta de que se han recolectado datos no es válida, por lo que si se está llevando a cabo un estudio con datos secundarios hay responder Es complicado y en la pregunta 8 de la plantilla especificar por qué este preregistro sigue siendo válido pese a que los datos son preexistentes. Otro detalle importante es que cada pregunta está pensada para ser respuesta en aproximadamente una oración. Esta plantilla tiene el objetivo de ser lo más eficiente posible, por lo que, en general, se recomienda que todo el documento no pase de los 3200 caracteres. Otro detalle que especificar es que la pregunta acerca del tipo de estudio que se está preregistrando también es semicerrada, tenemos las opciones de: Proyecto de clase, Experimento, Encuesta, Estudio observacional y Otro. Es responsabilidad de quien hace el preregistro el seleccionar la opción que más se asemeje a su situación. Por último, es importante señalar que el preregistro, al menos en la página de AsPredicted, solo puede ser rellenado en inglés, por lo que en caso de utilizar otro idioma solicitará traducirlo. 2.3.3 Otras herramientas Sí bien los preregistros son una de las herramientas que más ha ido tomando protagonismo para promover la transparencia, existen otras. Específicamente, queremos mencionar dos de ellas: el modelo de registered reports (informes registrados) y la transparency checklist (lista de transparencia). Informes registrados El modelo de informes registrados es una alternativa al modelo tradicional de publicación. Consiste en que el artículo atraviesa una revisión por pares en etapas tempranas de la investigación, específicamente previo a la recolección de datos. Esta práctica tiene por objetivo que el estudio sea evaluado por su innovación y calidad del diseño de investigación, más que por resultados impactantes (Chambers et al. 2015). Además, busca dejar sin efecto prácticas cómo el sesgo de publicación, p-hacking y HARKing, ya que no solamente existe una marca temporal que avala el diseño de investigación del estudio (cómo es el caso de un preregistro), sino que también existe un grupo de científicos anónimos que están de acuerdo con que el artículo es un aporte al conocimiento (Chambers 2013; Brian A. Nosek y Lakens 2014; Marsden et al. 2018). Los informes registrados tienen dos características principales (Marsden et al. 2018). Primero, un manuscrito con la justificación del estudio, lo que incluye una introducción, revisión de antecedentes y una pregunta de investigación, dando la posibilidad de una aceptación preliminar (IPA, por sus siglas en inglés In principle acceptance). La segunda característica es que el IPA no puede revocarse en base a los resultados del estudio, esto evita que trabajos con resultados no significativos no sean publicados y así combatir el sesgo de publicación. Relacionado a ambas características, los informes registrados pasan por dos etapas de revisión, la primera es la del manuscrito, siendo este el determinante sí el estudio se acepta o no, y la segunda revisión que se da posterior a terminar la recolección y análisis de datos. El modelo, en comparación al sistema tradicional de publicaciones, se puede ver en la Figura N° 2.10. Figura 2.10: Método convencional y de informes registrados para publicación cientifica Para enviar un artículo bajo el modelo de informes registrados, primero se debe tener en conocimiento de cuáles son las revistas que cuentan con este tipo de revisión. El Center for Open Sciences cuenta con una lista actualizada de revistas aquí. Una vez escogida una revista, el proceso no es tan distinto al método convencional, en el sentido de que los investigadores envían su manuscrito con la justificación del estudio y este puede ser aceptado o rechazado por el editor, ya sea directamente o después de la corrección de algunos comentarios. Una vez se cuenta con el IPA y se efectúa la revisión en la segunda etapa, los revisores se aseguran de que el estudio ha seguido el plan de análisis inicialmente planteado y sí sus conclusiones tienen sentido de acuerdo a los datos y resultados obtenidos, así cómo también que toda desviación del plan original sea debidamente justificada (Stewart et al. 2020). Desviaciones muy sustanciales y/o que no sean debidamente justificadas pueden conllevar el rechazo del artículo, aunque puede seguir el proceso en el método convencional de publicación (Stewart et al. 2020). Una planilla para la elaboracion de informes registrados se puede ver aquí Lista de transparencia La lista de transparencia es una herramienta complementaria elaborada por Aczel et al. (2020) que busca acompañar el proceso de reportar un estudio, contribuyendo a que estos sean más transparentes. Esta lista ha sido elaborada específicamente para investigadores de las ciencias sociales y del comportamiento que trabajan con datos primarios, aunque puede ser útil para otros enfoques y disciplinas. La lista consta de 36 ítems divididos en cuatro categorías: preregistro, método, resultados y discusiones y accesibilidad de datos, donde cada ítem refiere a alguna característica de un reporte transparente, preguntando sí ha sido efectuada o no, o sea, las respuestas posibles de cada ítem son Sí, No y N/A. Existe una versión más corte de 12 items, los cuales son los siguientes: Sección de preregistro: Antes de analizar el conjunto completo de datos, se publicó un prerregistro con sello de tiempo en un registro independiente de terceros para el plan de análisis de datos. El estudio fue registrado antes de que cualquier dato fuera recolectado después de que algunos datos fueron recolectados, pero antes de explorarlos después de que todos los datos fueron recolectados, pero antes de explorarlos después de explorar los datos, pero antes de que cualquier análisis estadístico fuera efectuado después de efectuar algunos análisis estadísticos, pero no todos en otro momento, explicar: El análisis estadístico previsto para cada pregunta de investigación (esto puede requerir, por ejemplo, información sobre la unilateralidad de las pruebas, los criterios de inferencia, las correcciones para pruebas múltiples, los criterios de selección de modelos, las distribuciones previas, etc.). Sección de método El manuscrito describe completamente la justificación del tamaño de la muestra utilizado (por ejemplo, un análisis de potencia a priori). el diseño, los procedimientos y los materiales del estudio para permitir una réplica independiente. las medidas de interés (por ejemplo, la amabilidad) y sus operacionalizaciones (por ejemplo, un cuestionario que mide la amabilidad). ¿algún cambio en el prerregistro (como cambios en los criterios de elegibilidad, en los límites de pertenencia al grupo o en los procedimientos experimentales)? Sección de resultados y discusión El manuscrito distingue explícitamente entre la confirmación (es decir, preestablecido) y exploratorio (es decir, no preestablecidos). Sección de disponibilidad de datos, código y materiales Se han hecho públicas las siguientes los datos (procesados) en los que se han basado los análisis del manuscrito. todo el código y el software (que no esté protegido por derechos de autor). todas las instrucciones, los estímulos y los materiales de las pruebas (que no estén protegidos por derechos de autor). El manuscrito incluye una declaración sobre la disponibilidad y localización de todos los elementos de la investigación, incluidos los datos, materiales y códigos pertinentes para su estudio. Tanto la versión completa de 36 ítems, cómo la recortada de 12 están disponibles para rellenar en línea. Aquí se puede encontrar la lista online, es una aplicación de uso simple, además que permite generar el reporte final de manera automática. References "],["reproducibilidad.html", "Capítulo 3 Reproducibilidad", " Capítulo 3 Reproducibilidad ¿Cuántas veces nos hemos enfrentado a un trabajo publicado que no comparte sus materiales, y que por tanto, es imposible acceder a los procedimientos que dieron luces de sus resultados? En el marco de la denominada crisis de la ciencia, la comunidad científica se ha organizado para dar salida a este problema a través de una diversidad de iniciativas que, a modo general, buscan promover los principios de la ciencia abierta. En este sentido, dichas iniciativas han puesto sus esfuerzos en contribuir con herramientas que permitan dar salida a los problemas en torno a la transparencia de los procesos de investigación y la reproducibilidad en la investigación empírica. En este apartado, revisaremos cómo ha sido entendido este problema y luego se presentarán las propuestas de tres iniciativas en torno a cómo abordar la transparencia y la reproducibilidad en las ciencias sociales empíricas. "],["qué-es-la-reproducibilidad.html", "3.1 ¿Qué es la reproducibilidad?", " 3.1 ¿Qué es la reproducibilidad? En la discusión sobre los problemas de transparencia en torno a los procedimientos de investigación, se vuelve necesario precisar de qué manera es entendido el concepto de reproducibilidad en la ciencia. En esta línea, la laxitud en que ha se ha empleado el término ha llevado a definiciones poco claras, lo cual ha generado una tendencia a confundir lo que refiere a la transparencia de un proceso único que ya ha sido realizado, con un proceso nuevo y que puede realizarse de manera reiterativa, obteniendo los mismos resultados. Por este motivo, esta sección propone dar luces respecto a cómo entendemos el concepto de reproducibilidad, en contraste con el replicabilidad en la ciencias sociales. La discusión en torno a cómo se entiende la reproducibilidad, habitualmente lleva al contraste respecto al concepto de replicabilidad. Al respecto Earth y Behavioral (2019) menciona que con el incremento de las herramientas computacionales a principios de los años 90, el término de investigación reproducible era concebido como las investigaciones que proveían un compendio detallado de la documentación, código y datos que permitieran obtener los mismos resultados publicados por los autores, enfatizando que los análisis fueran transparentes y claros con el objetivo de ser verificados por sus pares. Por otro lado, los autores sostienen que en otras disciplinas, el concepto de reproducibilidad era asociado a investigaciones independientes entre sí en términos de los datos empleados, los materiales, métodos e implementación de un estudio, lo cual estaría orientado a robustecer o cuestionar la evidencia previa (Earth y Behavioral 2019, pp 33-34). Actualmente, a esta práctica se la entiende como replicabilidad de una investigación y no debe ser confundida con el concepto de reproducibilidad (Barba 2018). Barba (2018) sugiere que la confusión entre reproducibilidad y replicabilidad ha contribuido a obstaculizar las prácticas en ambas dimensiones. En una revisión reciente realizada por la autora se han identificado al menos tres escenarios o versiones de cómo se entienden ambos conceptos en una amplia gama de disciplinas que van desde las ciencias sociales hasta estudios clínicos en las ciencias médicas. El primer escenario (A), y a la vez el más común, es donde el uso de ambos conceptos es indistinto, contribuyendo a la ya mencionada confusión. El segundo escenario (B1) es cuando la reproducibilidad es entendida como la situación que los datos originales y el código de análisis son empleados para regenerar los resultados originales, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes utilizan datos nuevos para obtener los mismos resultados que la investigación previa. Finalmente, un tercer escenario (B2) es cuando la reproducibilidad es entendida cuando investigadores o equipos independientes obtienen los mismos resultados empleando sus propios datos y métodos, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes llegan a los mismos resultados empleando los artefactos digitales1 originales del autor con menores o mayores modificaciones, los cuales han sido puestos previamente a disposición de sus pares. La Figura 3.1 ilustra cómo podemos entender los escenarios B1 y B2 en relación a la distinción entre reproducibilidad y replicabilidad. El color rojo, tanto en los datos como en los métodos, indica que los componentes empleados son idénticos a los del estudio original. Por otro lado, el color azul, indica que tanto los datos como los métodos son distintos a los del estudio original. Finalmente, el color morado en los métodos se entiende como un punto intermedio y refiere cuando se han empleado métodos que siguen las indicaciones del estudio original, pero que han incorporado modificaciones, nuevos métodos u otras innovaciones metodológicas (p. ej. métodos nuevos, pruebas robustez u otros). Figura 3.1: Escenarios B1 y B2 en reproducibilidad y replicabilidad. En las ciencias sociales, el debate en torno a la investigación reproducible y la replicabilidad no ha estado ausente. Como fue reseñado en la sección anterior, existen casos icónicos en torno a prácticas cuestionables de investigación que han afectado la confianza en la investigación científica, lo cual ha contribuido a incrementar los esfuerzos por una ciencia social abierta y reproducible (Breznau 2021; B. A. Nosek et al. 2015). En los tres escenarios descritos por Barba (2018), las ciencias sociales han experimentado de manera diversa el ajuste hacia una cultura de mayor apertura y precisión en torno a los problemas de la crisis de reproducibilidad, principalmente a través del estudio sistemático de dicha problemática, dentro de lo cual la psicología ha sido un pionera en proveer evidencia para este debate (Open Science Collaboration 2015; Gilbert et al. 2016). Al respecto Bishop (2019) sostiene que una de las principales amenazas para el progreso de la ciencia en general ha sido a la falta de reproducibilidad de los resultados (irreproducibility), lo cual ha afectado principalmente la robustez y credibilidad de la evidencia reportada por las investigaciones, problema que también ha sido identificado en las ciencias sociales, principalmente por la falta de precisión en los procedimientos y las barreras de acceso a materiales clave del proceso de análisis (Freese y Peterson 2017). Entonces, retomando la distinción clave entre lo que entendemos por reproducibilidad y replicabilidad, en su revisión, Barba (2018) sugiere que una manera de entender y distinguir ambos conceptos de manera minimalista puede descansar en el carácter de los datos y los métodos. Al respecto B. A. Nosek et al. (2015) sostiene que en lo que refiere a estas dos dimensiones, los niveles en que una publicación los incorpora es gradual y puede entenderse como un continuo o espectro (R. D. Peng 2011), y por tanto, el nivel en que se cumplen con determinados criterios nos permite definir el carácter de una investigación en términos de su reproducibilidad. Por ejemplo, la Figura 3.2 nos muestra cómo podemos caracterizar una investigación publicada en torno al acceso y vinculación entre código y datos. Por un lado, se observa que en el polo donde únicamente disponemos de la publicación, se entiende como la ausencia de reproducibilidad. Por otro lado, en la medida que incrementa el acceso a los materiales, y se explicita el enlace entre ellos, se puede caracterizar a una publicación como reproducible.2 Figura 3.2: Espectro de Reproducibilidad. Traducción propia en base a R. D. Peng (2011) Como sugiere B. A. Nosek et al. (2015), el problema de la ausencia o falta de reproducibilidad debe ser abordado a través de un cambio en las prácticas de investigación, para lo cual se requiere, por un lado, de una disposición por parte de la comunidad científica, es decir a que se le atribuya un sentido positivo a estas prácticas. Sin embargo, R. D. Peng (2011) sostiene que una de las principales barreras para promover estas prácticas ha sido la falta de mecanismos que faciliten la distribución de la investigación reproducible, como también la poca claridad respecto de los estándares asociados a ello. Siguiendo esta autocrítica de algunos sectores dentro de la comunidad científica, dentro de los últimos años han surgido iniciativas, por ejemplo, como el Open Science Framework, al alero del Center for Open Science, desde donde se busca contribuir con herramientas para el entrenamiento y educación de la comunidad científica en general, como también proveer de una infraestructura tecnológica que facilite la transición cultural hacia una ciencia abierta, transparente y reproducible (B. A. Nosek et al. 2015). Por este motivo, proponemos revisar tres iniciativas internacionales que han puesto sus esfuerzos en la promoción de estos principios, con particular atención en la transparencia y reproducibilidad de la investigación científica, y en particular de las ciencias sociales empíricas cuantitativas. Dentro de estas iniciativas encontraremos esfuerzos orientados a la educación y entrenamiento, herramientas tecnológicas y fortalecimiento de redes de colaboración. References "],["qué-se-ha-hecho-1.html", "3.2 ¿Qué se ha hecho?", " 3.2 ¿Qué se ha hecho? 3.2.1 Berkeley Initiative for Transparency in the Social Sciences Objetivos y visión Esta iniciativa busca promover la credibilidad en la evidencia generada por las ciencias sociales a través de mecanismos de avanzada para la transparencia, reproducibilidad y prácticas éticas en la investigación social empírica. Desde esta premisa, ha desarrollado y puesto a disposición de la comunidad científica una serie de herramientas en colaboración con estudiantes, investigadores, entidades académicas y fundaciones de la sociedad civil al alero de tres principios orientadores. Generar evidencia en torno a problemas y soluciones a través de los investigadores y la comunidad de BITSS quienes han liderado investigaciones meta-analíticas con atención en las ciencias sociales. Incrementar el acceso a la enseñanza de la ciencia abierta, a través del fortalecimiento de prácticas para reconocer y conducir investigación social transparente y reproducible a través del entrenamiento de investigadores jóvenes, acceso a materiales, apoyo financiero y la consolidación de una red de colaboración. Fortalecer el ecosistema científico, estableciendo condiciones para investigadores e instituciones para contribuir a un cambio efectivo y equitativo en las normas que permitan una consolidación de una política interna orientada a la ciencia abierta y al desarrollo de protocolos en esta dirección. Como se ha señalado, esta iniciativa se orienta bajo estos tres ámbitos o principios. Desde sus inicios, se han desarrollado una serie de componentes que buscan promover y dar soluciones a los problemas de transparencia y reproducibilidad en las ciencias sociales. En particular, nos interesa destacar algunas de las contribuciones en este ámbito que serán presentadas a continuación las cuales se pueden resumir en Evidencia, Educación y Recursos. Contribución En el ámbito de Evidencia, desde BITSS se ha realizado un esfuerzo por producir y sistematizar evidencia centralizadamente. En este contexto existe la Research Library, una base de datos de publicaciones científicas que engloba una serie de investigaciones meta-analíticas en el ámbito de las ciencias sociales, contribuyendo con un cuerpo de evidencia sistemática en torno a los problemas y soluciones sobre transparencia y reproducibilidad en las ciencias sociales sin precedentes. En este apartado, tanto los colaboradores como investigadores de BITSS ponen a disposición de la comunidad científica las investigaciones que han sido financiadas a través de las Social Science Meta-Analysis and Research Transparency (SSMART) grants, las cuales constituyen fondos orientados a contribuir a la investigación empírica en torno a la transparencia y reproducibilidad en disciplinas como la economía, ciencia política, psicología y ciencias sociales afines. Desde la Educación y Entrenamiento podemos identificar la articulación de una serie de Training activities desarrolladas por BITSS. Dentro de los objetivos de estas actividades podemos encontrar dos aspectos que se buscan abordar desde esta dimensión. Por un lado se encuentra el promover una visión crítica de los investigadores en las ciencias sociales, esto considera un entendimiento de los principales problemas asociados a la investigación social de calidad al alero de los principios de la ciencia abierta, dentro de lo cual podemos encontrar los sesgos y prácticas referidas a las presiones por publicar, prácticas cuestionables de investigación, reproducibilidad y privacidad de datos. Por otro lado, se han propuesto promover el manejo de técnicas de investigación para la transparencia y reproducibilidad, principalmente a través de actividades de entrenamiento con un foco en el aprendizaje e implementación de herramientas y métodos. En esta línea destacan dos contribuciones que se fundamentan en estos principios, las cuales serán descritas a continuación. Research Transparency and Reproducibility Training Una de las contribuciones señaladas es el Research Transparency and Reproducibility Training (RT2), el cual constituye uno de los principales eventos académicos realizados anualmente por BITSS, teniendo por objetivo el poner a disposición de estudiantes e investigadores una mirada general de las herramientas y prácticas actuales para la transparencia y la reproducibilidad en la investigación empírica en ciencias sociales. Los contenidos de RT2 abordan una serie de tópicos de manera transversal que pueden ilustrados en seis puntos: Amenazas para la credibilidad en la ciencia y la reproducibilidad, junto con su relación con el ethos científico: Conducta y valores en la ciencia. Mejoras en las especificaciones de los diseños de investigación: pre-registros y plan de pre-analysis en investigación con datos experimentales y observacionales. Ética e investigación abierta: estándares éticos para la ciencia abierta, manejo de datos y autoría de fuentes de información abiertas (citación). Herramientas y métodos para la investigación reproducible y colaboración: control de versiones y reportes dinámicos. Sistematización de evidencia, reproducibilidad e interpretación: métodos para investigación meta-analítica y revisiones sistemáticas, transparencia y reproducibilidad usando datos administrativos; y replicabilidad en la investigación. Software para la Ciencia Abierta e innovaciones metodológicas. MOOC: Transparent and Open Social Science Research Otra de las contribuciones es el Transparent and Open Social Science Research corresponde a un curso gratuito online de cinco semanas el cual aborda los fundamentos conceptuales y las principales herramientas para promover una ciencia social abierta y transparente. La Tabla 3.1 muestra el contenido de las sesiones, las cuales se basan en un curso de nivel de grado dictado por el director de BITSS Ted Miguel en la Universidad de California Berkeley. Tabla 3.1: Cursos por semana en el MOOC de BITSS Semana Contenido 1 Introducción a la transparencia y reproducibilidad de la investigación 2 Sesgo de publicación 3 Pre-registro, Plan de Pre-Análisis; y Meta-análisis 4 Replicación y Datos Abiertos 5 Visualización de Datos transparente y Viendo hacia adelante Una de las principales características de este curso introductorio es la sistematización de aspectos claves para la ciencia abierta con un foco particular en las ciencias sociales. Adicionalmente, tiene el objetivo de introducir conceptualmente a los problemas que se han visto presentes en las ciencias y busca dar respuestas prácticas a través de herramientas y métodos concretos para solucionarlo. Finalmente, constituye un esfuerzo breve y preciso, dado que las sesiones semanales poseen una duración promedio de unos treinta minutos y se encuentran dosificadas en videos de corta duración subtitulados. En el ámbito de los Recursos que provee BITTS, podemos encontrar librería de recursos o simplemente la Resource Library, la cual incluye una multiplicidad de recursos de aprendizaje digitales en torno a la transparencia y reproducibilidad, ordenados según (i) Tópico, (ii) Tipo y (iii) Disciplina de las ciencias sociales. La Figura 3.3 muestra cómo se visualizan los tópicos disponibles en la librería, lo cual puede ser ordenado según tipo y disciplina. Figura 3.3: Librería de Recursos de BITSS 3.2.2 Proyecto TIER (Teaching Integrity in Empirical Research) Objetivos y visión El proyecto TIER es una iniciativa respaldada por la Fundación Alfred Sloan que se propone contribuir a un cambio en las normas y conducta profesionales en torno a la transparencia y reproducibilidad en la investigación empírica en las ciencias sociales. Uno de los principios orientadores de sus actividades es el proveer formación en herramientas para la documentación oportuna de procedimientos que involucren datos estadísticos a través de rutinas y referencias que garanticen la reproducibilidad de estos. La idea subyacente que motiva estas acciones es que los autores puedan concebir la documentación como un componente esencial de la comunicación de sus resultados con sus pares, como también el público no especializado, de modo tal que estas medidas contribuyan a incrementar la confianza y credibilidad en la evidencia científica. En esta línea, su declaración de principios sostiene que su objetivo se puede considerar como logrado cuando: () no proporcionar documentación de replicación para un estudio empírico se considere tan aberrante como escribir un artículo teórico que no contenga pruebas de las proposiciones, un artículo experimental que no describa las condiciones de tratamiento o un artículo de revisión de leyes que no cite los estatutos legales o las decisiones judiciales. (traducción propia) Contribución Es necesario tener presente que uno de los principales campos de acción del proyecto TIER es la Educación y Entrenamiento, hacia cientistas sociales en formación, tomando en consideración que es en el ciclo formativo inicial donde se deben impulsar la adopción de prácticas integrales para la investigación social empírica. En esta línea, uno de los elementos destacables es la sección de herramientas para la enseñanza titulada TIER in the Classroom, sus contenidos referidos a temas de reproducibilidad pueden resumir de la siguiente manera: Soup-to-Nuts Exercises: No existe una traducción en el español, no obstante la expresión Soup-to-Nuts refiere a un proceso de inicio-a-fin. Como lo dice, esta sección muestra ejercicios orientados a la reproducibilidad de los análisis pasando por (1) los datos, (2) procesamiento, (3) análisis y (4) reporte. La idea fuerza de este ejercicio es introducir a estudiantes a los principios y prácticas fundamentales de la investigación social transparente y reproducible para que los implementen en sus tareas o informes. Materiales para clases: Esta sección está fuertemente orientada al análisis estadístico y a los métodos cuantitativos. Se presentan una serie de veinticuatro cursos de pregrado y postgrado que incorporan en su currículum los principios de transparencia y reproducibilidad en la enseñanza de los métodos de manera transversal. Los materiales de cada curso se encuentran disponibles para libre descarga, incorporando ejercicios de análisis estadístico (R, Stata, SPSS), reportes dinámicos (R Markdown, Markstat) y sus respectivos _ syllabus_. Trabajos estudiantiles: En este sección se incorporan una serie de trabajos estudiantiles/papers, los cuales están acompañados de una completa documentación basada en el Protocolo TIER (ver detalle abajo). El objetivo es presentar modelos de trabajos realizados con análisis reproducibles, de modo tal que quien esté interesado en emplear la estructura de un proyecto pueda observar un trabajo real e, idealmente, logre reproducir completamente sus resultados. Una de las contribuciones más relevantes del proyecto TIER es la elaboración de estándares para la organización, publicación y comunicación de proyectos de investigación empírica cuantitativa reproducible. Al respecto, existen dos esfuerzos orientados a este fin: Por un lado tenemos el Protocolo TIER, el cual constituye una serie de especificaciones respecto a los contenidos de la documentación para la replicación de un estudio, el cual está orientado a ser empleado para la enseñanza de la investigación que incorpore la reproducibilidad de los análisis. En este caso es importante precisar, como ya hemos identificado en un principio, que el concepto de replicación se emplea como sinónimo de reproducibilidad, entendiendo este último como la conjunción de datos y métodos originales que nos permitan regenerar los resultados de un estudio que ha sido publicado. Por lo tanto, cuando en TIER se habla de replicación se refiere a esta idea. La documentación debe incluir una serie de elementos descritos a continuación. Datos empleados por el proyecto Rutinas de código escrito en el software empleado para la preparación y análisis estadístico. Esto se incluye dado que el objetivo es proveer los datos brutos a procesar, junto con todas las instrucciones que permiten regenerar los resultados reportados en el estudio. Fuentes de información que contribuyan a comprender detalladamente cada sección del estudio de inicio a fin. Por otro lado tenemos el Protocolo DRESS (Documenting Research in the Empirical Social Sciences). Al igual que el Protocolo TIER, se incorporan los mismos estándares para la documentación para una investigación transparente que incorpore la reproducibilidad de los análisis. Sin embargo, este se encuentra adaptado a los propósitos de los investigadores profesionales, más que para el uso de los estudiantes durante su formación en investigación. 3.2.3 UK Reproducibility Network (UKRN) Objetivos y visión La UK Reproducibility Network (UKRN) es un consorcio institucional del Reino Unido que tiene por objetivo promover los principios y prácticas de la ciencia abierta con una mirada local, es decir, en las instituciones nacionales y sus investigadores. Para contribuir a este objetivo se realizan esfuerzos en torno a la investigación de los factores que determinan una investigación abierta y robusta, promoviendo el entrenamiento a través de actividades abiertas y diseminando las buenas prácticas para una ciencia abierta. En particular, se proponen a profundizar en los factores que determinan la carencia de reproducibilidad y replicabilidad, para lo cual se busca: Desarrollar aproximaciones que contrarresten esta falta de transparencia. Incrementar la confianza y la calidad de la investigación científica. Abordar de manera transversal estos problemas en las distintas disciplinas científicas. Avanzar hacia un cambio cultural en la ciencia y transformar las prácticas de quienes la desarrollan. En la UKRN se caracteriza por un trabajo en red, es decir por un importante componente de vinculación entre instituciones de investigación vinculadas a universidades como también a oficinas gubernamentales que desarrollan investigación (ver External Stakeholders) . En esta línea, existen diversas iniciativas apoyadas por la UKRN que promueven el entrenamiento, metodologías y recursos tecnológicos para la ciencia abierta. A continuación se presentarán algunas de las contribuciones más relevantes realizadas por la red, como también algunas de las iniciativas externas que han sido respaldadas por la UKRN. Contribución En el ámbito de la Educación y Entrenamiento, es posible identificar, por un lado, las contribuciones realizadas directamente por la UKRN, y por otro lado, las iniciativas que son respaldadas por la red y que promueven la formación en torno a los principios y prácticas de la ciencia abierta, particularmente en la etapa temprana de la carrera de investigación. Respecto a una de las iniciativas elaboradas por los académicos e investigadores involucrados en la UKRN, encontramos unos de los principales recursos virtuales en un breve curso online que aborda una serie de tópicos relevantes para la promoción de la ciencia abierta, dentro de lo cual encontramos el uso de pre-prints, autorías, registered reports, datos abiertos y reproducibilidad. A continuación se puede observar la lista de sesiones que han sido desarrolladas en torno a estos temas. Junto con las sesiones, existe una serie de recursos compartidos a través de un proyecto abierto en el Open Science Framework. Aquí es posible acceder a documentos breves que abordan los tópicos de cada sesión, además de recursos adicionales sobre uso de software de código abierto y repositorios. Un ámbito de desarrollo ha sido la disposición de recursos tecnológicos que promuevan y faciliten las prácticas en ciencia abierta. Una de las iniciativas impulsadas es el Open Research Calendar, el cual consiste en una instrumento colaborativo y abierto que busca brindar a la comunidad de investigadores interesados en temas relacionados a la ciencia abierta un flujo constante de actualizaciones en torno a workshops y conferencias a nivel mundial que abordan tópicos sobre ciencia abierta unificados en un calendario. El carácter colaborativo de esta herramienta permite que usuarios previamente registrados y validados puedan contribuir con información que se centraliza en el calendario de eventos, precisando los contenidos y redireccionando a la inscripción y/o enlace para las actividades que se realizan a través de internet. Para facilitar la experiencia de usuario, el calendario se integra con Google Calendar el cual puede sincronizarse con la agenda personal, los cuales se van actualizando automáticamente. Otra herramienta tecnológica patrocinada por la UKRN es la plataforma Octopus. A la fecha, la plataforma se presenta como una aplicación en desarrollo y abierta a comentarios de los usuarios. En términos generales se propone ser una alternativa para contribuir a la apertura de publicaciones. El detalle se presenta así: () sustituir a las revistas y los artículos como lugar para establecer la prioridad y registrar su trabajo con todo detalle, Octopus es de uso gratuito y publica todo tipo de trabajos científicos, ya sea una hipótesis, un método, datos, un análisis o una revisión por pares (traducción propia). La Figura 3.4 ilustra un ejemplo de cómo se ve un proyecto en Octopus. Vemos que existen siete componentes que buscan representar el flujo de una investigación. Entendiendo que los procesos de investigación no son lineales y tienden a existir iteraciones en entre teoría y métodos, la virtud de la registro y publicación de un proyecto permite que otros puedan conocer y evaluar nuestras hipótesis, plan de análisis, resultados y versiones de un artículo, así como también la vinculación entre cada sección. Figura 3.4: Ejemplo de un trabajo registrado en desarrollo en octopus.org Para publicar debemos logearnos con una cuenta de ORCID. Si no tienes una cuenta puedes crear un perfil aquí. Luego, se deben seguir tres pasos. El primero es elegir qué tipo de componente se desea publicar (Problema, Hipótesis, Métodos, etc). Segundo, dar detalles sobre el componente y con qué otros proyectos se relaciona. Y finalmente, contribuir con un borrador de escritura que luego será publicado. "],["herramientas-para-los-análisis-reproducibles.html", "3.3 Herramientas para los análisis reproducibles", " 3.3 Herramientas para los análisis reproducibles Introducción Por un lado tenemos todos los materiales que nos facilitan la reproducibilidad en términos computacionales, no obstante, la mera existencia de estos elementos no nos garantiza que un proyecto sea reproducible per se, dado que es importante tener en consideración cómo se relacionan entre sí, para regenerar los resultados de un trabajo publicado. Herramientas: Flujo de trabajo Documentos dinámicos Control de versiones Herramienta/Función 3.3.1 Flujo de trabajo Una de las principales cosas que debemos considerar al elaborar un proyecto es su estructura, lo que nos permita entender e identificar qué es cada componente, su función y rol en el flujo de trabajo. En este sentido, una de las herramientas que han sido desarrolladas son los denominados Protocolos (p. ej. TIER, DRESS, IPO), los cuales brindan una serie de orientaciones referentes a estructura digital de carpetas, documentación de archivos y rutinas para conseguir el anhelado objetivo de los análisis reproducibles. Para esto, es posible mencionar una serie de orientaciones generales referentes a dichos procedimientos, por ejemplo en el Proyecto TIER [CITAR] se han desarrollado protocolos orientados a la reproducibilidad de los análisis, los cuales se fundamentan en tres principios que se describen a continuación . Reproducibilidad: La documentación debe permitir regenerar completamente los resultados del estudio original. En primer lugar, se debe comenzar con los datos originales brutos idénticos a aquellos con los que el autor comenzó la investigación, Luego, la posibilidad de realizar las mismas rutinas de código para preparar los datos finales para el análisis. Finalmente, se debe disponer de las rutinas de código que permitan regenerar los mismos resultados publicados, por ejemplo, las tablas o figuras presentes en la investigación. Independencia: Toda la información necesaria para regenerar los resultados del estudio debe estar presente en la documentación. Esto refiere a que no debe ser necesario solicitar ninguna información adicional al autor original. Realismo: La documentación debe estar organizada y presentada con suficiente claridad para que bajo un criterio realista, sea factible que un investigador independiente con un nivel de expertise razonable tenga la posibilidad de regenerar completa e independientemente los resultados del estudio sin mayores dificultades. Teniendo en cuenta lo anterior, la forma en que se encuentran organizadas las partes de un proyecto es fundamental para cumplir a cabalidad con lo que se propone cada principio. Como se ha hecho notar en la sección previa, es posible entender la reproducibilidad como un espectro que involucra una triada de tres elementos: Datos, Métodos y Resultados. ESQUEMA: Datos - Métodos - Resultados El esquema de trabajo se basa en la estructura de proyectos del Protocolo IPO. Adicionalmente, se tomarán en consideración los estándares propuestos por el Protocolo DRESS, principalmente en lo que refiere a la documentación de cada uno de los componentes del proyecto. Para ello, trabajaremos en base a tres secciones: 3.3.1.1 Nivel principal Contenido El nivel principal corresponde al nivel base donde se encuentra toda la documentación de referencia general para el proyecto. Primero, el objetivo de documentar este nivel es exponer ordenadamente el contenido del proyecto completo de manera jerárquica, es decir, el contenido de subcarpetas y su función. Segundo, se proveen orientaciones para conducir a una correcta ejecución de las rutinas que permitan regenerar los resultados de la investigación. Los contenidos principales son: Detalle del nivel principal y las subcarpetas organizadas según su contenido. Una manera amigable de representar esta estructura es a través de un árbol de directorios, el cual ilustra la jerarquía de las carpetas y los principales archivos contenidos. Tip: Cómo generar un directory tree automatizado en Windows,linux y MacOS Instrucciones para la configuración (setup) del paquete estadístico necesario para ejecutar las rutinas de código. Esto considera el número de versión del software, los complementos necesarios que sean adicionales al paquete estándar y cualquier otra información especial sobre el software que el lector necesite conocer para reproducir los resultados del estudio. Instrucciones de inicio-a-fin para regenerar los resultados a través de referencias directas al uso de los archivos de procesamiento de datos en la preparación y análisis. En este apartado se incluye el detalle de los objetivos de cada rutina de código de manera independiente. Presentación Los contenidos descritos se deben incluir en un archivo que lleve de nombre readme.md/txt/pdf. Una sugerencia de estructura interna de este documento es la siguiente: Estructura y contenido del proyecto reproducible Esquema tipo Árbol de directorios Descripción de cada subcarpeta, sus archivo y roles Instrucciones y rutinas de ejecución de resultados Instrucciones para configuración del software Instrucciones para la ejecución de rutinas de código de inicio-a-fin. 3.3.1.2 A. Datos La carpeta de Datos tiene la función de albergar todos los archivos necesarios para la elaboración del procesamiento y el análisis de los datos. El protocolo IPO propone cuatro subcarpetas: data para los datos originales, bib para los archivos de citado, imageness para las imagenes que se vayan a incluir en el documento de preparación o el paper y prereg donde se albergan todos los archivos necesarios para documentar un pre registro. Separar los archivos en distintas carpetas permite, por una parte, ordenar mejor el flujo de trabajo ya que sabemos con certeza dónde está cada archivo y no tenemos que navegar en las carpetas para encontrarlo y, por otra parte, hace más reproducible el trabajo para terceros al facilitar la documentación del flujo. 3.3.1.2.1 Documentación La descripción de los contenidos de la subcarpeta Input deben estar adecuadamente identificados y documentados. Como se ha indicado, existen cuatro subcarpetas que incluyen datos, bibliografía, imágenes y documentación de pre-registro. A continuación se mostrarán una serie de sugerencias de documentación de los archivos y subcarpetas de Input. 3.3.1.2.2 Datos 3.3.1.2.2.1 Datos originales Para toda fuente de datos original, se debe proveer la siguiente información: Citación bibliográfica en un formato estándar (p. ej. American Psychological Association, Chicago, etc). Sugerimos revisar el componente de Datos Abiertos para la publicación de datos. La fecha de creación de la base de datos o el día en que se accedió por primera vez por parte del autor. Una descripción respecto a cómo se puede acceder a una copia de esta base de datos. Se debe ser lo suficientemente claro como para que un usuario independiente pueda acceder a los datos sin requerir información adicional. Un libro de códigos de todas las variables de la base de datos. Sugerimos revisar el apartado ¿Cómo hacer un libro de códigos?. 3.3.1.2.2.2 Datos procesados Para toda fuente de datos procesada, es posible identificar dos tipos: Base de datos intermedia, la cual contiene información que, por un lado, puede ser complementaria con una base de datos principal. Por ejemplo, tenemos una base de datos con información de individuos pertenecientes a zonas/territorios (regiones o países), a la cual necesitamos incorporar información adicional que proviene de fuentes externas. En este caso, podemos generar una base procesada intermedia, para luego proceder a combinar ambas fuentes de datos. Base de datos final, es una versión final de una base de datos que contiene las variables completamente procesadas para realizar los análisis. En estos casos se sugiere proveer la siguiente información: Libro de códigos de la base procesada. Para ello, las variables deben estar correctamente etiquetadas. Fecha de creación y versión de la base de datos procesada. 3.3.1.3 B. Métodos 3.3.1.3.1 a) Explicación En la sección de procesamiento, se espera albergar al menos dos documentos, uno que contenga el procesamiento de los datos y otro documento de análisis de datos. La principal razón para separar ambas actividades en documentos distintos es hacer más clara la lectura del código para la reproducibilidad. Esto quiere decir que, cualquier tercero que vaya a leer el código pueda comprender cómo se llegó a los resultados de forma paulatina, evitando a toda costa que, por ejemplo, en la mitad de la revisión del código emerja una pregunta tipo ¿y de dónde salió esta variable? En esta sección propondremos un flujo de trabajo para la generación de ambos documentos, así cómo también dejaremos planteadas algunas buenas prácticas para hacer estos documentos reproducibles. Procesamiento Esta sección cumple una función muy importante para el desarrollo de un artículo: la de procesar los datos que darán paso a los análisis del estudio. Considerando eso, el objetivo final de este documento es generar una base de datos procesada, que contenga solamente los datos importantes para analizar. El flujo puede ser: Cargar la base de datos original: Cargar la base de datos original es el punto de partida para el procesamiento de los datos, y cómo tal, es muy importante que esta acción sea reproducible. Cargar la base de datos original de forma que no se pueda reproducir abre la posibilidad de que todo el código que elaboremos a posterior sea inutilizable. De manera breve, dejamos estipulado cuál sería una forma no reproducible de cargar la base de datos, y una forma que sí es reproducible. Revisar la base de datos: Una vez cargada la base de datos original, recomendamos siempre revisar para que todo esté en orden. Cuando decimos ver que todo esté en orden nos referimos a diagnosticar si la base ha sido correctamente cargada. Por ejemplo, a veces podría suceder que la base de datos está en formato .csv con las columnas separadas por punto y coma (;), por lo que sí no lo especificamos en el código, tendríamos una base de datos con toda la información colapsada en una sola columna. Seleccionar las variables que se utilizarán: Generalmente no ocupamos todas las variables dentro de una base de datos, en especial en la investigación basada en encuestas con datos secundarios. Es por eso que el comienzo del procesamiento de datos consta de seleccionar las variables que utilizaremos para los análisis. Renombrar las variables: Si bien no es estrictamente necesario renombrar las variables, sí se recomienda para facilitar tanto el propio trabajo cómo el de alguien que vaya a emplear el mismo código. Generalmente, en la investigación de encuestas con datos secundarios nos encontramos con grandes bases de datos, con nombres técnicos y poco autoexplicativos. La principal recomendación aquí es cambiar estos nombres por nombres cortos y autoexplicativos. Procedimientos a realizar por cada variable: Una vez hemos cumplido con los aspectos generales del procesamiento, podemos pasar a la revisión de variable a variable. Aquí proponemos el siguiente flujo: Descriptivo inicial: calcular una tabla de frecuencias o de medidas de tendencia central y dispersión para conocer el estado de la variable previo a cualquier modificación. Recodificación: aquí se toman las decisiones respecto a la recodificación de los datos perdidos y otro tipo de valores a modificar (e.g. errores de tipeo). Es importante que las decisiones sobre la recodificación queden bien estipuladas y transparentadas. Por ejemplo, en caso de hacer imputación en alguna variable, dejarlo comentado en el código. Etiquetado: el etiquetado es una forma simple y eficiente de poder dar más información acerca de una variable. En el caso de bases de datos sobre encuestas, generalmente una base bien documentada trae etiquetas predeterminadas que hacen alusión a las preguntas del cuestionario. Descriptivo final: recomendamos que, posterior a haber hecho las recodificaciones correspondientes, revisar de nuevo las frecuencias o las medidas de tendencia central de las variables, para diagnosticar que no hemos cometido errores en el procesamiento. Un ejemplo común, es que etiquetemos de forma errónea cada categoría de la variable. Esto tendría un impacto directo en la interpretación de los datos. Otros ajustes: en esta última parte del flujo por variable, recomendamos efectuar toda modificación específica y relevante para la forma que analizaremos los datos. Por ejemplo, si fuésemos a construir un índice con algunas de las variables. Para esta sección de flujo de trabajo, también sugerimos, a modo de práctica de orden, que todo título y subtítulo estén especificados y jerarquizados. En detalle, proponemos que por cada título correspondiente a la variable a recodificar, cada aspecto del flujo sea un subtítulo, algo cómo: Rutas relativas El último momento de la sección de procesamiento consiste en guardar la base de datos con los cambios realizados. En el caso de R, esto se reduce solamente a una línea de código, sin embargo, queremos aprovechar el momento para explicar una práctica muy importante para la reproducibilidad: las rutas relativas Cómo hemos visto, una estructura de carpetas simple, eficiente y reproducible para el procesamiento y el análisis de los datos. Sin embargo, ¿qué ocurre cuándo necesitamos movernos entre carpetas para cargar archivos? Por ejemplo, si estamos trabajando en el documento de procesamiento y necesitamos insertar una imagen. Acá es donde entran en juego las rutas relativas, estas son una forma simple de moverse entre carpetas asumiendo una carpeta raíz. En la práctica, requiere solamente dos nociones: [ESTO PODRIA SER UNA TABLA] Si queremos avanzar entre carpetas, debemos usar forward slashes (/) por cada subcarpeta que avancemos (e.g. input/data/archivo.txt) Si queremos retroceder entre carpetas, debemos usar forward slashes más dos puntos por cada nivel que retrocedamos (e.g. ../archivo.txt) Retomemos el ejemplo, si estamos trabajando en el documento de procesamiento (el cual se encuentra en la carpeta procesamiento y tenemos que cargar alguna imagen, podemos utilizar la siguiente ruta: ../input/images/imagen.png. Estando en conocimiento del funcionamiento de las rutas relativas, el código para guardar la base de datos sería algo así: Análisis Una vez contamos con nuestra base de datos procesada, es hora de la acción. En la sección del análisis de datos se procede a elaborar todas las tablas, gráficos, pruebas estadísticas etc. que vayan a ser introducidos en el artículo final. Es importante que se piense en este documento cómo un reporte de análisis en sí mismo, es decir, debe estar dirigido al público y no solo ser un documento de trabajo interno para el equipo de investigación. Al igual que para la sección de procesamiento de datos, aquí también recomendamos un flujo de trabajo para hacer el código reproducible y eficiente. Dividimos el flujo en dos secciones, primero, una que contenga los análisis necesarios para probar las hipótesis de investigación. Segundo, una sección con análisis secundarios y/o exploratorios que sean relevantes para lo que el artículo busca plantear. Veremos esto con un poco más de detalle. 3.3.1.3.2 b) Documentación Para una correcta comprensión de la subcarpeta de procesamiento, sus archivos y roles, es importante tener una descripción adecuada de cada una de sus partes. Al estar mayormente orientado a la programación de rutinas de código, los documentos de preparación y análisis debieran contener la mayor parte de la información para una correcta comprensión del procedimiento. No obstante, es relevante precisar de qué manera estos documentos se vinculan con otros archivos dentro del proyecto. Por un lado, el documento de preparación requiere de una fuente de datos inicial, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos originales. Por otro lado, el documento de análisis requiere de una fuente de datos procesada, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos procesados. Además, se debe tener en consideración que los productos del análisis, es decir, los resultados de la investigación, pueden ser reportados en forma de figuras o tablas, las cuales son almacenadas en la carpeta Output y en las subcarpetas imágenes y tablas, respectivamente. Para una correcta ejecución de las rutinas de código, es importante describir adecuadamente la relación entre los archivos de preparación y análisis. Para ello, se sugiere incorporar un archivo de nombre readme-proc.md/txt/pdf, en donde se describa brevemente dicha vinculación. Para ello sugerimos los siguientes puntos a describir: Para la ejecución de la preparación, precisar la ubicación de la o las fuentes de datos originales. (p.ej. input/data/original/original-data.dta) Para el cierre de la preparación, precisar la ruta donde se deben almacenar la base de datos procesada y su extensión (p.ej. input/data/original/proc-data.RData) Para la ejecución de los análisis se debe precisar el origen de la base procesada que fue creada en el punto 2. . Para los archivos de resultados provenientes del análisis de los datos, tales como figuras o tablas, debemos precisar la ruta donde se almacenarán y su nombre. 3.3.1.4 C. Resultados 3.3.1.4.1 a) Explicación En la sección de output se espera albergar toda tabla, figura o gráfico relevante producto del código de análisis de datos. Para esto se proponen dos carpetas, una de imágenes y otra de tablas. La idea de esta carpeta es que podamos guardar toda figura que vaya a ser parte del documento final del artículo. 3.3.1.4.2 b) Documentación Como se ha señalado anteriormente, tenemos dos tipos de archivos contenidos dentro de las subcarpetas de Output. Para una correcta identificación de cada uno de estos elementos sugerimos seguir las siguientes indicaciones: Para las imágenes, sugerimos usar nombres breves e incorporar numeración. Por ejemplo figura01.png, según el orden de aparición en la publicación. Para el caso de los cuadros o tablas, existen distintas extensiones para almacenarlas como archivos independientes (tex/txt/md/html/xls). Para ello, sugerimos emplear nombres cortos e incorporar numeración. Por ejemplo, tabla01.xls, según el orden de aparición en la publicación. 3.3.2 Documentos dinámicos 3.3.3 Control de versiones "],["palabras-finales.html", "Capítulo 4 Palabras finales", " Capítulo 4 Palabras finales Hemos aprendido sobre transparencia y reproducibilidad. "],["references.html", "References", " References "]]
