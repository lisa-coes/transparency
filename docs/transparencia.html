<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Transparencia | Transparencia y Reproducibilidad en Investigación Social</title>
  <meta name="description" content="Un breve manual sobre la transparencia y reproducibilidad en las ciencias sociales." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Transparencia | Transparencia y Reproducibilidad en Investigación Social" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Un breve manual sobre la transparencia y reproducibilidad en las ciencias sociales." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Transparencia | Transparencia y Reproducibilidad en Investigación Social" />
  
  <meta name="twitter:description" content="Un breve manual sobre la transparencia y reproducibilidad en las ciencias sociales." />
  

<meta name="author" content="Julio Iturra y Martín Venegas" />


<meta name="date" content="2021-07-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="reproducibilidad.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Transparencia</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="transparencia.html"><a href="transparencia.html"><i class="fa fa-check"></i><b>2</b> Transparencia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="transparencia.html"><a href="transparencia.html#qué-es-la-transparencia-un-concepto-multidimensional"><i class="fa fa-check"></i><b>2.1</b> ¿Qué es la transparencia? Un concepto multidimensional</a></li>
<li class="chapter" data-level="2.2" data-path="transparencia.html"><a href="transparencia.html#crisis-en-las-ciencias"><i class="fa fa-check"></i><b>2.2</b> ¿Crisis en las ciencias?</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="transparencia.html"><a href="transparencia.html#mala-conducta-académica-ffp"><i class="fa fa-check"></i><b>2.2.1</b> Mala conducta académica (FFP)</a></li>
<li class="chapter" data-level="2.2.2" data-path="transparencia.html"><a href="transparencia.html#prácticas-cuestionables-de-investigación-qrp"><i class="fa fa-check"></i><b>2.2.2</b> Prácticas cuestionables de investigación (QRP)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="transparencia.html"><a href="transparencia.html#que-podemos-hacer"><i class="fa fa-check"></i><b>2.3</b> ¿Que podemos hacer?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="reproducibilidad.html"><a href="reproducibilidad.html"><i class="fa fa-check"></i><b>3</b> Reproducibilidad</a></li>
<li class="chapter" data-level="4" data-path="herramientas-para-la-transparencia-y-irreproducibilidad.html"><a href="herramientas-para-la-transparencia-y-irreproducibilidad.html"><i class="fa fa-check"></i><b>4</b> Herramientas para la transparencia y irreproducibilidad</a>
<ul>
<li class="chapter" data-level="4.1" data-path="herramientas-para-la-transparencia-y-irreproducibilidad.html"><a href="herramientas-para-la-transparencia-y-irreproducibilidad.html#pre-registros"><i class="fa fa-check"></i><b>4.1</b> Pre-registros</a></li>
<li class="chapter" data-level="4.2" data-path="herramientas-para-la-transparencia-y-irreproducibilidad.html"><a href="herramientas-para-la-transparencia-y-irreproducibilidad.html#flujos-de-trabajos-reproducibles."><i class="fa fa-check"></i><b>4.2</b> Flujos de trabajos reproducibles.</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="palabras-finales.html"><a href="palabras-finales.html"><i class="fa fa-check"></i><b>5</b> Palabras finales</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Transparencia y Reproducibilidad en Investigación Social</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="transparencia" class="section level1" number="2">
<h1><span class="header-section-number">Capítulo 2</span> Transparencia</h1>
<p>Esta sección tratará sobre la transaprencia en la investigación cientifica, haciendo enfásis en las ciencias sociales. Nuestro objetivo es poder comunicar de forma clara y concisa tres puntos: a) qué es la transparencia, b) por qué la necesitamos y c) cómo podemos adoptarla. En esta sección verenmos los dos primeros puntos, luego, en la sección de herramientas presentaremos algunas formas de adoptar la transparencia. La tónica de este escrito es la práctica, es decir; todo lo que presentemos acá tiene la finalidad de servir de camino para poder aprender y aprehender herramientas que promueven la transparencia. Dicho esto, comenzemos con los dos primeros puntos.</p>
<div id="qué-es-la-transparencia-un-concepto-multidimensional" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> ¿Qué es la transparencia? Un concepto multidimensional</h2>
<p>Nuestro punto de partida es que la transparencia es un concepto amplio y multidimensional. Por eso, antes de adentrarnos en su complejidad, comenzemos con una definición de diccionario para comprender lo más básico en la idea de transparencia. Según la Real Academia Española la transparencia es la cualidad de un cuerpo que permite ver a travez de él. Un gran ejemplo para llevar esta definición a la práctica es el vidrio de una ventana. La transparencia del vidrio nos permite ver con claridad lo que está el otro lado, como por ejemplo un paisaje. Sin embargo, ¿qué ocurre cuándo la transparencia del vidrio se va perdiendo? La respuesta es simple, pero potente: la claridad con la que veíamos el paisaje se va difuminando. Esta perdida de claridad puede dar como resultado que nuestra observación del paisaje se torne ambigua y erronea, o dicho de otro modo, cada vez será más dificil analizar el paisaje. En esta metafora, el paisaje sería equivalen al proceso de producción cientifica, y el vidrio representa la claridad con la que podemos analizar estos procesos. De esta manera, la base de la idea de transparencia es que permite analizar con claridad un fenomeno, una situación, o en este caso, un proceso.</p>
<p>¿Qué implica un proceso cientifico transparente? Ya existen algunas respuestas a esta pregunta. Por ejemplo, <span class="citation"><a href="#ref-breznau_Does_2021" role="doc-biblioref">Breznau</a> (<a href="#ref-breznau_Does_2021" role="doc-biblioref">2021</a>)</span> entiende la transparencia como una forma en que los investigadores pueden revelar el proceso, ideas y materiales que sustentan un argumento o una teoría, con tal de contribuir a una comunidad científica más ética. Otra perspectiva es la de <span class="citation"><a href="#ref-aczel_consensusbased_2020" role="doc-biblioref">Aczel et al.</a> (<a href="#ref-aczel_consensusbased_2020" role="doc-biblioref">2020</a>)</span>, quienes proponen a la transparencia como un principio que permite evaluar y reproducir los hallazgos científicos, así como también a sintetizar investigaciones y contribuir a la ejecución de metanálisis. Estas perspectivas son una primera aproximación a las implicancias de un proceso cientifico transparente, no obstante, no son una presentación exhaustiva del concepto.</p>
<p>Para abarcar la complejidad del concepto de transparencia, y las múltuiples formas que puede adoptar, nos basamos en la taxonomía de <span class="citation"><a href="#ref-elliott_Taxonomy_2020" role="doc-biblioref">Elliott</a> (<a href="#ref-elliott_Taxonomy_2020" role="doc-biblioref">2020</a>)</span>. La taxonomía se basa en cuatro grandes preguntas: ¿por qué?, ¿quienes? ¿qué? y ¿cómo? Cada una de estas preguntas tiene al menos una dimensión asociada. La primera pregunta se refiere a los propósitos por los cuales adoptar la transparencia; la segunda pregunta apunta a la audiencia que está recibiendo la información; la tercera pregunta hace alusión al contenido qué es transparentado y la cuarta pregunta consiste en cuatro dimensiones distintas sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y lugar. También, la taxonmía propone una dimensión sobre los peligros que podrían afectar a las iniciativas que busquen promover la transparencia. Aunque esta última dimensión no es una forma de transparencia -en el mismo sentido que las otras dimensiones-, si tiene relevancia en tanto permite mejorar las iniciativas de transparencia. Una representación gráfica puede verse en la Figura N° <a href="transparencia.html#fig:taxonomy">2.1</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:taxonomy"></span>
<img src="docs/images/taxonomy.png" alt="Taxonomía de Transparencia" width="100%" />
<p class="caption">
Figura 2.1: Taxonomía de Transparencia
</p>
</div>
<p>Para comprender mejor la taxonomía la Figura N° <a href="transparencia.html#fig:tabtax">2.2</a> presenta una versión detallada de cada dimensión en conjunto a una lista no exhaustiva de variaciones. Por ejemplo, la dimensión del propósito sintetiza varios de los puntos que ya se han señalado en la literatura sobre ciencia abierta: hacer la ciencia más replicable, facilitar la interacción crítica, facilitar el reanalisis de resultados, entre otros. La mayoría de estos propositos están estrechamente relacionados con el horizonte de una ciencia con mayor credibilidad. Dentro de las dimensiones restantes, existe una en particular que queremos recalcar: los contenidos. Aquí, los distintos contenidos que pueden ser transparentados van desde cosas complejas como los juicios de valor, hasta lo más concreto como datos, métodos y materiales, o dicho de otra forma, el diseño de investigación. El diseño de investigación es uno de los que más se ha promovido la transparencia últimamente, especialmente a raíz de los pre-registros. Profundizaremos en esto más adelante en el escrito.</p>
<p>En síntesis, un proceso de investigación transparente es uno que se puede evaluar con claridad y facilidad. La taxonomía de <span class="citation"><a href="#ref-elliott_Taxonomy_2020" role="doc-biblioref">Elliott</a> (<a href="#ref-elliott_Taxonomy_2020" role="doc-biblioref">2020</a>)</span> nos ayuda a comprender las diversidad dimensiones en las que se puede pensar la idea de transparencia. Sin embargo, aun existe la pregunta del <em>por qué</em>. ¿Por qué es relevante la idea de transparencia? La dimensión de propositos de la taxonomía ya nos ha dado algunas pistas: la ciencia puede ser mejor. Y no solo eso, sino que inclusive podria estar en crisis.</p>
<div class="figure" style="text-align: center"><span id="fig:tabtax"></span>
<img src="docs/images/table_tax.png" alt="Variaciones por dimensión de transparencia" width="100%" />
<p class="caption">
Figura 2.2: Variaciones por dimensión de transparencia
</p>
</div>
</div>
<div id="crisis-en-las-ciencias" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> ¿Crisis en las ciencias?</h2>
<p>En los últimos años, ha venido tomando fuerza la idea de que existe una crisis en la ciencia. Esta idea se basa en el diagnóstico de que gran parte de los artículos cientificos en distintas discplinas no son posibles de reproducir ni replicar. Tanto la reproducibilidad (emplear el mismo diseño y datos para reproducir los hallazgos de un artículo) o la replicabilidad (emplear el mismo diseño y distintos datos para obtener los mismos resultados) son componentes centrales de la ciencia. Es más, algunos de los mecanismos que permiten el avance del conocimiento cientifico son el escrutinio y la verificabilidad de sus hallazgos, por lo que un fallo en el cumplimiento de estos es un golpe directo a la credibilidad de la ciencia. La pregunta es ¿existe realmente una crisis en las ciencias?</p>
<p>Unas de las fuentes más comunmente citadas para introducir la idea de crisis es una encuesta realizada en la revista <em>Nature</em>. En esta encuesta, <span class="citation"><a href="#ref-baker_500_2016" role="doc-biblioref">Baker</a> (<a href="#ref-baker_500_2016" role="doc-biblioref">2016</a>)</span> logró obtener las opiniones de poco más de 1,500 investigadores de discplinas como la quimica, ingenerías y la medicina, sobre tópicos relacionados a la reproducibilidad en las ciencias. El resultado principal muestra que un <strong>90% de los encuestados está de acuerdo en la existencia una crisis</strong>, donde un 52% piensa que es una gran crisis y un 38% la percibe como una ligera crisis. En este mismo estudio, se les pregunta por los factores que contribuyen a esta crisis, donde la cultura del <em>pública o perece</em> y el <em>reporte selectivo de resultados</em> aparecen como los protagonistas. Si bien la encuesta no es una muestra representativa de toda la comunidad cientifica, presenta una panoramica que lleva a, por lo menos, considerar la crisis de la ciencia como tema que merece atención.</p>
<p>Actualmente, existe un cuerpo de literatura que se ha dedicado diagnosticar y proponer alternativas de solución ante la idea de una ciencia en crisis. Dentro del diagnóstico, variados estudios han orientado sus esfuerzos a esclarecer cuáles son los factores que podrían estar influenciando esta crisis. En esta sección, presentaremos estos factores en dos grandes dimensiones. La primera dimensión se relaciona a las prácticas de investigación, especificamente aquellas prácticas que ya sea en menor o mayor grado afectan la credibilidad de los hallazgos cientificos en su conjunto. La segunda dimensión se centrará más en factores institucionales y que no dependen estrictamente de los investigadores. Una vez explicados estos factores, analizeremos como ciertas herramientas que promueven la transparencia en la investigación podrían c</p>
<p>Comenzemos con las prácticas de investigación. Para esquematizar de mejor manera qué es lo problemático de ciertas prácticas, es que utilizaremos el esquema conceptual de <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span>. El esquema parte de una distinción básica entre la <em>ética en investigación</em> y la <em>integridad en investigación</em>, englobando ambas bajo el gran concepto de <em>Conducta Responsable de Investigación (RCR)</em> (ver Figura N° <a href="transparencia.html#fig:rcr">2.3</a>. A grandes rasgos, la RCR se puede entender como el “llevar a cabo la investigación de forma que se cumplan las responsabilidades profesionales de los investigadores, tal y como las definen sus organizaciones profesionales, las instituciones para las que trabajan y, en su caso, el gobierno y el público” <span class="citation">(<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006</a>)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<div class="figure" style="text-align: center"><span id="fig:rcr"></span>
<img src="docs/images/rcr.png" alt="Conducta Responsable de Investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006" width="100%" />
<p class="caption">
Figura 2.3: Conducta Responsable de Investigación. Imagen de <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> basada en <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span>
</p>
</div>
<p>Dentro de este concepto, la ética de investigación está relacionada al comportamiento académico visto desde la óptica de los principios morales <span class="citation">(<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006</a>)</span>, lo que se expresa en tópicos como el uso de datos, los consentimientos informados, el trato con pacientes -en el caso de las ciencias biomedicas-, por dar algunos ejemplos. La definición que ofrece <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span> señala que la ética de investigación se define como “el estudio crítico de los problemas morales asociados o que surgen en el curso de la investigación” (p.56) En cámbio, la integridad en investiación se entiende como “poseer y adherirse firmemente a las normas profesionales, tal y como las señalan las organizaciones profesionales, las instituciones de investigación y, en su caso, el gobierno y el público” <span class="citation">(<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006, 56</a>)</span>. A diferencia de la ética de investigación, el concepto de identidad está regido por los estándares profesionales más que por los principios morales, su función es plantear una guía clara para la conducta inevestigativa, de ahí que sea el concepto utilizado por distintos códigos de conducta[].</p>
<div class="figure" style="text-align: center"><span id="fig:grad"></span>
<img src="docs/images/grad.png" alt="Gradación del comportamiento integro en investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006" width="100%" />
<p class="caption">
Figura 2.4: Gradación del comportamiento integro en investigación. Imagen de <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> basada en <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span>
</p>
</div>
<p>Habiendonos situando dentro del concepto de integridad en la investigación, podemos pasar a delinear las principales prácticas que atentan contra él y que se han propuesto como factores que contribuyen a la crisis en la ciencia. Tanto <span class="citation"><a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck</a> (<a href="#ref-steneck_Fostering_2006" role="doc-biblioref">2006</a>)</span> como distintos códigos de conducta de universidades e instituciones de financiamiento [] evalúan las prácticas de investigación en un continuo, que representa cuánto adhieren los investigadores a los principios de integridad cientifica. La Figura N° <a href="transparencia.html#fig:grad">2.4</a> esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derechaa el peor comportamiento (FFP). Las FPP son un abreviación en lengua inglésa para referirse a <em>Fabrication, Falsification, Plagiarism</em> (Invención, Falsificación y Plagio), también conocidas como <em>mala conducta académica</em>-. En el medio del continuo están las <em>prácticas cuestionables de investigación</em> (QRP, por sus siglas en inglés) las cuáles refieren a “acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación” <span class="citation">(<em>National Academies of Science</em> 1992 en <a href="#ref-steneck_Fostering_2006" role="doc-biblioref">Steneck 2006, 58</a>)</span>. A diferencia de las FFP, las QRP son prácticas que tienen el potencial de dañar la ciencia y no que la dañan directamente (como las FFP).</p>
<p>Comprendidos ambos conceptos, veamos las situaciones que podrían categorizarse como FFP y las que podrían concebirse como QRP.</p>
<div id="mala-conducta-académica-ffp" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Mala conducta académica (FFP)</h3>
<p>La mala conducta académica suelen ser situaciones polémicas y que muchas veces alcanzan gran conbertura mediatica. El libro de <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> presenta una serie de situaciones, en distintas discplinas y años, en las que investigadores han sido descubiertos cometiendo prácticas que atentan directamente a la ciencia. Las situaciones son variadas, existen casos de manipulación de imagenes [], exageración de lo registros de laboratorio, o de plano la invención de conjuntos de datos enteros. En esta sección veremos el caso de Diderik Stapel como ejemplo de malas prácticas de investigación y plantearemos la relación que tiene con la transparencia en la investigación.</p>
<div id="diderik-stapel" class="section level4" number="2.2.1.1">
<h4><span class="header-section-number">2.2.1.1</span> Diderik Stapel</h4>
<p>Probablemente, el caso de Diderik Stapel sea uno de los más emblématicos y representativos de este problema. Diderik Stapel era un investigador de la <em>Tilburg University</em> que se dedicaba al campo de la psicologóa social. Su carrera se caracterizó por una trayectoria ejemplar, obtuvo su M.A en psicolgía y comunicaciones el año 1991, se doctoró en psicología social el año 1997 y trabajó como profesor asociado primero en la <em>University of Gronigen</em> (2000-2006) y dede el 2006 en la Tilburg University. Fue fundador del <em>Tilburg Institute for Behavioral Economics Research</em>, del cuál el 2010 se convirtió en decano. Así también, fue galardonado con el premio a la trayectoria académica por la <em>Social of Experimental Social Psychology</em>. En breve, Stapel era una figura de alto estatus en el mundo académico, entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas cientificas, algunas de las más prestigiosas (e.g. <em>Science</em>). Sin embargo, el año 2011 se confirmó que gran parte de su trayectoria académica era una farsa.</p>
<p>Después de la verificación de su culpa ante acusaciones de malas prácticas, la carrera de Diderik Stapel acabó. Fue desvinculado de la Tilburg University, se le rebocó su título de doctorado y toda su trayectoria académica fue investigada acusiociamente. El informe final de la investigación encontró que más de 50 de sus artículos eran fraudulentos. De hecho, Stapel ocupa el tercer lugar en <em>Retraction Watch</em>, con 58 de sus artículos retractados. A efectos de este escrito, lo que más destacable es que Stapel cometió conductas de mala conducta académica durante más de 15 años. La pregunta es ¿cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o co-autores se dio cuenta de sus malas prácticas? La respuesta breve es por la falta de transparencia durante el proceso de investigación.</p>
<p>Los artículos periodisticos que han profundizado en el caso <span class="citation">(e.g. <a href="#ref-carey_Fraud_2011" role="doc-biblioref">Carey 2011</a>)</span> han relatado parte del proceso investigativo de Stapel. Dentro de los procesos de producción y análisis de datos, Stapel se caracterizaba por hacer todo el trabajo solo y “a puertas cerradas.” Es decir, nadie más que él tenía acceso a los datos brutos, ni támpoco a la ejecución de las pruebas estadísticas. Generalmente, Stapel compartía con sus colegas y alumnos de doctorado la base de datos lista, con las pruebas estadísticas ya hechas y, claro está, con resultados significativos. Estas prácticas no causaron sospechas durante muchos años, es más, a muchos de sus estudiantes les parecía una práctica normal y eficiente. Además, con el estatus de Stapel ¿qué podría estar mal? Sin embargo, era a raíz de esta práctica que Stapel tenía la oportunidad de inventar y falsificar datos a su conveniencia. Esto explica en gran parte de su trayectoría académica llena de grandes hallazgos.</p>
<p>El caso de Stapel deja un punto base sobre la mesa: la falta de transparencia en el proceso investigativo dio cabida a la mala conducta académica. Cómo nadie más colaboraba con el procesamiento de datos, ni támpoco parecía extraño que asi fuera, las oportunidades para la falsificación de los datos estaba abierta. Ahora, esta no es necesariamente una relación de causalidad, la falta de transparencia no tiene porque terminar en conductas como fabricación o falsificación de datos. Sin embargo, tal y como lo argumentan <span class="citation">(<a href="#ref-oboyle_Chrysalis_2017" role="doc-biblioref">O’Boyle, Banks, and Gonzalez-Mulé 2017</a>)</span> si son una oportunidad para violaciones a la integridad cientifíca más sutiles, tales como las QRP.</p>
</div>
</div>
<div id="prácticas-cuestionables-de-investigación-qrp" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Prácticas cuestionables de investigación (QRP)</h3>
<p>Recordemos, las QRP son prácticas que en si mismas no dañan directamente la empresa cientifica, pero si tienen el potencial de hacerlo. En la literatura sobre el tema, existen una multiplicidad de términos y listas de prácticas especificas que pueden categorizarse como cuestionables. <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> hace una recopilación y traducción de distintos códigos de conducta de distintas universidades y organismos, el cuál nosotros sistematizamos en la Figura N° X. La figura muestra un conjunto de prácticas divididos en cuatro categorías, de acuerdo a si las prácticas tienen que ver con: la redacción y el reporte de los resultados, el procesamiento de los datos, temas de citación y uso de ideas ajenas y, por último, sobre relaciones con otros actores en el campo de la ciencia. El objetivo de esta recopilación es meramente esquemático, en el sentido de poder gatillar la reflexión respecto a la experiencia del lector a partir de algunas situaciones concretas que podráin afectar las investigaciones.</p>
<p>Han habido algunos estudios que han intentado medir directamente la existencia de estas prácticas a través de encuestas cuantitativas. <span class="citation"><a href="#ref-fanelli_How_2009" role="doc-biblioref">Fanelli</a> (<a href="#ref-fanelli_How_2009" role="doc-biblioref">2009</a>)</span> hizo un metanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez y que un 33.7% había realizado alguna vez una QRP como “borrar puntos de los datos basados en un sentimiento visceral.” Un estudio más reciente, también basado en encuestas cuantitativas sobre prácticas, es el de <span class="citation"><a href="#ref-john_Measuring_2012" role="doc-biblioref">John, Loewenstein, and Prelec</a> (<a href="#ref-john_Measuring_2012" role="doc-biblioref">2012</a>)</span>. En este estudio, los resultados mostraron que un 36.6% de quienes participaron alguna vez habían práctiado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicologos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipotesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Estos estudios son una primera aproximación a la existencia de las QRP en la ciencia.</p>
<p>Existen ciertas prácticas que han sido tratadas con más enfásis en la literatura, y que son las que queremos destacar acá. Por un lado, está el <em>sesgo de publicación</em>. A grandes rasgos, los sesgos de publicación se refieren a la publicación exclusiva de resultados significativos, en desmedro de los no significativos. Dicho de otra forma, cuándo el criterio de selección para la publicación de resultados es la significancia, el cuerpo de literatura de esa temática particular comienza a sesgarse. El estudio de <span class="citation"><a href="#ref-franco_Publication_2014" role="doc-biblioref">Franco, Malhotra, and Simonovits</a> (<a href="#ref-franco_Publication_2014" role="doc-biblioref">2014</a>)</span> tiene por objetivo cuantificar esta situación, especificamente en ciencias sociales. En su estudio encontraron un patrón interesante: “estudios donde la hipotesis principales arrojan resultados nulos son 40% menos probables de ser publicados en una revista cientifica, en contraste a estudios que arrojen resultados significativos” <span class="citation">(<a href="#ref-christensen_Transparent_2019" role="doc-biblioref">Christensen, Freese, and Miguel 2019, 41</a>)</span>. Los descriptivos se pueden ver en la Figura N° <a href="transparencia.html#fig:written">2.5</a>.</p>
<p>Otra práctica es la del <em>p-hacking</em>…</p>
<p>Por último, está el <em>HARKing</em>, el cual…</p>
<p>Un estudio que se aleja de la encuesta directa sobre prácticas, pero que contribuye estimando cuál es el potencial de que una QRP afecte los resultados de un artículo es el de <span class="citation"><a href="#ref-simmons_FalsePositive_2011" role="doc-biblioref">Simmons, Nelson, and Simonsohn</a> (<a href="#ref-simmons_FalsePositive_2011" role="doc-biblioref">2011</a>)</span>. En detalle, los autores buscan calcular el <em>likelihood</em> de obtener un falso positivo (error Tipo I) de acuerdo a al nivel de manipulación intencionada de los datos. El procedimiento consistió en calcular 15.000 muestras de 20 observaciones por condición de tratamiento para un experimento hipotetico y determinaron cuatro posibles ajustes a los datos: 1) plantear dos variables dependientes correlacionadas, 2) incrementar la muestra entre 20 y 30 casos según condición de tratamiento, 3) controlar por una variable sociodemográfica (género) o plantear una interacción genero y condición de tratamiento y 4) flexibilidad en eliminar alguna condición de tratamiento. Como se puede ver en la Figura N° <a href="#fig:fp"><strong>??</strong></a>, el resultado principal es que a medida que aumenta la cantidad de manipulación en los datos, el likelihood de obtener un falso positivo aumenta progresivamente. Una situación en donde se realicen los cuatro ajustes planteados tiene un 60.7% de likelihood de encontrar un falso positivo.</p>
<p>Una herramienta que se ha utilizado para estimar la existencia de p-hacking en los cuerpos de literatura es la <em>p-curve</em>. La p-curve “describe la densidad de los <em>p-values</em> reportados en una literatura, aprovechando el hecho de que si la hipótesis nula fuera verdadera (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1” <span class="citation">(<a href="#ref-christensen_Transparent_2019" role="doc-biblioref">Christensen, Freese, and Miguel 2019, 67</a>.)</span>. De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de p-values debería ser asimetrica a la derecha, en cambio, si existe sesgo por p-hacking la distribución de p-values estaría distribuida de forma asimetrica a la izquierda. <span class="citation"><a href="#ref-simonsohn_Pcurve_2014" role="doc-biblioref">Simonsohn, Nelson, and Simmons</a> (<a href="#ref-simonsohn_Pcurve_2014" role="doc-biblioref">2014</a>)</span> proponen esta herramienta y la prueban en dos muestras de artículos de la <em>Journal of Personality and Social Psychology (JPSP)</em>. Las pruebas estadísitcas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipotesis, en detalle, los artículos que presentaban solamente resultados con covariables, resultaron tener una p-curve asimetrica a la izquierda.</p>
<div class="figure" style="text-align: center"><span id="fig:written"></span>
<img src="docs/images/fp.png" alt="Porcentajes de publicación de acuerdo a significancia de resultados. Imagen de @christensen_Transparent_2019." width="100%" />
<p class="caption">
Figura 2.5: Porcentajes de publicación de acuerdo a significancia de resultados. Imagen de <span class="citation"><a href="#ref-christensen_Transparent_2019" role="doc-biblioref">Christensen, Freese, and Miguel</a> (<a href="#ref-christensen_Transparent_2019" role="doc-biblioref">2019</a>)</span>.
</p>
</div>
</div>
</div>
<div id="que-podemos-hacer" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> ¿Que podemos hacer?</h2>
<p>Tanto en las ciencias sociales, como en otras disciplinas han ido emergiendo una variedad de recomiendaciones y consejos que contribuyen a la adopción de la transparencia. Por ejemplo, <span class="citation"><a href="#ref-cruwell_Easy_2018" role="doc-biblioref">Crüwell et al.</a> (<a href="#ref-cruwell_Easy_2018" role="doc-biblioref">2018</a>)</span> propone formar investigadores y estudiantes a partir de la promoción de siete principales tópicos: entender la ciencia abierta; acceso abierto; la importancia de los datos, material y código abierto, los análisis reproducibles; los pre-registros; la replicación y, por último, la enseñanza de la ciencia abierta. De forma similar,…</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-abrilruiz_Manzanas_2019" class="csl-entry">
Abril Ruiz, Angel. 2019. <em><span class="nocase">Manzanas podridas: Malas prácticas de investigación y ciencia descuidada</span></em>.
</div>
<div id="ref-aczel_consensusbased_2020" class="csl-entry">
Aczel, Balazs, Barnabas Szaszi, Alexandra Sarafoglou, Zoltan Kekecs, Šimon Kucharský, Daniel Benjamin, Christopher D. Chambers, et al. 2020. <span>“A Consensus-Based Transparency Checklist.”</span> <em>Nature Human Behaviour</em> 4 (1): 4–6. <a href="https://doi.org/10.1038/s41562-019-0772-6">https://doi.org/10.1038/s41562-019-0772-6</a>.
</div>
<div id="ref-baker_500_2016" class="csl-entry">
Baker, Monya. 2016. <span>“1,500 Scientists Lift the Lid on Reproducibility.”</span> <em>Nature</em> 533 (7604): 452–54. <a href="https://doi.org/10.1038/533452a">https://doi.org/10.1038/533452a</a>.
</div>
<div id="ref-breznau_Does_2021" class="csl-entry">
Breznau, Nate. 2021. <span>“Does <span>Sociology Need Open Science</span>?”</span> <em>Societies</em> 11 (1): 9. <a href="https://doi.org/10.3390/soc11010009">https://doi.org/10.3390/soc11010009</a>.
</div>
<div id="ref-carey_Fraud_2011" class="csl-entry">
Carey, Benedict. 2011. <span>“Fraud <span>Case Seen</span> as a <span>Red Flag</span> for <span>Psychology Research</span>.”</span> <em>The New York Times</em>, November.
</div>
<div id="ref-christensen_Transparent_2019" class="csl-entry">
Christensen, Garret S., Jeremy Freese, and Edward Miguel. 2019. <em>Transparent and Reproducible Social Science Research: How to Do Open Science</em>. <span>Oakland, California</span>: <span>University of California Press</span>.
</div>
<div id="ref-cruwell_Easy_2018" class="csl-entry">
Crüwell, Sophia, Johnny van Doorn, Alexander Etz, Matthew C. Makel, Hannah Moshontz, Jesse Niebaum, Amy Orben, Sam Parsons, and Michael Schulte-Mecklenbeck. 2018. <span>“7 <span>Easy Steps</span> to <span>Open Science</span>: <span>An Annotated Reading List</span>,”</span> November. <a href="https://doi.org/10.31234/osf.io/cfzyx">https://doi.org/10.31234/osf.io/cfzyx</a>.
</div>
<div id="ref-elliott_Taxonomy_2020" class="csl-entry">
Elliott, Kevin C. 2020. <span>“A <span>Taxonomy</span> of <span>Transparency</span> in <span>Science</span>.”</span> <em>Canadian Journal of Philosophy</em>, 1–14. <a href="https://doi.org/10.1017/can.2020.21">https://doi.org/10.1017/can.2020.21</a>.
</div>
<div id="ref-fanelli_How_2009" class="csl-entry">
Fanelli, Daniele. 2009. <span>“How <span>Many Scientists Fabricate</span> and <span>Falsify Research</span>? <span>A Systematic Review</span> and <span>Meta</span>-<span>Analysis</span> of <span>Survey Data</span>.”</span> <em>PLOS ONE</em> 4 (5): e5738. <a href="https://doi.org/10.1371/journal.pone.0005738">https://doi.org/10.1371/journal.pone.0005738</a>.
</div>
<div id="ref-franco_Publication_2014" class="csl-entry">
Franco, A., N. Malhotra, and G. Simonovits. 2014. <span>“Publication Bias in the Social Sciences: <span>Unlocking</span> the File Drawer.”</span> <em>Science</em> 345 (6203): 1502–5. <a href="https://doi.org/10.1126/science.1255484">https://doi.org/10.1126/science.1255484</a>.
</div>
<div id="ref-john_Measuring_2012" class="csl-entry">
John, Leslie K., George Loewenstein, and Drazen Prelec. 2012. <span>“Measuring the <span>Prevalence</span> of <span>Questionable Research Practices With Incentives</span> for <span>Truth Telling</span>.”</span> <em>Psychological Science</em> 23 (5): 524–32. <a href="https://doi.org/10.1177/0956797611430953">https://doi.org/10.1177/0956797611430953</a>.
</div>
<div id="ref-oboyle_Chrysalis_2017" class="csl-entry">
O’Boyle, Ernest Hugh, George Christopher Banks, and Erik Gonzalez-Mulé. 2017. <span>“The <span>Chrysalis Effect</span>: <span>How Ugly Initial Results Metamorphosize Into Beautiful Articles</span>.”</span> <em>Journal of Management</em> 43 (2): 376–99. <a href="https://doi.org/10.1177/0149206314527133">https://doi.org/10.1177/0149206314527133</a>.
</div>
<div id="ref-simmons_FalsePositive_2011" class="csl-entry">
Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. 2011. <span>“False-<span>Positive Psychology</span>: <span>Undisclosed Flexibility</span> in <span>Data Collection</span> and <span>Analysis Allows Presenting Anything</span> as <span>Significant</span>.”</span> <em>Psychological Science</em> 22 (11): 1359–66. <a href="https://doi.org/10.1177/0956797611417632">https://doi.org/10.1177/0956797611417632</a>.
</div>
<div id="ref-simonsohn_Pcurve_2014" class="csl-entry">
Simonsohn, Uri, Leif D. Nelson, and Joseph P. Simmons. 2014. <span>“P-Curve: <span>A</span> Key to the File-Drawer.”</span> <em>Journal of Experimental Psychology: General</em> 143 (2): 534–47. <a href="https://doi.org/10.1037/a0033242">https://doi.org/10.1037/a0033242</a>.
</div>
<div id="ref-steneck_Fostering_2006" class="csl-entry">
Steneck, Nicholas H. 2006. <span>“Fostering Integrity in Research: <span>Definitions</span>, Current Knowledge, and Future Directions.”</span> <em>Science and Engineering Ethics</em> 12 (1): 53–74. <a href="https://doi.org/10.1007/PL00022268">https://doi.org/10.1007/PL00022268</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>A raíz de esta definición, y también en base al código de conducta detallado por XX es que <span class="citation"><a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">Abril Ruiz</a> (<a href="#ref-abrilruiz_Manzanas_2019" role="doc-biblioref">2019</a>)</span> proponen a la siguiente definición: “la RCR es el conjunto de normas, habitualmente plasmadas en códigos de conducta, que pretenden ser una guía para que nuestras acciones se mantengan dentro de la integridad investigadora” (p.144).<a href="transparencia.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="reproducibilidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["transparency.pdf", "transparency.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
