# Transparencia

```{r setup, include=FALSE}
if (!require("pacman")) install.packages("pacman")  #si falta pacman, instalar
if (!require("tinytex")) install.packages("tinytex")#si falta tinytex, instalar
pacman::p_load(knitr, kableExtra, dplyr, ggplot2,sjmisc,texreg) # librerias
knitr::opts_chunk$set(
	fig.pos = "H",
	message = FALSE,
	warning = FALSE,
	cache = FALSE,
	out.width = "85%"
)
options(scipen=999) # notacion cientifica
rm(list=ls())       # limpiar workspace
options(knitr.kable.NA = '') # NA en kable = ''
```

Esta sección tratará sobre la transparencia en la investigación científica, haciendo énfasis en las ciencias sociales. Nuestro objetivo es poder comunicar de forma clara y concisa tres puntos: a) qué es la transparencia, b) por qué la necesitamos y c) cómo podemos adoptarla. En esta sección profundizaremos en los dos primeros puntos. Respecto al tercer punto, entregaremos algunos consejos y recomendaciones que se han dado en la literatura, para después, en la siguiente sección, profundizar en torno a las herramientas que nos permitirían adoptar la transparencia. La tónica de este escrito es la práctica, es decir; todo lo que presentemos acá tiene la finalidad de servir de camino para poder aprender y aprehender herramientas que promueven la transparencia. Dicho esto, comencemos con los dos primeros puntos.

## ¿Qué es la transparencia?

Nuestro punto de partida es que la transparencia es un concepto amplio y multidimensional. Por eso, antes de adentrarnos en sus dimensiones, comencemos con una definición de diccionario. Según la Real Academia Española la transparencia es la cualidad de un cuerpo que permite ver a través de él. Un ejemplo para llevar esta definición a la práctica es el vidrio de una ventana. La transparencia del vidrio nos permite ver con claridad lo que está el otro lado, como por ejemplo un paisaje. No obstante, ¿qué ocurre cuándo la transparencia del vidrio se va perdiendo? La respuesta es simple, pero potente: la claridad con la que veíamos el paisaje se va difuminando. Esta pérdida de claridad puede dar como resultado que nuestra observación del paisaje se torne ambigua y errónea, o dicho de otro modo, cada vez será más difícil analizar el paisaje. Desde este ejemplo se podría plantear un símil con la ciencia; el paisaje equivale al proceso de producción científica, y el vidrio representa la claridad con la que podemos analizar este proceso. De esta manera, la base de la idea de transparencia es que permite analizar con claridad un fenómeno, una situación, o en este caso, un proceso.

¿Qué implica un proceso científico transparente? Ya existen algunas respuestas a esta pregunta. Por ejemplo, @breznau_Does_2021 entiende la transparencia como una forma en que los investigadores pueden revelar el proceso, ideas y materiales que sustentan un argumento o una teoría, con tal de contribuir a una comunidad científica más ética. Otra perspectiva es la de @aczel_consensusbased_2020, quienes proponen a la transparencia como un principio que permite evaluar y reproducir los hallazgos científicos, así como también a sintetizar investigaciones y contribuir a la ejecución de metaanálisis. @klein_Practical_2018 proponen que la credibilidad de los productos científicos dependen de la transparencia en la que se basan y que, en consecuencia, avanzar hacia la transparencia simplemente significa adoptar ciertas prácticas de gestión de la investigación que la hagan menos propensa a errores y más reproducibles. Estas perspectivas son una primera aproximación a las implicancias de un proceso científico transparente, no obstante, no representan una presentación exhaustiva del concepto.

Volvamos a nuestro planteamiento inicial: la transparencia es un concepto multidimensional. Para abarcar las múltiples formas que puede adoptar, nos basamos en la taxonomía de @elliott_Taxonomy_2020. La taxonomía se estructura en torno a cuatro preguntas: _¿por qué?, ¿quién? ¿qué? y ¿cómo?_ Cada una de estas preguntas tiene al menos una dimensión asociada. La primera pregunta (_¿por qué?_) se refiere a los propósitos por los cuales es necesario adoptar la transparencia; la segunda pregunta (_¿quién?_) apunta a la audiencia que está recibiendo la información; la tercera pregunta (_¿qué?_) hace alusión al contenido qué es transparentado y la cuarta pregunta (_¿cómo?_) consiste en cuatro dimensiones distintas sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y espacios. También, la taxonomía propone una dimensión sobre las amenazas que podrían afectar a las iniciativas que busquen promover la transparencia. Una representación gráfica puede verse en la Figura N° \@ref(fig:taxonomy).

```{r taxonomy, echo=FALSE, fig.cap="Taxonomía de Transparencia", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/taxonomy.png")
```

Para comprender mejor la taxonomía la Tabla N° \@ref(tab:tabtax) presenta una versión detallada de cada dimensión en conjunto a una lista no exhaustiva de variaciones. Al igual que la Figura N° \@ref(fig:taxonomy), la tabla está organizada en dimensiones asociadas a una pregunta, la diferencia es que aquí se añaden ciertas situaciones que ejemplifican cada dimensión de la transparencia, además de que hemos añadido la pregunta "¿Qué podría afectar iniciativas de transparencia?" para comunicar de mejor manera la dimensión de amenazas. Partiendo por la dimensión del **propósito** la cual sintetiza varios de los puntos que ya se han señalado en la literatura sobre ciencia abierta: la transparencia contribuye a formar una ciencia más replicable, facilita la interacción crítica, facilita el reanálisis de resultados, entre otros. La mayoría de estos propósitos están estrechamente relacionados con el horizonte de una ciencia con mayor credibilidad, cuestión que profundizaremos en breve. Luego, la dimensión de la **audiencia** nos muestra distintos sujetos que podrían recibir la información transparentada, como otros científicos, desarrolladores de política pública o también el público general.
La dimensión de los **contenidos** es una que queremos recalcar. Aquí, los distintos contenidos que pueden ser transparentados van desde cosas complejas como los juicios de valor o factores que podrían influenciar las interpretaciones de resultados, hasta lo más concreto como datos, métodos y materiales, o en otras palabras, el diseño de investigación.

Además de las tres dimensiones anteriores, contamos con cuatro dimensiones que están asociadas a la pregunta por el *¿cómo?* promover la transparencia. La primera dimensión es la de los **actores** que tienen el potencial de promover la transparencia, tales como periodistas o científicos. La segunda dimensión se trata de los **espacios** donde la transparencia puede ser promovida, donde algunos ejemplos son la divulgación científica, reportes de agencias gubernamentales o los repositorios que albergan la información transparentada. En tercer lugar, está el **marco temporal** en donde se puede optar por promover la transparencia. Aquí es variado, la transparencia puede ser ejercida tanto antes, durante o después del proceso de investigación a través de herramientas distintas y con implicancias distintas. Por ejemplo, en este documento nos centramos en la transparencia del diseño de investigación a través de los preregistros, lo que, generalmente, cabría dentro del antes de la investigación. Por último, están los mecanismos a través de los cuáles la transparencia puede ser ejercida, como en las colaboraciones interdisciplinares o en iniciativas gubernamentales.

La última dimensión sobre las **amenazas** trata sobre ciertas situaciones que podrían afectar las iniciativas sobre transparencia. Un ejemplo bastante esclarecedor es el causar confusión dada la cantidad de información y herramientas que están detrás de las iniciativas para la transparencia. Es por eso que, tener en cuenta estas amenazas permite anticipar los posibles problemas y orientar la ejecución de las iniciativas para evitarlos. Por ejemplo, este manual busca evitar causar confusión al presentar solamente algunas de las herramientas que existen para adherir a la transparencia y la reproducibilidad en la investigación en ciencias sociales.

```{r tabtax, echo=FALSE}
# Función para que las tablas renderizen tanto en html como pdf
table_format = if(is_html_output()) { # Usar en argumento "format=" de kable
  "html"
} else if(is_latex_output()) {
  "latex"
}

# Título tabla
cap1 <- "Variaciones por cada dimensión de transparencia"

# Crear tabla
tabtax <- read.csv(file = "input/tables/tabtax.csv",header = 1,sep = ",",encoding = "UTF-8") # Leer .csv con la estructura de la tabla
cnames <- c("Pregunta","Dimensión","Variaciones") # Nombres de las columnas
kable(tabtax,table_format,booktabs = T, linesep = "",col.names = cnames, caption = cap1) %>%
  kable_styling(
    full_width = T,
    latex_options = c("hold_position"), # Argumento para fijar la tabla en esta seccón del documento.
    position = "center",
    font_size = 10,
    bootstrap_options=c("striped", "bordered")) %>%
  column_spec(column = 1, width = "8 cm", ) %>%
  column_spec(column = 2,width = "5 cm") %>%
	column_spec(column = 3,width = "5 cm") %>%
  collapse_rows(columns = 1:2,valign = "middle") # Para colapsar filas que tengan el mismo contenido
```

En síntesis, un proceso de investigación transparente es uno que se puede evaluar con claridad y facilidad. La taxonomía de @elliott_Taxonomy_2020 nos ayuda a comprender la diversidad de dimensiones en las que se puede pensar la idea de transparencia. Ahora conocemos un poco más sobre la transparencia y lo que han dicho algunas voces de la literatura, no obstante, probablemente esté pensando algo como "Sí, tiene sentido que la transparencia contribuya a una ciencia mejor, pero ¿de verdad vale el esfuerzo y el tiempo de adoptar todas estas prácticas? La ciencia parece estar bien como está" Es un pensamiento razonable, sin embargo, la comunidad de adherentes a la ciencia abierta y la literatura asociada han adoptado el discurso de que efectivamente es necesario cambiar la forma que estamos haciendo hoy en día. Ha emergido la narrativa de que la ciencia está en crisis.

### ¿Crisis en las ciencias? {-}

En los últimos años, ha venido tomando fuerza la idea de que existe una crisis en la ciencia. Esta idea se basa en el diagnóstico de que gran parte de los artículos científicos en distintas disciplinas no son posibles de reproducir ni replicar [e.g. @wilson_Replication_1973; @camerer_Evaluating_2018]. Tanto la reproducibilidad (emplear el mismo diseño y datos para reproducir los hallazgos de un artículo) o la replicabilidad (emplear el mismo diseño y distintos datos para obtener los mismos resultados) son componentes centrales de la ciencia. Gran parte del avance del conocimiento científico recae en la verificabilidad de sus hallazgos, por lo que si estos no se pueden poner a prueba es más difícil confiar en la ciencia. La pregunta es ¿existe realmente una crisis en las ciencias?

Unas de las fuentes más comúnmente citadas para introducir la idea de crisis es una encuesta realizada en la revista _Nature_. En esta encuesta, @baker_500_2016 logró obtener las opiniones de poco más de 1,500 investigadores de disciplinas como la química, ingeniería y la medicina, sobre tópicos relacionados a la reproducibilidad en las ciencias. El resultado principal muestra que un **90% de los encuestados está de acuerdo en la existencia una crisis**, donde un 52% piensa que es una gran crisis y un 38% la percibe como una ligera crisis. En este mismo estudio, se les pregunta por los factores que contribuyen a esta crisis, donde la cultura del _pública o perece_ y el _reporte selectivo de resultados_ aparecen como los protagonistas. Si bien la encuesta no es una muestra representativa de toda la comunidad científica, presenta una panorámica que lleva a, por lo menos, considerar la crisis de la ciencia como tema que merece atención.

Actualmente, existe un cuerpo de literatura que se ha dedicado diagnosticar y proponer alternativas de solución ante la idea de una ciencia en crisis. Dentro del diagnóstico, variados estudios han orientado sus esfuerzos a esclarecer cuáles son los factores que podrían estar influenciando esta crisis. En línea con los resultados de @baker_500_2016, es posible plantear dos áreas: una relacionada al modelo de producción científica actual, donde los incentivos por publicar[@angell_Publish_1986], los criterios de ascenso en la jerarquía [@flier_Faculty_2017] académica y el formato de la revisión por pares contribuyen [@chambers_Registered_2013] a generar una cultura del _pública o perece_ que fuerza a los investigadores a aumentar su productividad académica; y otra relacionada a la flexibilidad (también conocida como grados de libertad) que tienen los investigadores a la hora de realizar investigaciones, generando la oportunidad para prácticas académicas que pueden afectar la credibilidad de los resultados [@christensen_Transparent_2019]. En esta sección, nos centraremos en la dimensión de las prácticas de investigación.

Comencemos con las prácticas de investigación. Para esquematizar de mejor manera qué es lo problemático de ciertas prácticas, es que utilizamos el esquema conceptual de @steneck_Fostering_2006. El esquema parte de una distinción básica entre la _ética en investigación_ y la _integridad en investigación_, englobando ambas bajo el concepto de _Conducta Responsable de Investigación (RCR)_ (ver Figura N° \@ref(fig:rcr). A grandes rasgos, la RCR se puede entender como el "llevar a cabo la investigación de forma que se cumplan las responsabilidades profesionales de los investigadores, tal y como las definen sus organizaciones profesionales, las instituciones para las que trabajan y, en su caso, el gobierno y el público" [@steneck_Fostering_2006]. En palabras simples, una conducta integra es atenerse a un conjunto de reglas sobre conducta científica.

```{r rcr, echo=FALSE, fig.cap="Conducta Responsable de Investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/rcr.png")
```
Dentro de la RCR, la ética de investigación está relacionada al comportamiento académico visto desde la óptica de los principios morales [@steneck_Fostering_2006], lo que se expresa en tópicos como el uso de datos, los consentimientos informados o el trato con pacientes -en el caso de las ciencias biomédicas-, por dar algunos ejemplos. La definición que ofrece @steneck_Fostering_2006 señala que la ética de investigación se define como "el estudio crítico de los problemas morales asociados o que surgen en el curso de la investigación" (p.56) En cambio, la integridad en investigación se entiende como "poseer y adherirse firmemente a las normas profesionales, tal y como las señalan las organizaciones profesionales, las instituciones de investigación y, en su caso, el gobierno y el público" [@steneck_Fostering_2006, p.56]. A diferencia de la ética de investigación, el concepto de integridad está regido por los estándares profesionales más que por los principios morales, su función es plantear una guía clara para la conducta investigativa, de ahí que sea el concepto utilizado por distintos códigos de conducta [ver @abrilruiz_Manzanas_2019].

```{r grad, echo=FALSE, fig.cap="Gradación del comportamiento integro en investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/grad.png")
```
Habiéndonos situado dentro del concepto de integridad en la investigación, podemos pasar a delinear las principales prácticas que atentan contra él y que se han propuesto como factores que contribuyen a la crisis en la ciencia. Tanto @steneck_Fostering_2006 como distintos códigos de conducta de universidades e instituciones de financiamiento [ver @abrilruiz_Manzanas_2019] evalúan las prácticas de investigación en un continuo, que representa cuánto adhieren los investigadores a los principios de integridad científica. La Figura N° \@ref(fig:grad) esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derecha el peor comportamiento (FFP). Las FPP son una abreviación en lengua inglesa para referirse a _Fabrication, Falsification, Plagiarism_ (Invención, Falsificación y Plagio), también conocidas como _mala conducta académica_-. En el medio del continuo están las _prácticas cuestionables de investigación_ (QRP, por sus siglas en inglés) las cuáles refieren a "acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación" [_National Academies of Science_ 1992 en @steneck_Fostering_2006, p.58]. Las QRP se caracterizan porque tienen el potencial de dañar la ciencia, en tanto las FFP la dañan directamente.

Comprendidos ambos conceptos, veamos las situaciones que podrían categorizarse como FFP y las que podrían concebirse como QRP.

### Mala conducta académica (FFP) {-}

La mala conducta académica suelen ser situaciones polémicas y que muchas veces alcanzan gran cobertura mediática. El libro de @abrilruiz_Manzanas_2019 hace una revisión de una serie de situaciones, en distintas disciplinas y años, en las que investigadores han sido descubiertos cometiendo prácticas que atentan directamente a la ciencia. Las situaciones son variadas, existen casos de manipulación de imágenes, exageración de registros de laboratorio, o de plano la invención de conjuntos de datos enteros. En esta sección veremos el caso de Diderik Stapel como ejemplo de malas prácticas de investigación y plantearemos la relación que tiene con la transparencia en la investigación.

#### El caso de Diderik Stapel {-}

Probablemente, el caso de Diderik Stapel sea uno de los más emblemáticos y representativos de este problema. Diderik Stapel era un investigador de la _Tilburg University_ que se dedicaba al campo de la psicología social. Su carrera se caracterizó por una trayectoria ejemplar, obtuvo su M.A en psicología y comunicaciones el año 1991, se doctoró en psicología social el año 1997 y trabajó como profesor asociado primero en la _University of Gronigen_ (2000-2006) y dede el 2006 en la Tilburg University. Fue fundador del _Tilburg Institute for Behavioral Economics Research_, del cuál el 2010 se convirtió en decano. Así también, fue galardonado con el premio a la trayectoria académica por la _Social of Experimental Social Psychology_. En breve, Stapel era una figura de alto estatus en el mundo académico, entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas científicas, algunas de las más prestigiosas (e.g. _Science_). Sin embargo, 	el año 2011 se confirmó que gran parte de su trayectoria académica era una farsa.

Después de la verificación de su culpa ante acusaciones de malas prácticas, la carrera de Diderik Stapel acabó. Fue desvinculado de la Tilburg University, se le revocó su título de doctorado y toda su trayectoria académica fue investigada acusiociamente. El informe final de la investigación encontró que más de 50 de sus artículos eran fraudulentos. De hecho, Stapel está dentro de las diez figuras con más artículos retractados (58) en _Retraction Watch_ (https://retractionwatch.com/), una plataforma que se dedica a sistematizar y mantener una lista actualizada sobre retracciones de artículos. A efectos de este escrito, lo que más destacable es que Stapel cometió conductas de mala conducta académica durante más de 15 años. La pregunta es ¿cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o coautores se dio cuenta de sus malas prácticas? La respuesta breve es por la falta de transparencia durante el proceso de investigación.

Los artículos periodísticos que han profundizado en el caso han relatado parte del proceso investigativo de Stapel [e.g. @carey_Fraud_2011]. Dentro de los procesos de producción y análisis de datos, Stapel se caracterizaba por hacer todo el trabajo solo y "a puertas cerradas". Es decir, nadie más que él tenía acceso a los datos brutos, ni tampoco a la ejecución de las pruebas estadísticas. Generalmente, Stapel compartía con sus colegas y alumnos de doctorado la base de datos lista, con las pruebas estadísticas ya hechas y, claro está, con resultados estadísticamente significativos. Estas prácticas no causaron sospechas durante muchos años, es más, a muchos de sus estudiantes les parecía una práctica normal y eficiente. Además, con el estatus de Stapel ¿qué podría estar mal? Sin embargo, era a raíz de esta práctica que Stapel tenía la oportunidad de inventar y falsificar datos a su conveniencia. Esto explica en gran parte de su trayectoria académica llena de grandes hallazgos y una producción académica increíble.

El caso de Stapel deja un punto importante sobre la mesa: la falta de transparencia en el proceso investigativo dio cabida a la mala conducta académica. Cómo nadie más colaboraba con el procesamiento de datos, ni tampoco parecía extraño que así fuera, las oportunidades para la falsificación de los datos estaban abiertas. Ahora, esta no es necesariamente una relación de causalidad, la falta de transparencia no tiene por qué terminar en conductas como fabricación o falsificación de datos. Sin embargo, tal y como lo argumentan @oboyle_Chrysalis_2017 si son una oportunidad para violaciones a la integridad científica más sutiles, tales como las QRP.

### Prácticas cuestionables de investigación (QRP) {-}

Recordemos, las QRP son prácticas que en si mismas no dañan directamente la empresa científica, pero si tienen el potencial de hacerlo. Son prácticas que alteran el correcto funcionamiento del método científico. En la literatura, existen una variedad de términos que se utilizan para describir las prácticas cuestionables, así como también distintas listas de prácticas que han emitido instituciones. @abrilruiz_Manzanas_2019 hace una recopilación y traducción de distintos códigos de conducta de distintas universidades y organismos, el cuál nosotros sistematizamos en la Tabla N° \@ref(tab:tabqrp). La tabla muestra un conjunto de prácticas divididos en cuatro categorías, de acuerdo con si las prácticas tienen que ver con: el diseño y el procesamiento de los datos, la redacción y el reporte de los resultados, temas de citación y uso de ideas ajenas y, por último, sobre relaciones con otros actores en el campo de la ciencia. Esta no es una lista exhaustiva de las QRP, sino que son solo algunas de las más comunes.

Veamos a qué se refiere cada dimensión. La primera dimensión refiere a todas aquellas QRP que afectan el diseño de investigación y el procesamiento de los datos de un artículo, como por ejemplo eliminar datos después de las pruebas de hipótesis, suprimir o adicionar selectivamente variables o reformular las hipótesis para que calcen con los resultados. La segunda dimensión apunta a los aspectos relacionados a la redacción, el reporte y la publicación de la investigación. En este apartado, podemos apreciar QRP que se relacionan al reporte selectivo de información (e.g. metodológica o de resultados) o a la forma en la que está escrito los resultados (e.g. exagerar la importancia de los resultados o tergiversar los logros de la investigación). La tercera dimensión se circunscribe al área de la propiedad intelectual y la autoría, donde las QRP tienen que ver con el uso de ideas sin dar crédito, o la asignación inapropiada de las autorías. Por último, identificamos una dimensión que tiene que ver con las relaciones con otros en el campo científico, donde las QRP se expresan en el incentivo o encubrimiento a cometer otro tipo de QRP, entre otros.

```{r tabqrp, echo=FALSE}
# Función para que las tablas renderizen tanto en html como pdf
table_format = if(is_html_output()) { # Usar en argumento "format=" de kable
  "html"
} else if(is_latex_output()) {
  "latex"
}

# Título tabla
cap1 <- "Algunas situaciones de QRP"

# Crear tabla
tab01 <- read.csv(file = "input/tables/tabqrp.csv",header = 1,sep = ",",encoding = "UTF-8") # Leer .csv con estructura de la tabla
cnames <- c("Dimensión","Práctica") # Nombre de las columnas
kable(tab01,table_format,booktabs = T, linesep = "",col.names = cnames, caption = cap1) %>%
  kable_styling(
    full_width = T,
    latex_options = c("hold_position"), # Argumento para mantener posición de la tabla en esta sección del documento
    position = "center",
    font_size = 10,
    bootstrap_options=c("striped", "bordered")) %>%
  column_spec(column = 1, width = "5 cm", ) %>%
  column_spec(column = 2,width = "5 cm") %>%
  collapse_rows(columns = 1:2,valign = "middle") # Para colapsar filas con el mismo contenido
```

No es difícil imaginar que las QRP que engloba la Tabla N° \@ref(tab:tabqrp) hayan ocurrido alguna vez. Probablemente, hemos escuchado la historia de algún conocido que se vio envuelto en cualquiera de estas situaciones o nosotros hemos sido parte de alguna de estas situaciones en algún momento de nuestra carrera académica. Sin embargo, más allá de la ocurrencia anecdótica de estas situaciones, es relevante preguntarse ¿son algo que ocurre seguido? En lo que viene daremos algunos antecedentes que permitan dar luz a esta pregunta.

Existen una serie de estudios que han intentado medir directamente la existencia de estas prácticas a través de encuestas. @fanelli_How_2009 hizo un metaanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez (FFP) y que un 33.7% había realizado alguna vez una QRP como "borrar puntos de los datos basados en un sentimiento visceral". Un estudio más reciente, también basado en encuestas cuantitativas sobre prácticas, es el de @john_Measuring_2012. En este estudio, los resultados mostraron que un 36.6% de quienes participaron alguna vez habían practicado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicólogos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipótesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Estos estudios son una primera aproximación a la existencia de las QRP en la ciencia.

Existen ciertas prácticas que han sido tratadas con más énfasis en la literatura, y que son las que queremos destacar acá. Por un lado, está el _sesgo de publicación_, el cual significa, a grandes rasgos, que un artículo es publicado en base a sus resultados. Específicamente, el sesgo de publicación ocurre cuando el criterio determinante para que un artículo sea publicado es que sus resultados sean significativos, en desmedro de la publicación de resultados no significativos. El estudio de @franco_Publication_2014 logra cuantificar esta situación bastante bien y esclarecer el _file drawer problem_ (en español: problema del cajón de archivos), que hace alusión a los resultados perdidos dentro de un cuerpo de evidencia [@christensen_Transparent_2019, p.39]. @franco_Publication_2014 encontraron que, efectivamente, los resultados nulos tienen un 40% menos de probabilidades de ser publicados en revistas científicas, en comparación a estudios con resultados significativos. Es más, muchas veces los resultados nulos ni siquiera llegan a ser escritos: más de un 60% de los experimentos que componen la muestra del estudio de @franco_Publication_2014 nunca llegaron a ser escritos, en contraste al menos del 10% de resultados significativos.

El principal problema del sesgo de publicación es que puede impactar en la credibilidad de cuerpos enteros de literatura. Existen ejemplos de cuerpos de literatura que se han hallado sesgados, como el _Value of Statistical Life_ (Valor de la Vida Estadística) y el de salario mínimo y desempleo, ambos en economía [para detalle ver p.42 y p.46 en @christensen_Transparent_2019]. También, a partir del desarrollo de distintos métodos de detección, se ha podido diagnosticar el sesgo de publicación en importantes revistas en economía [@brodeur_Star_2016], sociología y ciencias políticas [@gerber_Publication_2008; @gerber_Statistical_2008].

Otra práctica bastante cuestionada es el _p-hacking_, que de forma literal sería un "hackeo" de los valores p. El _p-hacking_ se da cuando el procesamiento de los datos tiene por objetivo obtener resultados significativos. Si el sesgo de publicación afecta la credibilidad de un cuerpo de literatura, el _p-hacking_ afecta a la credibilidad de los artículos mismos, ya que al forzar la significancia estadística la probabilidad de que en realidad estemos frente a un falso positivo aumenta. Un trabajo que da sustento a esta idea es el de @simmons_FalsePositive_2011, quienes calculan la posibilidad de obtener un falso positivo (error Tipo I) de acuerdo con el nivel de manipulación intencionada de los datos. El resultado principal es que a medida que aumenta la cantidad de manipulación en los datos, la posibilidad de obtener un falso positivo aumenta progresivamente.

El _p-hacking_ también contribuye a sesgar cuerpos enteros de literatura. Para diagnosticar esto se ha utilizado una herramienta denominada _p-curve_, la cual "describe la densidad de los _p-values_ reportados en una literatura, aprovechando el hecho de que si la hipótesis nula no se rechaza (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1" [@christensen_Transparent_2019, p.67.]. De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de p-values debería estar cargada a la izquierda (siendo precisos, asimétrica a la derecha), en cambio, si existe sesgo por p-hacking la distribución de p-values estaría cargada a la derecha (asimetría a la izquierda). @simonsohn_Pcurve_2014 proponen esta herramienta y la prueban en dos muestras de artículos de la _Journal of Personality and Social Psychology (JPSP)_. Las pruebas estadísticas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipótesis, en detalle, los artículos que presentaban solamente resultados con covariables resultaron tener una p-curve cargada a la derecha (asimétrica a la izquierda).

Por último, pero no menos importante existe la práctica del _HARKing_. El nombre es una nomenclatura en lengua inglesa: _Hypothesizing After the Results are Known_, que literalmente significa establecer las hipótesis del estudio una vez que se conocen los resultados. El principal problema de esta práctica es que confunde los dos tipos de razonamiento que están a la base de la ciencia: el exploratorio y el confirmatorio. El objetivo principal del razonamiento exploratorio es plantear hipótesis a partir de un análisis de datos. En cambio, el razonamiento confirmatorio busca plantear hipótesis basado en teoría y contrastar esas hipótesis con datos empíricos. Como señala @nosek_preregistration_2018, cuando se confunden ambos tipos de análisis y se hace pasar un razonamiento exploratorio como confirmatorio se está cometiendo un sesgo inherente, ya que se está generando un razonamiento circular: se plantean hipótesis a partir del comportamiento de los datos y se confirman las hipótesis con esos mismos datos.

## ¿Qué se ha hecho? 

Tanto en las ciencias sociales, como en otras disciplinas han ido emergiendo una variedad de recomendaciones que contribuyen a la adopción de la transparencia. Por ejemplo, @cruwell_Easy_2018 propone formar investigadores y estudiantes a partir de la promoción de siete principales tópicos: entender la ciencia abierta; acceso abierto; la importancia de los datos, material y código abierto, los análisis reproducibles; los pre-registros; la replicación y, por último, la enseñanza de la ciencia abierta. Cada uno de estos tópicos son un paso para lograr avanzar hacia una ciencia más abierta y transparente. De forma similar, @miguel_Promoting_2014 enfatiza en tres ideas: el _disclosure_ (divulgación), los pre-registros y los datos y materiales abiertos. La divulgación consta de que los investigadores deben declarar todo tipo de procesamiento realizada a los datos y detallar como se llégó a las muestras finales. Los preregistros son una forma de ser más transparente con los procedimientos y dividir los tipos de formulación de hipótesis. Los datos y materiales abiertos permiten que otros investigadores puedan reproducir el trabajo, hacer otras pruebas de hipótesis, identificar malas prácticas etc. También @lindsay_Seven_2020 discute los efectos que tienen el sesgo de publicación y otras prácticas similares en la credibilidad de la ciencia, proponiendo siete pasos para mejorar la transparencia: decir la verdad, por ejemplo, si la idea de investigación surgió analizando datos plantearlo de esa manera; evaluar la comprensión de la estadística inferencial; estandarizar la aproximación para probar las hipótesis, por ejemplo, realizar un plan de análisis; hacer un manual de laboratorio (en el caso de diseños experimentales); hacer abiertos los materiales, datos y análisis; abordar las limitaciones de la generalidad de las conclusiones; y por último, considerar enfoques colaborativos para conducir investigaciones. A su vez, @oboyle_Chrysalis_2017 proponen tres simples consejos para hacer la ciencia más transparente: incluir una clausula ética en el envío de manuscritos que declaren no haber cometido QRP, qué todo artículo original (e.g. tesis doctoral) debe estar disponible para descarga y que las revistas cuenten con un espacio dedicado a replicación.

Una propuesta sistemática para adoptar la transparencia, que incluye varias de las recomendaciones mencionadas son las _Transparency and Openess Promotion (TOP) Guidelines_ (Guías para la Promoción de la Transparencia y la Accesibilidad). Estos son principios que buscan alcanzar un formato de investigación reproducible a través del aumento de la transparencia en el proceso y los productos de investigación [@nosek_Transparency_2014]. Estos principios sirven de guía tanto para la adopción de buenas prácticas en los investigadores, como para que las revistas académicas puedan adherir progresivamente al ideal de transparencia en la ciencia. Son ocho principios:

1. Citación
2. Transparencia de datos
3. Transparencia de métodos analíticos (código)
4. Transparencia de los materiales
5. Transparencia del diseño y el análisis
6. Preregistro de estudios
7. Preregistro de planes de análisis
8. Replicación

A grandes rasgos, el principio de citación propone que las normas de citado deben ampliarse también a los datos y códigos, permitiendo reconocer su autoría intelectual [@nosek_Promoting_2015]. Los principios de transparencia de datos, métodos analíticos, materiales y diseño y análisis (2 a 5) refieren a la transparencia en su forma más concreta: la apertura del proceso de investigación para su evaluación. El detalle puesto a los principios responde a la generalidad que se le busca dar a los principios. Por ejemplo, un estudio observacional cuantitativo no tiene material que transparentar, pero si datos y métodos analíticos. Así también, un estudio cualitativo quizás no tenga código que transparentar, pero si un diseño y una bitácora detalla del proceso de análisis. En el caso de los principios relacionados al preregistro, @nosek_Promoting_2015 argumenta que registrar los estudios los hace más descubribles, incluso si no son publicados. Así también, los preregistros del plan de análisis contribuyen a distinguir entre los análisis confirmatorios y exploratorios (ver @nosek_preregistration_2018 para un manejo detallado del tema). Por último, el principio de replicación fomenta las oportunidades para la corrección de artículos y redirecciona la investigación en vías más prometedoras [@nosek_Promoting_2015].

Cada uno de estos principios cuenta con tres niveles, que sirven para medir el grado de inclusión de la transparencia por parte de una revista científica [ver @nosek_Promoting_2015 para detalle]. La adopción de prácticas transparentes va desde el nivel 1, siendo lo menos transparente, hasta el nivel 3 siendo lo más transparente. Se añade un nivel 0 que no cumple los estándares de transparencia con la finalidad de tener una comparación. Por ejemplo, para los estándares de transparencia del método de análisis (código), el nivel 1 dicta que las revistas deben solicitar la existencia del código de análisis, en cambio, el nivel 3 es más estricto en plantear que el código de análisis debe estar almacenado en un repositorio confiable y que el análisis será reproducido durante el proceso de revisión. El mismo método se puede aplicar para la el preregistro del plan de análisis. En el nivel 1 las revistas promueven el uso de preregistros, en cambio, en el nivel 3 los preregistros son obligatorios y también reconocidos. En suma, las _TOP Guideliness_ son una iniciativa que contribuye a la apertura en la ciencia proponiendo nuevas prácticas para los requerimientos de las revistas.

Como podemos ver, en general las recomendaciones sobre transparencia giran en torno a los preregistros, los datos y materiales abiertos y la replicación. En la siguiente sección profundizaremos en los preregistros como una forma de aumentar la transparencia durante el proceso de investigación.

## Herramientas para los diseños transparentes

### Preregistros

Los preregistros son una marca temporal sobre las decisiones del diseño, el método y el análisis de un artículo científico y se suelen hacer antes del levantamiento de datos [@stewart_Preregistration_2020]. Básicamente, preregistrar un artículo o un proyecto implica que un grupo de investigadores dejarán por escrito una pauta de investigación a la cual se atendrán lo más posible cuando desarrollen la investigación, especialmente la recopilación y el análisis de los datos. Ahora ¿por qué habría de hacer algo así? Llevar a cabo una investigación ya es lo suficientemente complejo como para añadirle una tarea adicional. La respuesta es que, cómo señalamos en secciones anteriores, los preregistros son una herramienta que permite hacerle frente a las QRP y, a la larga, contribuir a la realización de una ciencia de mayor calidad.

Ciertamente, los preregistros no son la respuesta a cada una de las QRP existentes, pero si son una herramienta eficaz para evitar las más frecuentes. En secciones anteriores hablamos de los sesgos de publicación, el p-hacking y el HARKing pues, cada uno de ellos puede ser evitado a partir de un preregistro. Primero, vimos que el sesgo de publicación se trataba de publicar selectivamente los resultados de investigación: resultados que no hayan sido significativos, o hipótesis que "no funcionaron" simplemente se omiten. Sin embargo, cuando existe un documento como un preregistro, el cual deja estipulado claramente las hipótesis que deben ponerse a prueba y los análisis que se emplearan para ello, se torna más difícil reportar selectivamente los resultados. Dicho de otra forma, cuando existe una pauta a la cual apegarse, la discrecionalidad en el reporte de los resultados disminuye. En el caso del p-hacking, el efecto del preregistro es parecido. Cómo vimos, el p hacking consistía en abusar de las pruebas estadísticas para obtener resultados significativos. "Abusar" en el sentido de buscar toda vía posible para obtener un valor p que confirme las hipótesis planteadas. El hecho de preregistrar el plan de análisis y el procesamiento que se le efectuara a las variables permite evitar este tipo de búsqueda intencionada: como hay una guía que seguir, cualquier desviación debe ser justificada. En esta misma línea, un preregistro evita el HARKing ya que las hipótesis están previamente planteadas y no es posible cambiarlas una vez que se han visto los resultados. En suma, el plantear un registro _a priori_ de la investigación, disminuye la flexibilidad que suele dar paso a las QRP.

Si bien los preregistros pueden ser una herramienta en contra de las QRP, existen resquemores de los que es preciso hacerse cargo. Una de las principales preocupaciones es que el uso de preregistros tendería a coartar la creatividad y la producción de conocimiento exploratoria [@moore_Preregister_2016]. La lógica es que, como cada parte de la investigación debe ser registrada detalladamente previo a la recopilación, no queda espacio para la espontaneidad durante el análisis de datos. Nada puede estar más lejos del sentido de un preregistro. Más que inhibir la investigación exploratoria, el objetivo de especificar una pauta a priori es poder separar lo que es la investigación confirmatoria (pruebas de hipótesis) y la exploratoria (generación de hipótesis) [@nosek_preregistration_2018]. En ese sentido, es posible la investigación exploratoria bajo el modelo de preregistros, solo que hay que especificarla como tal. Una segunda creencia es que realizar un preregistro añade un nivel de escrutinio mayor del necesario, es decir, como se conoce cada detalle, la investigación se vuelve un blanco fácil de críticas. Sin embargo, la situación es todo lo contrario [@moore_Preregister_2016], por ejemplo, haber preregistrado un plan de análisis para una regresión logística binaria con datos que originalmente eran ordinales hará más creíble los resultados, ya que quienes evalúen la investigación tendrán pruebas de que el nivel de medición no se cambió solo para obtener resultados significativos. Una tercera idea en torno a los preregistros es que conllevan una gran inversión de tiempo y energía. Si bien es cierto que se añade un paso más al proceso de investigación, el avance en la temática ha logrado que existan una variedad de plantillas que hacen el proceso más rápido y eficiente. Desde una lógica racional, el tiempo que toma este paso nuevo en la investigación es un costo bajo en contraste a los beneficios que trae.

Una característica principal de los preregistros es que deben ser efectuados previo a la recolección de datos. Este requisito es lo que permite asegurar la credibilidad de los resultados, ya que, si no hay datos que alterar, entonces las probabilidades de que ocurra una QRP son básicamente nulas. Generalmente, para las ciencias médicas o la psicología experimental (disciplinas donde cada vez se usan más los preregistros), esto no suele ser un problema ya que se utilizan diseños experimentales. Los diseños experimentales se apegan al método científico clásico: se plantean hipótesis basadas en la teoría, se diseña un experimento para probar esas hipótesis y luego se recopilan y analizan los datos para ver si dan soporte a las hipótesis planteadas. Sin embargo, ¿qué ocurre cuando trabajamos con datos preexistentes? En muchas disciplinas de las ciencias sociales los diseños experimentales son una pequeña fracción del conjunto de la literatura [e.g. según @card_Role_2011 en 2010, un 3% de los artículos en las mejores revistas de economía eran experimentales], donde lo que prima son los diseños observacionales, los que suelen trabajar con datos administrativos o generados a partir de censos o encuestas. A diferencia de los estudios experimentales, los cuales deben generar de primera fuente el experimento que les permita testear sus hipótesis, en los estudios observacionales se utilizan datos ya existentes, lo cual afecta al principal componente de credibilidad de los preregistros: nada puede asegurar que los datos fueron analizados antes de la escritura del preregistro y que, por ejemplo, las hipótesis se están planteando una vez conocidos los patrones significativos (HARKing). De ahí que nace la pregunta sobre la posibilidad (y la utilidad) de utilizar preregistros en estudios con datos preexistentes.

En la literatura sobre preregistros se han discutido los desafíos que implica preregistrar estudios que utilicen datos preexistentes [e.g. @editors_Observational_2014]. Existen posturas que proponen que, en realidad, no existe una forma creíble para preregistrar este tipo de estudios [@christensen_Transparency_2018]. No obstante, otras posturas han profundizado en las situaciones en las que aún es posible preregistrar estudios con datos elaborados previamente. @burlig_Improving_2018 propone tres escenarios donde el preregistro de datos observacionales es valioso. El primero es, básicamente, cuando los investigadores que diseñaron la investigación generan sus propios datos, en este caso, los investigadores sí pueden elaborar un preregistro previo a la recolección de datos. El segundo escenario se da cuando se preregistra un estudio que tiene como objeto de interés un suceso que aún no ha ocurrido, lo que se conoce como estudios prospectivos. Por ejemplo, un grupo de investigadores puede estar interesado en el efecto que tendrá la introducción de una ley en las prácticas sociales, o el efecto de un tratado en las variaciones del PIB. Para esos casos, el preregistro aún mantiene su validez original ya que, si bien los datos ya existen, no es posible hacer los análisis antes del preregistro porque el evento de interés no ha ocurrido. El tercer escenario ocurre cuando los datos existen, pero no están abiertos al público. En estos casos, es la accesibilidad lo que determina la credibilidad del preregistro. Por ejemplo, el grupo de investigadores que elaboraron los datos pueden establecer que serán accesibles con previo contacto y que se solicitará un preregistro. Por ende, en orden de analizar los datos, los investigadores interesados deberán elaborar un preregistro para utilizar los datos. Según @mertens_Preregistration_2019, también se pueden adoptar ciertas prácticas para asegurar la credibilidad de un preregistro con datos secundarios. Dos de ellas son: que el grupo de investigadores que analiza los datos sea distinto e independiente de quien propuso el diseño de investigación y que el equipo realice sintaxis de análisis con datos simulados, con tal de demostrar que las hipótesis ya existían previas a acceder a los datos. En suma, lo que permite mantener el efecto "puro" de un preregistro, es que los datos no hayan sido observados por ningún integrante del grupo de investigación que los analizará [@nosek_preregistration_2018].

El principio básico de un preregistro entonces es que los datos no deben haber sido observados previos al análisis. Sin embargo, según @nosek_preregistration_2018 aún pueden existir ciertos sesgos en el planteamiento de hipótesis a raíz de cosas como el reporte de resultados descriptivos de la base de datos o las recomendaciones sobre cómo aproximarse a la base de datos. Este tipo de influencias son un poco más sutiles y es difícil deshacerse completamente de ellas. Es por esto que, quizás la recomendación más transversal y a la vez simple para preregistrar análisis con datos secundarios, es ser sincero y detallado respecto a lo que se ha hecho y lo que no [@nosek_preregistration_2018]. Si es que se ha leído el reporte descriptivo sobre la base de datos, estipularlo como tal. Es preciso transparentar cualquier tipo de aproximación a los datos previo haberlos analizados. Para lograr este nivel de detalle y ser eficiente con los tiempos y la comunicación hacia otros investigadores, es que existen plantillas predeterminadas para preregistrar distintos tipos de artículos. A continuación, describiremos algunas de las más usadas.

### Manos a la obra: cómo utilizar un preregistro

En la práctica, preregistrar un artículo es básicamente sintetizar la información importante sobre nuestra investigación en una plantilla estandarizada y alojar ese documento en un lugar público. Por lo que el primer paso para elaborar un preregistro es elegir la plantilla correcta. Existen plantillas estandarizadas, que están estructuradas de tal forma que son útiles para preregistrar estudios de cualquier disciplina, así como también existen plantillas dedicadas a una disciplina o un conjunto de ellas. En la Tabla N° \@ref(tab:tabprereg) se pueden ver algunas de las plantillas más usadas según @stewart_Preregistration_2020. Primero está el conjunto de plantillas que ofrece el Open Science Framework (OSF) dependiendo de las características específicas del estudio. Luego, encontramos a la plantilla de AsPredicted que se caracteriza por su simpleza: son solo nueve preguntas que buscan recopilar la información sustancial para el preregistro de un artículo. También, están las plantillas de PROSPERO, ISRCTN y Bio-Protocol que se utilizan más en el campo de las ciencias biológicas o médicas. PROSPERO se focaliza en artículos de tipo _review_ que tengan relación con la medicina, en tanto IRCTN busca ser una primera instancia de registro para ensayos clínicos. Bio-Protocol por su parte busca dejar el registro de protocolos detallados en la investigación biológica, con tal de complementar la sección de Método en los artículos. Las plantillas de AEA RCT, RIDIE y EGAP están más relacionadas a las ciencias sociales y áreas afines. La AEA RCT se focaliza en diseños experimentales para ciencias sociales, en tanto RIDIE es una herramienta para evaluaciones de impacto. EGAP busca ser una plantilla específica para temas de gobernanza y política. Como podemos ver, todas las plantillas tienen su campo de aplicación, sin embargo, aquí nos centraremos en las dos más universales y conocidas: OSF y AsPredicted.

```{r tabprereg, echo=FALSE}
# Función para que las tablas renderizen tanto en html como pdf
table_format = if(is_html_output()) { # Usar en argumento "format=" de kable
  "html"
} else if(is_latex_output()) {
  "latex"
}

# Título tabla
cap1 <- "Plantillas de preregistro"

# Crear tabla
tab01 <- read.csv(file = "input/tables/tabprereg.csv",header = 1,sep = ",",encoding = "UTF-8") # Leer .csv con estructura de la tabla
cnames <- c("Plantilla","Proposito", "Discplina/Área") # Nombre de las columnas
kable(tab01,table_format,booktabs = T, linesep = "",col.names = cnames, caption = cap1) %>%
  kable_styling(
    full_width = T,
    latex_options = c("hold_position"), # Argumento para mantener posición de la tabla en esta sección del documento
    position = "center",
    font_size = 10,
    bootstrap_options=c("striped", "bordered")) %>%
  column_spec(column = 1, width = "5 cm", ) %>%
  column_spec(column = 2,width = "5 cm") %>%
  collapse_rows(columns = 1:2,valign = "middle") # Para colapsar filas con el mismo contenido
```


Como bien se ha señalado en otras partes de este libro, el Open Science Framework (OSF) es tanto una herramienta para la colaboración, que permite hacer públicos distintos tipos de proyectos; como un modelo de flujo de trabajo que hace más eficiente el proceso de investigación al centralizar herramientas como GitHub, Google Docs etc. Dentro de estas funciones se encuentra la el servicio de preregistros. En la línea de lo que hemos señalado hasta ahora, con este servicio OSF busca fomentar la transparencia y reproducibilidad en la investigación. Vamos viendo paso a paso como ingresar un preregistro en OSF.

El primer paso es acceder a la sección especifica de preregistros de la página de OSF, la cual se encuentra en el siguiente link: https://osf.io/prereg/. Para usar este servicio es necesario tener una cuenta, cuestión que no profundizaremos aquí. Si entramos al link con una cuenta recién hecha, la apariencia de la página será algo como la Figura N° \@ref(fig:osfprereg1). En la página veremos una barra superior con opciones asociadas a la cuenta y en el centro veremos un gran botón azul con forma rectangular el cual nos da la opción de comenzar un preregistro. En el caso de acceder con una cuenta que ya tiene proyectos, OSF nos dará la opción de preregistrar un proyecto ya existente. Seleccionemos _Start a new preregistration_, le damos un nombre y hacemos click en _Continue_, lo que nos llevará a la siguiente página, representada en la Figura N° \@ref(fig:osfprereg2). En la página, podemos ver que hemos creado un proyecto nuevo en OSF, el cual nos da la opción de preregistrarlo haciendo click en el botón _New registration_.



```{r osfprereg1, echo=FALSE, fig.cap="Preregistros en OSF", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/osfprereg1.png")
```

```{r osfprereg2, echo=FALSE, fig.cap="Preregistros en OSF 2", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/osfprereg2.png")
```

En la Figura N° \@ref(fig:osfprereg3) podemos ver dos cosas. Primero, la descripción de lo que está haciendo OSF al comenzar un nuevo preregistro, lo que en pocas palabras es una versión no modificable del proyecto al momento que hacemos el preregistro. Tal y como dice la página es una versión "congelada". En segundo lugar, también se aprecia una serie de opciones para preregistrar, estas son las plantillas que habíamos mencionado anteriormente. OSF nos ofrece distintas plantillas de acuerdo con el carácter que tiene nuestro estudio. Una breve descripción de cada una es la siguiente:


- OSF Preregistration: Es la plantilla estándar, en la cual se hacen una serie de preguntas relativas al muestreo, diseño y planes de análisis.

- Open-Ended Registration: Consiste en una síntesis narrativa de la investigación a preregistrar. No hay un minimo de palabras para el documento.

- Qualitative Preregistration: Plantilla elaborada por la comunidad de investigadores cualitativos para preregistrar estudios cualitativos.

- Secondary Data Preregistration: También consiste en una serie de preguntas relativas al muestro, diseño y planes de análisis, con algunas pequeñas variaciones.

- Registered Report Protocol Preregistration: Hace unas cuantas preguntas relativas al estudio y permite adjuntar el manuscrito. Esta plantilla se utiliza cuando se está intentando publicar en una revista que adhiere al modelo de _Registered Reports_.

- OSF-Standard Pre-Data Collection Registration: Plantilla que sigue el modelo estándar, pero que agrega algunas preguntas más específicas sobre recolección de datos. Por ejemplo, pregunta si la recolección de datos está en curso o si se ha hecho algún análisis de los datos hasta ahora.

- Preregistration Template from AsPredicted.org: Plantilla estandarizada de AsPredicted. Simplifica el proceso de preregistro en 9 preguntas clave sobre el estudio.

- Replication Recipe (Brandt et al., 2013): Post-Completion: Se trata de una plantilla para estudios de replicación, específicamente estudios que ya finalizaron.

- Replication Recipe (Brandt et al., 2013): Pre-Registration: Se trata de una plantilla para estudios de replicación que aún no han comenzado.

- Pre-Registration in Social Psychology (van 't Veer & Giner-Sorolla, 2016): Pre-Registration: Plantilla de preregistro para estudios específicamente de la subdisciplina Psicología Social.

```{r osfprereg3, echo=FALSE, fig.cap="Preregistros en OSF", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/osfprereg3.png")
```

De todas estas plantillas veremos el detalle de tres de ellas: OSF Preregistration, Secondary Data Preregistration y Preregistration Template from AsPredicted.org.

Una vez escojamos una plantilla, la página se verá como la Figura N°  \@ref(fig:osfprereg5). Esta sección es transversal a todas las plantillas y consiste en el registro de los metadatos. Específicamente, OSF nos solicitará que registremos:

- Título del preregistro
- Una breve descripción
- Contribuyentes
- La categoría. Generalmente está en categoría _Project_, pero dependiendo de lo que estemos preregistrando, podemos cambiarlo a _Data_, _Software_, _Analysis_, entre otros.
- Areas discplinares, como _Arts and Humanities_, _Business_, _Social and Behavioral Sciences_ entre otras.
- Tags. Los tags sirven para facilitar la búsqueda del preregistro

```{r osfprereg5, echo=FALSE, fig.cap="Metadatos para preregistros", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/osfprereg5.png")
```

#### OSF Preregistration

Esta plantilla incluye ocho tópicos para rellenar con la información del estudio, estos son:

- Información del estudio: Principalmente solicita listar de forma concisa y detallada las hipótesis que serán puestas a prueba. Se solicita reportar si la hipótesis es direccional o no, y en el caso de serlo, especificar el sentido de la dirección. Si el estudio incluye moderaciones o mediaciones, plantearlas en hipótesis aparte.

- Plan del diseño: En esta sección se hacen cuatro preguntas importantes. La primera es sobre el **tipo del estudio**, donde se solicita especificar si el estudio es de tipo experimental, observacional, un metaanálisis u otro. En segundo lugar, está el **_blinding_**, el cual trata sobre quienes están en conocimiento de las condiciones de tratamiento en el caso de un diseño experimental. En el caso de un diseño experimental no aplica. En tercer lugar, se pregunta sobre el **diseño del estudio**, donde se solicita la mayor cantidad de detalles posibles respecto a este tópico. Por último, se solicita especificar cuál será el tipo de **aleatorización** (en el caso de un diseño experimental).

- Plan del muestreo: En esta sección, la plantilla requiere rellenar información respecto a la existencia de datos, los procedimientos de recolección de datos y sobre el tamaño de la muestra. En el caso de la existencia de datos, se nos solicita que marquemos de las siguientes situaciones la que más se acerca al estado de nuestro estudio:

  * Registro previo a la creación de datos
  * Registro previo a cualquier observación humana de los datos
  * Registro previo a acceder a los datos
  * Registro previo al análisis de los datos
  * Registro tras el análisis de los datos

  En el caso de trabajar con datos existentes la plantilla da una opción para detallar los pasos necesarios que se han tomado para asegurar que no conocemos el comportamiento de los datos. Por ejemplo, cómo es que se ha limitado la accesibilidad de los datos, o quiénes han revisado los datos y quienes no.

  En lo que respecta a los procedimientos de análisis, la plantilla solicita especificar cómo es que se han recolectado los datos y cuáles han sido los criterios de exclusión. En el caso de muestras que involucren seres humanos, se deben reportar todo tipo de incentivos a la participación. Por último, se pregunta por el tamaño de muestra y si se ha realizado algún análisis de poder estadístico

- Variables: En esta sección se preguntan tres cosas. La primera es sobre, en el caso de los estudios experimentales, cómo se manipularán los niveles de tratamiento de las variables. Segundo, la plantilla requiere especificar cómo es que se medirán las variables, tanto la variable dependiente como los predictores. En tercer lugar, en el caso de construir índices, se pide detallar lo más posible su construcción.


- Plan de análisis: En esta sección se busca el mayor detalle posible para le plan de análisis con tal de que sirva de guía para la reproducción o replicación del artículo. Partiendo por los modelos estadísticos, la plantilla solicita especificar la herramienta principal de análisis de datos (e.g. regresión múltiple) en conjunto a las variables que se incluirán (dependientes, independientes, controles, términos de interacción etc.). Otro componente importante para especificar son las transformaciones a los datos, incluyendo recodificaciones, centrados o cualquier procedimiento que cambie el formato original de la variable. También, la plantilla solicita especificar cuáles serán los criterios de inferencia estadística (e.g. valores p o intervalos de confianza). Por último, la plantilla requiere especificar cómo se determinará la exclusión de datos, cómo se trabajarán los datos perdidos y detallar los análisis exploratorios en caso de que existiesen.

- Otro: Esta es la última sección de la plantilla, donde se da la opción al investigador o investigadora de añadir cualquier información importante que hasta ahora no ha sido reportada.

#### Secondary Data Preregistration

Esta plantilla es similar a la que acabamos de revisar, la principal diferencia es que está enfocada en el preregistro de datos secundarios, por lo que todas las opciones que veíamos en la plantilla general de OSF que hacían referencia a datos primarios ya no existen. Recomendamos esta plantilla a investigadores que usen datos secundarios ya que hace más simple el proceso de preregistro al enfocarse en las preguntas que realmente se asemejan a la situación del investigador.

La plantilla se compone de siete puntos. El primero también consiste en especificar los metadatos del estudio, como por ejemplo en nombre del proyecto, el área del conocimiento en el que se circunscribe etc.

- Información del estudio: Básicamente implica especificar las preguntas y las hipótesis que orientan el estudio.

- Descripción de los datos: Esta sección es característica de esta plantilla, ya que nos pregunta directamente sobre características de la base de datos a utilizar. En detalle, recaba información sobre el nombre de la base de datos, una descripción general de ella y cuál será el subconjunto de datos en caso de que corresponda. También se solicita especificar qué tipo de base de datos es (e.g. longitudinal), si es que existen restricciones para el acceso y describir el procedimiento de elaboración de la base de datos. Por último, se nos solicita adjuntar el libro de códigos correspondiente y si este no existe, adjuntar cualquier archivo de la base de datos que permita conocer su composición.

- Variables: En esta sección las preguntas no son muy distintas de la plantilla que acabamos de revisar. En general, se solicita especificar la manipulación de las variables (no aplica para estudios observacionales), la forma de medición de las variables, la unidad de análisis y cuáles serán los procedimientos para tratar con casos perdidos y extremos.

- Conocimiento de los datos: Esta sección es característica de esta plantilla. A grandes rasgos, se nos pide dos cosas. Primero, que listemos los documentos con los cuales hayamos trabajado y que estén basados en la base de datos que utilizaremos (e.g. publicaciones, _working papers_, presentaciones de conferencia). Segundo, reportar cualquier conocimiento previo que tengamos del uso de la base de datos, especialmente las variables que sean relevante para el análisis propuesto. Este conocimiento de la base puede venir de publicaciones previas, de reportes de resultados o del libro de códigos, por dar algunos ejemplos.

- Análisis: En esta sección se pregunta sobre toda característica de nuestro análisis de datos, partiendo por el tipo de modelos estadístico que utilizaremos para probar las hipótesis. Se nos solicita que por cada hipótesis detallemos la herramienta de análisis. Luego, se nos preguntan detalles cómo: el tamaño de efecto de interés para nuestro análisis, el poder estadístico, los criterios de inferencia (e.g. valores p o factores bayesianos), las pruebas de robustez que se efectuarán y si es que realizaremos algún tipo de análisis exploratorio.

#### AsPredicted

La plantilla de AsPredicted es quizás una de las más conocidas para hacer preregistros, dado que está estandarizada y puede ser utilizada en cualquier disciplina. Esta plantilla la podemos encontrar tanto en OSF, como en la misma página de AsPredicted, en este caso, mostraremos cómo es el proceso en la página original.

Partimos por entrar a la página de AsPredicted, donde veremos algo como la Figura N° \@ref(fig:asp). Acá se nos da la opción de crear un preregistro, de ver los que ya hemos hecho (si es que ese es el caso) y también una breve descripción de AsPredicted. A grandes rasgos, la página nos dice que AsPredicted es una plataforma que busca facilitar el preregistro de estudios por parte de los investigadores a través de nueve simples preguntas. La página genera un documento .pdf y una URL asociada. También, cuenta cómo funciona el preregistro. Básicamente, un autor elabora un preregistro de un estudio y los coautores reciben un mail para aprobar ese preregistro. Una vez aprobado por todos los autores, el preregistro queda alojado en la plataforma de manera privada, y no cambia hasta que un autor decida hacerlo público. Además, en caso de que el estudio entre en revisión por pares, se puede enviar una versión anónima del preregistro. Por último, nos entrega una recomendación sobre qué hacer en el caso de que el proceso de investigación no haya podido apegarse totalmente a lo predicho.

```{r asp, echo=FALSE, fig.cap="Página de inicio de AsPredicted", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/asp.png")
```

Para elaborar un preregistro debemos hacer click en el rectángulo azul que dice _Create_. Una vez hecho eso, nos pedirá una dirección de email para continuar. Cuando ingresemos un email, nos enviará un enlace al email que hayamos ingresado, con ese enlace podremos comenzar el preregistro. Una vez hayamos entrado en el enlace, veremos la plantilla de preregistro. Lo primero que aparece es una sección donde debemos escribir los emails de los autores colaboradores del estudio. También, nos da la opción de añadir otros emails además del que hemos introducido. Una vez pasada esta parte, ya nos encontramos con las preguntas del preregistro, las cuales son las siguientes:

1) Recogida de datos. ¿Se han recogido ya datos para este estudio?
2) Hipótesis. ¿Cuál es la pregunta principal que se plantea o la hipótesis que se pone a prueba en este estudio?
3) Variable dependiente. Describa la(s) variable(s) dependiente(s) clave especificando cómo se medirán.
4) Condiciones. ¿Cuántos y qué condiciones se asignarán a los participantes?
5) Análisis. Especifique exactamente qué análisis realizará para examinar la pregunta/hipótesis principal.
6) Valores atípicos y exclusiones. Describa exactamente cómo se definirán y tratarán los valores atípicos, así como su(s) regla(s) precisa(s) para excluir las observaciones.
7) Tamaño de la muestra. ¿Cuántas observaciones se recogerán o qué determinará el tamaño de la muestra?
8) Otros. ¿Hay algo más que quiera preinscribir?
9) Nombre. Poner un título a este preregistro de AsPredicted
Finalmente. A efectos de registro, indíquenos el tipo de estudio que está preinscribiendo.

Las preguntas son bastante auto explicativas, pero no está de más entregar algunos detalles adicionales. En la pregunta de recolección de datos, las opciones son tres: "Sí, se han recolectado datos", "No, no se han recolectado datos" y "Es complicado". Es importante mencionar que, en esta plantilla, la respuesta de que se han recolectado datos no es válida, por lo que si se está llevando a cabo un estudio con datos secundarios hay responder "Es complicado" y en la pregunta 8 de la plantilla especificar por qué este preregistro sigue siendo válido pese a que los datos son preexistentes. Otro detalle importante es que cada pregunta está pensada para ser respuesta en aproximadamente una oración. Esta plantilla tiene el objetivo de ser lo más eficiente posible, por lo que, en general, se recomienda que todo el documento no pase de los 3200 caracteres. Otro detalle que especificar es que la pregunta acerca del tipo de estudio que se está preregistrando también es semicerrada, tenemos las opciones de: "Proyecto de clase", "Experimento", "Encuesta", "Estudio observacional" y "Otro". Es responsabilidad de quien hace el preregistro el seleccionar la opción que más se asemeje a su situación. Por último, es importante señalar que el preregistro, al menos en la página de AsPredicted, solo puede ser rellenado en inglés, por lo que en caso de utilizar otro idioma solicitará traducirlo.
