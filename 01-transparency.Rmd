# Transparencia

```{r setup, include=FALSE}
if (!require("pacman")) install.packages("pacman")  #si falta pacman, instalar
if (!require("tinytex")) install.packages("tinytex")#si falta tinytex, instalar
pacman::p_load(knitr, kableExtra, dplyr, ggplot2,sjmisc,texreg) # librerias
knitr::opts_chunk$set(
	fig.pos = "H",
	message = FALSE,
	warning = FALSE,
	cache = FALSE,
	out.width = "85%"
)
options(scipen=999) # notacion cientifica
rm(list=ls())       # limpiar workspace
options(knitr.kable.NA = '') # NA en kable = ''
```

Esta sección tratará sobre la transaprencia en la investigación cientifica, haciendo enfásis en las ciencias sociales. Nuestro objetivo es poder comunicar de forma clara y concisa tres puntos: a) qué es la transparencia, b) por qué la necesitamos y c) cómo podemos adoptarla. En esta sección profundizaremos en los dos primer puntos. Respecto al tercer punto, entregaremos algunos consejos y recomendaciones que se han dado en la literatura, para después, en la siguiente sección, profundizar en torno a las herramientas que nos permitirían adoptar la transparencia. La tónica de este escrito es la práctica, es decir; todo lo que presentemos acá tiene la finalidad de servir de camino para poder aprender y aprehender herramientas que promueven la transparencia. Dicho esto, comenzemos con los dos primeros puntos.

## ¿Qué es la transparencia? Un concepto multidimensional

Nuestro punto de partida es que la transparencia es un concepto amplio y multidimensional. Por eso, antes de adentrarnos en sus dimensiones, comencemos con una definición de diccionario. Según la Real Academia Española la transparencia es la cualidad de un cuerpo que permite ver a travez de él. Un ejemplo para llevar esta definición a la práctica es el vidrio de una ventana. La transparencia del vidrio nos permite ver con claridad lo que está el otro lado, como por ejemplo un paisaje. No obstante, ¿qué ocurre cuándo la transparencia del vidrio se va perdiendo? La respuesta es simple, pero potente: la claridad con la que veíamos el paisaje se va difuminando. Esta perdida de claridad puede dar como resultado que nuestra observación del paisaje se torne ambigua y erronea, o dicho de otro modo, cada vez será más dificil analizar el paisaje. Desde este ejemplo se podria plantear un simil con la ciencia; el paisaje equivale al proceso de producción cientifica, y el vidrio representa la claridad con la que podemos analizar este proceso. De esta manera, la base de la idea de transparencia es que permite analizar con claridad un fenomeno, una situación, o en este caso, un proceso.

¿Qué implica un proceso cientifico transparente? Ya existen algunas respuestas a esta pregunta. Por ejemplo, @breznau_Does_2021 entiende la transparencia como una forma en que los investigadores pueden revelar el proceso, ideas y materiales que sustentan un argumento o una teoría, con tal de contribuir a una comunidad científica más ética. Otra perspectiva es la de @aczel_consensusbased_2020, quienes proponen a la transparencia como un principio que permite evaluar y reproducir los hallazgos científicos, así como también a sintetizar investigaciones y contribuir a la ejecución de metanálisis. @klein_Practical_2018 proponen que la credibilidad de los productos cientificos dependen de la transparencia en la que se basan, y que, en consecuencia, avanzar hacia la transparencia simplemente significa adoptar ciertas prácticas de gestión de la investigación que la hagan menos propensa a errores y más reproducibles. Estas perspectivas son una primera aproximación a las implicancias de un proceso cientifico transparente, no obstante, no representan una presentación exhaustiva del concepto.

Volvamos a nuestro planteamiento incial: la transparencia es un concepto multidimensional. Para abarcar las múltuiples formas que puede adoptar, nos basamos en la taxonomía de @elliott_Taxonomy_2020. La taxonomía se estructura en torno a cuatro preguntas: ¿por qué?, ¿quienes? ¿qué? y ¿cómo? Cada una de estas preguntas tiene al menos una dimensión asociada. La primera pregunta (_¿por qué?_) se refiere a los propósitos por los cuales es necesario adoptar la transparencia; la segunda pregunta (_¿quienes?_) apunta a la audiencia que está recibiendo la información; la tercera pregunta (_¿qué?_) hace alusión al contenido qué es transparentado y la cuarta pregunta (_¿cómo?_) consiste en cuatro dimensiones distintas sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y lugar. También, la taxonomía propone una dimensión sobre los peligros que podrían afectar a las iniciativas que busquen promover la transparencia.. Una representación gráfica puede verse en la Figura N° \@ref(fig:taxonomy).

```{r taxonomy, echo=FALSE, fig.cap="Taxonomía de Transparencia", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/taxonomy.png")
```

Para comprender mejor la taxonomía la Tabla N° \@ref(tab:tabtax) presenta una versión detallada de cada dimensión en conjunto a una lista no exhaustiva de variaciones. Por ejemplo, la dimensión del propósito sintetiza varios de los puntos que ya se han señalado en la literatura sobre ciencia abierta: la transparencia contribuye a formar una ciencia más replicable, facilita la interacción crítica, facilita el reanalisis de resultados, entre otros. La mayoría de estos propositos están estrechamente relacionados con el horizonte de una ciencia con mayor credibilidad, cuestión que profundizarmeos en breve. Dentro de las dimensiones restantes, existe una en particular que queremos recalcar: los contenidos. Aquí, los distintos contenidos que pueden ser transparentados van desde cosas complejas como los juicios de valor o factores que podrían influencias las interpretaciones de resultados, hasta lo más concreto como datos, métodos y materiales, o en otras palabras, el diseño de investigación. Como podemos ver, la transparencia abarca varias dimensiones, sin embargo, a fin de mantener un documento simple y práctico, esta sección apuntará especificamente a la promoción de la transparencia del diseño de investigación.

```{r tabtax, echo=FALSE}
# Función para que las tablas renderizen tanto en html como pdf
table_format = if(is_html_output()) { # Usar en argumento "format=" de kable
  "html"
} else if(is_latex_output()) {
  "latex"
}

# Título tabla
cap1 <- "Variaciones por cada dimensión de transparencia"

# Crear tabla
tabtax <- read.csv(file = "input/tables/tabtax.csv",header = 1,sep = ",",encoding = "UTF-8") # Leer .csv con la estructura de la tabla
cnames <- c("Dimensión","Variaciones") # Nombres de las columnas
kable(tabtax,table_format,booktabs = T, linesep = "",col.names = cnames, caption = cap1) %>%
  kable_styling(
    full_width = T,
    latex_options = c("hold_position"), # Argumento para fijar la tabla en esta seccón del documento.
    position = "center",
    font_size = 10,
    bootstrap_options=c("striped", "bordered")) %>%
  column_spec(column = 1, width = "5 cm", ) %>%
  column_spec(column = 2,width = "5 cm") %>%
  collapse_rows(columns = 1:2,valign = "middle") # Para colapsar filas que tengan el mismo contenido
```

En síntesis, un proceso de investigación transparente es uno que se puede evaluar con claridad y facilidad. La taxonomía de @elliott_Taxonomy_2020 nos ayuda a comprender las diversidad dimensiones en las que se puede pensar la idea de transparencia. Ahora conocemos un poco más sobre la transparencia y lo que han dicho algunas voces de la literatura, no obstante, probablemente esté pensando algo como "Sí, tiene sentido que la transparencia contribuya a una ciencia mejor, pero ¿de verdad vale el esfuerzo y el tiempo de adoptar todas estas prácticas? La ciencia parece estar bien como está" Es un pensamiento razonable, sin embargo, la comunidad de adherentes a la ciencia abierta y la literatura asociada han adoptado el discurso de que efectivamente es necesario cambiar la forma que estamos haciendo hoy en día. Ha emergido la narrativa de que la ciencia está en crisis.

## ¿Crisis en las ciencias?

En los últimos años, ha venido tomando fuerza la idea de que existe una crisis en la ciencia. Esta idea se basa en el diagnóstico de que gran parte de los artículos cientificos en distintas discplinas no son posibles de reproducir ni replicar [e.g. @wilson_Replication_1973; @camerer_Evaluating_2018]. Tanto la reproducibilidad (emplear el mismo diseño y datos para reproducir los hallazgos de un artículo) o la replicabilidad (emplear el mismo diseño y distintos datos para obtener los mismos resultados) son componentes centrales de la ciencia. Es más, gran parte del avance del conocimiento cientifico recae en la verificabilidad de sus hallazgos, por lo que un fallo en poner a prueba los hallazgos un golpe directo a la credibilidad de la ciencia. La pregunta es ¿existe realmente una crisis en las ciencias?

Unas de las fuentes más comunmente citadas para introducir la idea de crisis es una encuesta realizada en la revista _Nature_. En esta encuesta, @baker_500_2016 logró obtener las opiniones de poco más de 1,500 investigadores de discplinas como la quimica, ingenerías y la medicina, sobre tópicos relacionados a la reproducibilidad en las ciencias. El resultado principal muestra que un **90% de los encuestados está de acuerdo en la existencia una crisis**, donde un 52% piensa que es una gran crisis y un 38% la percibe como una ligera crisis. En este mismo estudio, se les pregunta por los factores que contribuyen a esta crisis, donde la cultura del _pública o perece_ y el _reporte selectivo de resultados_ aparecen como los protagonistas. Si bien la encuesta no es una muestra representativa de toda la comunidad cientifica, presenta una panoramica que lleva a, por lo menos, considerar la crisis de la ciencia como tema que merece atención.

Actualmente, existe un cuerpo de literatura que se ha dedicado diagnosticar y proponer alternativas de solución ante la idea de una ciencia en crisis. Dentro del diagnóstico, variados estudios han orientado sus esfuerzos a esclarecer cuáles son los factores que podrían estar influenciando esta crisis. En línea con los resultados de @baker_500_2016, es posible plantear dos áreas: una relacionada al modelo de producción cientifica actual, donde los incentivos por públicar[], los criterios de ascenso en la jerarquía [] académica y el formato de la revisión por pares contribuyen [] a generar una cultura del _pública o perece_ que fuerza a los invetigadores a aumentar su productividad académica; y otra relacionada a la flexibilidadad (también conocida como grados de libertad) que tienen los investigadores a la hora de realizar investigaciones, generando la oportunidad para prácticas académicas que pueden afectar la credibilidad de los resultados. En esta sección, nos centraremos en la dimensión de las prácticas de investigación.

Comencemos con las prácticas de investigación. Para esquematizar de mejor manera qué es lo problemático de ciertas prácticas, es que utilizamos el esquema conceptual de @steneck_Fostering_2006. El esquema parte de una distinción básica entre la _ética en investigación_ y la _integridad en investigación_, englobando ambas bajo el gran concepto de _Conducta Responsable de Investigación (RCR)_ (ver Figura N° \@ref(fig:rcr). A grandes rasgos, la RCR se puede entender como el "llevar a cabo la investigación de forma que se cumplan las responsabilidades profesionales de los investigadores, tal y como las definen sus organizaciones profesionales, las instituciones para las que trabajan y, en su caso, el gobierno y el público" [@steneck_Fostering_2006]. En palabras simples, una conducta integra es atenerse a un conjunto de reglas sobre conducta científica.

```{r rcr, echo=FALSE, fig.cap="Conducta Responsable de Investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/rcr.png")
```
Dentro de la RCR, la ética de investigación está relacionada al comportamiento académico visto desde la óptica de los principios morales [@steneck_Fostering_2006], lo que se expresa en tópicos como el uso de datos, los consentimientos informados o el trato con pacientes -en el caso de las ciencias biomedicas-, por dar algunos ejemplos. La definición que ofrece @steneck_Fostering_2006 señala que la ética de investigación se define como "el estudio crítico de los problemas morales asociados o que surgen en el curso de la investigación" (p.56) En cámbio, la integridad en investiación se entiende como "poseer y adherirse firmemente a las normas profesionales, tal y como las señalan las organizaciones profesionales, las instituciones de investigación y, en su caso, el gobierno y el público" [@steneck_Fostering_2006, p.56]. A diferencia de la ética de investigación, el concepto de integridad está regido por los estándares profesionales más que por los principios morales, su función es plantear una guía clara para la conducta investigativa, de ahí que sea el concepto utilizado por distintos códigos de conducta [ver @abrilruiz_Manzanas_2019].

```{r grad, echo=FALSE, fig.cap="Gradación del comportamiento integro en investigación. Imagen de @abrilruiz_Manzanas_2019 basada en @steneck_Fostering_2006", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/grad.png")
```
Habiéndonos situado dentro del concepto de integridad en la investigación, podemos pasar a delinear las principales prácticas que atentan contra él y que se han propuesto como factores que contribuyen a la crisis en la ciencia. Tanto @steneck_Fostering_2006 como distintos códigos de conducta de universidades e instituciones de financiamiento [ver @abrilruiz_Manzanas_2019] evalúan las prácticas de investigación en un continuo, que representa cuánto adhieren los investigadores a los principios de integridad cientifica. La Figura N° \@ref(fig:grad) esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR), y a la derechaa el peor comportamiento (FFP). Las FPP son un abreviación en lengua inglésa para referirse a _Fabrication, Falsification, Plagiarism_ (Invención, Falsificación y Plagio), también conocidas como _mala conducta académica_-. En el medio del continuo están las _prácticas cuestionables de investigación_ (QRP, por sus siglas en inglés) las cuáles refieren a "acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación" [_National Academies of Science_ 1992 en @steneck_Fostering_2006, p.58]. Las QRP se caracterizan porque tienen el potencial de dañar la ciencia, en tanto las FFP la dañan directamente.

Comprendidos ambos conceptos, veamos las situaciones que podrían categorizarse como FFP y las que podrían concebirse como QRP.

### Mala conducta académica (FFP)

La mala conducta académica suelen ser situaciones polémicas y que muchas veces alcanzan gran conbertura mediatica. El libro de @abrilruiz_Manzanas_2019 hace una revisión de una serie de situaciones, en distintas discplinas y años, en las que investigadores han sido descubiertos cometiendo prácticas que atentan directamente a la ciencia. Las situaciones son variadas, existen casos de manipulación de imagenes, exageración de lo registros de laboratorio, o de plano la invención de conjuntos de datos enteros. En esta sección veremos el caso de Diderik Stapel como ejemplo de malas prácticas de investigación y plantearemos la relación que tiene con la transparencia en la investigación.

#### Diderik Stapel

Probablemente, el caso de Diderik Stapel sea uno de los más emblématicos y representativos de este problema. Diderik Stapel era un investigador de la _Tilburg University_ que se dedicaba al campo de la psicología social. Su carrera se caracterizó por una trayectoria ejemplar, obtuvo su M.A en psicolgía y comunicaciones el año 1991, se doctoró en psicología social el año 1997 y trabajó como profesor asociado primero en la _University of Gronigen_ (2000-2006) y dede el 2006 en la Tilburg University. Fue fundador del _Tilburg Institute for Behavioral Economics Research_, del cuál el 2010 se convirtió en decano. Así también, fue galardonado con el premio a la trayectoria académica por la _Social of Experimental Social Psychology_. En breve, Stapel era una figura de alto estatus en el mundo académico, entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas cientificas, algunas de las más prestigiosas (e.g. _Science_). Sin embargo, 	el año 2011 se confirmó que gran parte de su trayectoria académica era una farsa.

Después de la verificación de su culpa ante acusaciones de malas prácticas, la carrera de Diderik Stapel acabó. Fue desvinculado de la Tilburg University, se le rebocó su título de doctorado y toda su trayectoria académica fue investigada acusiociamente. El informe final de la investigación encontró que más de 50 de sus artículos eran fraudulentos. De hecho, Stapel ocupa el tercer lugar en con 58 artículos listados en _Retraction Watch_ (https://retractionwatch.com/), una plataforma que se dedica a sistematizar y mantener una lista actualizada sobre retracciones de artículos . A efectos de este escrito, lo que más destacable es que Stapel cometió conductas de mala conducta académica durante más de 15 años. La pregunta es ¿cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o co-autores se dio cuenta de sus malas prácticas? La respuesta breve es por la falta de transparencia durante el proceso de investigación.

Los artículos periodisticos que han profundizado en el caso han relatado parte del proceso investigativo de Stapel [e.g. @carey_Fraud_2011]. Dentro de los procesos de producción y análisis de datos, Stapel se caracterizaba por hacer todo el trabajo solo y "a puertas cerradas". Es decir, nadie más que él tenía acceso a los datos brutos, ni támpoco a la ejecución de las pruebas estadísticas. Generalmente, Stapel compartía con sus colegas y alumnos de doctorado la base de datos lista, con las pruebas estadísticas ya hechas y, claro está, con resultados estadísticamente significativos. Estas prácticas no causaron sospechas durante muchos años, es más, a muchos de sus estudiantes les parecía una práctica normal y eficiente. Además, con el estatus de Stapel ¿qué podría estar mal? Sin embargo, era a raíz de esta práctica que Stapel tenía la oportunidad de inventar y falsificar datos a su conveniencia. Esto explica en gran parte de su trayectoría académica llena de grandes hallazgos y una producción académica increible.

El caso de Stapel deja un punto importante sobre la mesa: la falta de transparencia en el proceso investigativo dio cabida a la mala conducta académica. Cómo nadie más colaboraba con el procesamiento de datos, ni támpoco parecía extraño que así fuera, las oportunidades para la falsificación de los datos estaba abierta. Ahora, esta no es necesariamente una relación de causalidad, la falta de transparencia no tiene porque terminar en conductas como fabricación o falsificación de datos. Sin embargo, tal y como lo argumentan @oboyle_Chrysalis_2017 si son una oportunidad para violaciones a la integridad cientifíca más sutiles, tales como las QRP.

### Prácticas cuestionables de investigación (QRP)

Recordemos, las QRP son prácticas que en si mismas no dañan directamente la empresa cientifica, pero si tienen el potencial de hacerlo. Son prácticas que alteran el correcto funcionamiento del método cientifico. En la literatura, existen una variedad de términos que se utilizan para describir las prácticas cuestionables, asi como también distintas listas de prácticas que han emitido instituciones . @abrilruiz_Manzanas_2019 hace una recopilación y traducción de distintos códigos de conducta de distintas universidades y organismos, el cuál nosotros sistematizamos en la Tabla N° \@ref(tab:tabqrp). La tabla muestra un conjunto de prácticas divididos en cuatro categorías, de acuerdo a si las prácticas tienen que ver con: el diseño y el procesamiento de los datos, la redacción y el reporte de los resultados, temas de citación y uso de ideas ajenas y, por último, sobre relaciones con otros actores en el campo de la ciencia.

```{r tabqrp, echo=FALSE}
# Función para que las tablas renderizen tanto en html como pdf
table_format = if(is_html_output()) { # Usar en argumento "format=" de kable
  "html"
} else if(is_latex_output()) {
  "latex"
}

# Título tabla
cap1 <- "Algunas situaciones de QRP"

# Crear tabla
tab01 <- read.csv(file = "input/tables/tabqrp.csv",header = 1,sep = ",",encoding = "UTF-8") # Leer .csv con estructura de la tabla
cnames <- c("Dimensión","Práctica") # Nombre de las columnas
kable(tab01,table_format,booktabs = T, linesep = "",col.names = cnames, caption = cap1) %>%
  kable_styling(
    full_width = T,
    latex_options = c("hold_position"), # Argumento para mantener posición de la tabla en esta sección del documento
    position = "center",
    font_size = 10,
    bootstrap_options=c("striped", "bordered")) %>%
  column_spec(column = 1, width = "5 cm", ) %>%
  column_spec(column = 2,width = "5 cm") %>%
  collapse_rows(columns = 1:2,valign = "middle") # Para colapsar filas con el mismo contenido
```

Existen una serie de estudios que han intentado medir directamente la existencia de estas prácticas a través de encuestas. @fanelli_How_2009 hizo un metanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez (FFP) y que un 33.7% había realizado alguna vez una QRP como "borrar puntos de los datos basados en un sentimiento visceral". Un estudio más reciente, también basado en encuestas cuantitativas sobre prácticas, es el de @john_Measuring_2012. En este estudio, los resultados mostraron que un 36.6% de quienes participaron alguna vez habían práctiado alguna QRP. En detalle, analizando los porcentajes práctica a práctica se halló que el 50% de los psicologos encuestados alguna vez reportaron selectivamente estudios que apoyaran su hipótesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Estos estudios son una primera aproximación a la existencia de las QRP en la ciencia.

Existen ciertas prácticas que han sido tratadas con más enfásis en la literatura, y que son las que queremos destacar acá. Por un lado, está el _sesgo de publicación_, el cual significa, a grandes rasgos, que un artículo es públicado en base a sus resultados. Especificamente, el sesgo de publicación ocurre cuando el criterio determinante para que un artículo sea públicado es que sus resultados sean signiificativos, en desmedro de la publicación de resultados no signifcativos. El estudio de @franco_Publication_2014 logra cuantificar esta situación bastante bien y esclarecer el _file drawer problem_ (en español: problema del cajón de archivos), que hace alusión a los resultados perdidos dentro de un cuerpo de evidencia [@christensen_Transparent_2019, p.39]. @franco_Publication_2014 encontraron que, efectivamente, los resultados nulos tienen un 40% menos de probabilidades de ser públicados en revistas cientificas, en comparación a estudios con resultados significativos. Es más, muchas veces los resultados nulos nisiquiera llegan a ser escritos: más de un 60% de los experimentos que componen la muestra del estudio de @franco_Publication_2014 nunca llegaron a ser escritos, en contraste al menos del 10% de resultados significativos.

El principal problema del sesgo de publicación es que puede impactar en la credibilidad de cuerpos enteros de literatura. Existen ejemplos de cuerpos de literatura que se han hallado sesgados, como el _Value of Statistical Life_ (Valor de la Vida Estadística) y el de salario mínimo y desempleo, ambos en economía [para detalle ver p.42 y p.46 en @christensen_Transparent_2019]. También, a partir del desarrollo de distintos métodos de detección, se ha podido diagnosticar el sesgo de publicación en importantes revistas en economía @brodeur_Star_2016, sociología y ciencias políticas [@gerber_Publication_2008; @gerber_Statistical_2008].

Otra práctica bastante cuestionada es el _p-hacking_, que de forma literal sería un "hackeo" de los valores p. El _p-hacking_ se da cuando el procesamiento de los datos tiene por objetivo obtener resultados significativos. Si el sesgo de publicación afecta la credibilidad de un cuerpo de literatura, el _p-hacking_ afecta a la credibilidad de los artículos mismos, ya que al forzar la signifcancia estadística la probabilidad de que en realidad estemos frente a un falso positivo aumenta. Un trabajo que da sustento a esta idea es el de @simmons_FalsePositive_2011, quienes calculan la posibilidad de obtener un falso positivo (error Tipo I) de acuerdo a al nivel de manipulación intencionada de los datos. El resultado principal es que a medida que aumenta la cantidad de manipulación en los datos, la posibilidad de obtener un falso positivo aumenta progresivamente.

El _p-hacking_ también contribuye a sesgar cuerpos enteros de literatura. Para diagnosticar esto se ha utilizado una herramienta denominada _p-curve_, la cual "describe la densidad de los _p-values_ reportados en una literatura, aprovechando el hecho de que si la hipótesis nula no se rechaza (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1" [@christensen_Transparent_2019, p.67.]. De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de p-values debería estar cargada a la izquierda (siendo precisos, asimetrica a la derecha), en cambio, si existe sesgo por p-hacking la distribución de p-values estaría cargada a la derecha (asimetría a la izquierda). @simonsohn_Pcurve_2014 proponen esta herramienta y la prueban en dos muestras de artículos de la _Journal of Personality and Social Psychology (JPSP)_. Las pruebas estadísitcas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipótesis, en detalle, los artículos que presentaban solamente resultados con covariables, resultaron tener una p-curve cargada a la derecha (asimetrica a la izquierda).

Por último, pero no menos importante existe la práctica del _HARKing_. El nombre es una nomenclatura en lengua inglesa: _Hypothesizing After the Results are Known_, que literalmente significa establecer las hipótesis del estudio una vez que se conocen los resultados. El principal problema de esta práctica es que confunde los dos tipos de razonamiento que están a la base de la ciencia: el exploratorio y el confirmatorio. El objetivo principal del razonamiento exploratorio es plantear hipótesis a partir de un análisis de datos. En cambio, el razonamiento confirmatorio busca plantear hipótesis basado en teoría y contrastar esas hipótesis con datos empíricos. Como señala @nosek_preregistration_2018, cuando se confunden ambos tipos de análisis y se hace pasar un razonamiento explortorio como confirmatorio se está cometiendo un sesgo inherente, ya que se está generando un razonamiento circular: se plantean hipótesis a partir del comportamiento de los datos y se confirman las hipótesis con esos mismos datos.

## ¿Que podemos hacer?

Tanto en las ciencias sociales, como en otras disciplinas han ido emergiendo una variedad de recomendaciones que contribuyen a la adopción de la transparencia. Por ejemplo, @cruwell_Easy_2018 propone formar investigadores y estudiantes a partir de la promoción de siete principales tópicos: entender la ciencia abierta; acceso abierto; la importancia de los datos, material y código abierto, los análisis reproducibles; los pre-registros; la replicación y, por último, la enseñanza de la ciencia abierta. Cada uno de estos tópicos son un paso para lograr avanzar hacia una ciencia más abierta y transparente. De forma similar, @miguel_Promoting_2014 enfatiza en tres ideas: el _disclosure_ (divulgación), los pre-registros y los datos y materiales abiertos. La divulgación consta de que los investigadores deben declarar todo tipo de procesamiento realizada a los datos y detallar como se llégó a las muestras finales. Los preregistros son una forma de ser más transparente con los procedimientos y dividir los tipos de formulación de hipótesis. Los datos y materiales abiertos permite que otros investigadores puedan reproducir el trabajo, hacer otras pruebas de hipótesis, identificar malas prácticas etc. También @lindsay_Seven_2020 discute los efectos que tienen el sesgo de publicación y otras prácticas similares en la credibilidad de la ciencia, proponiendo siete pasos para mejorar la transparencia: decir la verdad, por ejemplo, si la idea de investigación surgió analizando datos plantearlo de esa manera; evaluar la comprensión de la estadística inferencial; estandarizar la aproximación para probar las hipótesis, por ejemplo, realizar un plan de análisis; hacer un manual de laboratorio (en el caso de diseños experimentales); hacer abiertos los materiales, datos y análisis; abordar las limitaciones de la generabilidad de las conclusiones; y por último, considerar enfoques colaborativos para conducir investigaciones. @oboyle_Chrysalis_2017 proponen tres simples consejos para hacer la ciencia más transparente: incluir una clausulas éticas en el envío de manuscritos que declaren no haber cometido QRP, qué todo artículo original (e.g. tesis doctoral) debe estar disponible para descarga y que las revistas cuenten con un espacio dedicado a replicación.

Una propuesta sistemática para adoptar la transparencia, que incluye varias de las recomendaciones mencionadas son las _Transparency and Openess Promotion (TOP) Guidelines_ (Guías para la Promoción de la Transparencia y la Accesibilidad). Estos son principios que buscan alcanzar un formato de investigación reproducible a través del aumento de la transparencia en el proceso y los productos de investigación [@nosek_Transparency_2014]. Estos principios sirven de guía tanto para la adopción de buenas prácticas en los investigadores, como para que las revistas académicas puedan adherir progresivamente al ideal de transparencia en la ciencia. Son ocho principios:

1. Citación
2. Transparencia de datos
3. Transparencia de métodos análiticos (código)
4. Transparencia de los materiales
5. Transparencia del diseño y el análisis
6. Preregistro de estudios
7. Pre registro de planes de análisis
8. Replicación

A grandes rasgos, el principio de citación propone que las normas de citado deben ampliarse también a los datos y códigos, permitiendo reconocer su autoría intelectual [@nosek_Promoting_2015]. Los principios de transparencia de datos, métodos análiticos, materiales y diseño y análisis (2 a 5) refieren a la transparencia en su forma más concreta: la apertura del proceso de investigación para su evaluación. El detalle puesto a los principios responde a la generelabizilidad que se le busca dar a los principios. Por ejemplo, un estudio observacional cuantitativo no tiene material que transparentar, pero si datos y métodos análiticos. Asi también, un estudio cualitativo quizás no tenga código que transparentar, pero si un diseño y una bitacora detalla del proceso de análisis. En el caso de los principios relacionados al pre-registro, @nosek_Promoting_2015 argumenta que registrar los estudios los hace más descubribles, incluso si no son públicados. Asi también, los preregistros del plan de análisis contribuyen a distinguir entre los análisis confirmatorios y explotatorios (ver @nosek_preregistration_2018 para un manejo detalado del tema). Por último, el principios de replicación fomenta las oportunidades para la corrección de artículos y redirecciona la investigación en vías más prometedoras [@nosek_Promoting_2015].

Cada uno de estos principios cuenta con tres niveles, que sirven para medir el grado de inclusión de la transparencia por parte de una revista cientifica (ver Figura N° \@ref(fig:tabtop) para detalle). La adopción de prácticas transparentes va desde el nivel 1, siendo lo menos transparente, hasta el nivel 3 siendo lo más transparente. Se añade un nivel 0 que no cumple los estandares de transparencia con la finalidad de tener una comparación. Por ejemplo, para los estandares de transparencia del método de análisis (código), el nivel 1 dicta que las revistas deben solicitar la existencia del código de análisis, en cambio, el nivel 3 es más estricto en plantear que el código de análisis debe estar almacenado en un repositorio confiable y que el análisis será reproducido durante el proceso de revisión. El mismo método se puede aplicar para la el preregistro del plan de análisis. En el nivel 1 las revistas promueven el uso de preregistros, en cambio, en el nivel 3 los preregistros son obligatorios y también reconocidos. En suma, las TOP Guideliness son una iniciativa que contribuye a la apertura en la ciencia proponiendo nuevas prácticas para los requerimientos de las revistas.

```{r tabtop, echo=FALSE, fig.cap="Variaciones por dimensión de transparencia", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/table_top.png")
```

Como podemos ver, en general las recomendaciones sobre transparencia giran en torno a los preregistros, los datos y materiales abiertos y la replicación. En la siguiente sección profundizaremos en los preregistros como una forma de aumentar la transparencia durante el proceso de investigación.
