# Reproducibilidad

¿Cuántas veces nos hemos enfrentado a un trabajo publicado que no comparte sus materiales, y que por tanto, es imposible acceder a los procedimientos que dieron luces de sus resultados? En el marco de la denominada “crisis de la ciencia", la comunidad científica se ha organizado para dar salida a este problema a través de una diversidad de iniciativas que, a modo general, buscan promover los principios de la ciencia abierta. En este sentido, dichas iniciativas han puesto sus esfuerzos en contribuir con herramientas que permitan dar salida a los problemas en torno a la transparencia de los procesos de investigación y la **reproducibilidad** en la investigación empírica. En este apartado, revisaremos cómo ha sido entendido este problema y luego se presentarán las propuestas de tres iniciativas en torno a cómo abordar la transparencia y la reproducibilidad en las ciencias sociales empíricas.

## ¿Qué es la reproducibilidad?

En la discusión sobre los problemas de transparencia en torno a los procedimientos de investigación, se vuelve necesario precisar de qué manera es entendido el concepto de reproducibilidad en la ciencia. En esta línea, la laxitud en que ha se ha empleado el término ha llevado a definiciones poco claras, lo cual ha generado una tendencia a confundir lo que refiere a la transparencia de un proceso único que ya ha sido realizado, con un proceso nuevo y que puede realizarse de manera reiterativa, obteniendo los mismos resultados. Por este motivo, esta sección propone dar luces respecto a cómo entendemos el concepto de reproducibilidad, en contraste con el replicabilidad en la ciencias sociales.

La discusión en torno a cómo se entiende la **reproducibilidad**, habitualmente lleva al contraste respecto al concepto de **replicabilidad**. Al respecto  @earth_Reproducibility_2019 menciona que con el incremento de las herramientas computacionales a principios de los años 90’, el término de "investigación reproducible" era concebido como las investigaciones que proveían un compendio detallado de la documentación, código y datos que permitieran obtener los mismos resultados publicados por los autores, enfatizando que los análisis fueran transparentes y claros con el objetivo de ser verificados por sus pares. Por otro lado, los autores sostienen que en otras disciplinas, el concepto de reproducibilidad era asociado a investigaciones independientes entre sí en términos de los datos empleados, los materiales, métodos e implementación de un estudio, lo cual estaría orientado a robustecer o cuestionar la evidencia previa [@earth_Reproducibility_2019, pp 33-34]. Actualmente, a esta práctica se la entiende como replicabilidad de una investigación y no debe ser confundida con el concepto de reproducibilidad [@barba_Terminologies_2018].

@barba_Terminologies_2018 sugiere que la confusión entre reproducibilidad y replicabilidad ha contribuido a obstaculizar las prácticas en ambas dimensiones. En una revisión reciente realizada por la autora se han identificado al menos tres escenarios o versiones de cómo se entienden ambos conceptos en una amplia gama de disciplinas que van desde las ciencias sociales hasta estudios clínicos en las ciencias médicas. El primer escenario (A), y a la vez el más común, es donde el uso de ambos conceptos es indistinto, contribuyendo a la ya mencionada confusión. El segundo escenario (B1) es cuando la reproducibilidad es entendida como la situación que los datos originales y el código de análisis son empleados para **regenerar** los resultados originales, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes utilizan datos nuevos para obtener los mismos resultados que la investigación previa. Finalmente, un tercer escenario (B2) es cuando la reproducibilidad es entendida cuando investigadores o equipos independientes obtienen los mismos resultados empleando sus propios datos y métodos, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes llegan a los mismos resultados empleando los artefactos digitales [^1] originales del autor con menores o mayores modificaciones, los cuales han sido puestos previamente a disposición de sus pares. La Figura \@ref(fig:scenarios) ilustra cómo podemos entender los escenarios B1 y B2 en relación a la distinción entre reproducibilidad y replicabilidad.  El color rojo, tanto en los datos como en los métodos, indica que los componentes empleados son idénticos a los del estudio original. Por otro lado, el color azul, indica que tanto los datos como los métodos son distintos a los del estudio original. Finalmente, el color morado en los métodos se entiende como un punto intermedio y refiere cuando se han empleado métodos que siguen las indicaciones del estudio original, pero que han incorporado modificaciones, nuevos métodos u otras innovaciones metodológicas (p. ej. métodos nuevos, pruebas robustez u otros).


[^1]: @barba_Terminologies_2018 lo define como un compendio que detallar la estrategia de medición, diseño del estudio o código de análisis originales de un autor

```{r scenarios, echo=FALSE, fig.cap="Escenarios B1 y B2 en reproducibilidad y replicabilidad.", fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/reproducibility.png")
```
En las ciencias sociales, el debate en torno a la investigación reproducible y la replicabilidad no ha estado ausente. Como fue reseñado en la sección anterior, existen casos icónicos en torno a prácticas cuestionables de investigación que han afectado la confianza en la investigación científica, lo cual ha contribuido a incrementar los esfuerzos por una ciencia social abierta y reproducible [@breznau_Does_2021; @nosek_Promoting_2015]. En los tres escenarios descritos por @barba_Terminologies_2018, las ciencias sociales han experimentado de manera diversa el ajuste hacia una cultura de mayor apertura y precisión en torno a los problemas de la crisis de reproducibilidad, principalmente a través del estudio sistemático de dicha problemática, dentro de lo cual la psicología ha sido un pionera en proveer evidencia para este debate [@opensciencecollaboration_Estimating_2015; @gilbert_Comment_2016]. Al respecto @bishop_Rein_2019 sostiene que una de las principales amenazas para el progreso de la ciencia en general ha sido a la falta de reproducibilidad de los resultados (_irreproducibility_),  lo cual ha afectado principalmente la robustez y credibilidad de la evidencia reportada por las investigaciones, problema que también ha sido identificado en las ciencias sociales, principalmente por la falta de precisión en los procedimientos y las barreras de acceso a materiales clave del proceso de análisis [@freese_Replication_2017].

Entonces, retomando la distinción clave entre lo que entendemos por **reproducibilidad** y **replicabilidad**, en su revisión, @barba_Terminologies_2018 sugiere que una manera de entender y distinguir ambos conceptos de manera minimalista puede descansar en el carácter de los _datos_ y los _métodos_.  Al respecto @nosek_Promoting_2015 sostiene que en lo que refiere a estas dos dimensiones, los niveles en que una publicación los incorpora es gradual y puede entenderse como un continuo o espectro [@peng_Reproducible_2011], y por tanto, el nivel en que se cumplen con determinados criterios nos permite definir el carácter de una investigación en términos de su reproducibilidad. Por ejemplo, la Figura \@ref(fig:espectro) nos muestra cómo podemos caracterizar una investigación publicada en torno al acceso y vinculación entre código y datos. Por un lado, se observa que en el polo donde únicamente disponemos de la publicación, se entiende como la ausencia de reproducibilidad. Por otro lado, en la medida que incrementa el acceso a los materiales, y se explicita el enlace entre ellos, se puede caracterizar a una publicación como reproducible. [^2]

[^2]: En la figura original, @peng_Reproducible_2011 muestra el polo derecho como el mejor escenario y lo clasifica como *Full replication*, sugiriendo que el mejor estándar para poner a prueba los hallazgos de una investigación científica es la replicación, pero en la ausencia de dicha posibilidad la reproducibilidad de los resultados debiese ser un estándar mínimo

```{r espectro, echo=FALSE, fig.cap="Espectro de Reproducibilidad. Traducción propia en base a @peng_Reproducible_2011 ", fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/repro-spectrum.png")
```
Como sugiere @nosek_Promoting_2015, el problema de la ausencia o falta de reproducibilidad debe ser abordado a través de un cambio en las prácticas de investigación, para lo cual se requiere, por un lado, de una disposición por parte de la comunidad científica, es decir a que se le atribuya un _sentido_ positivo a estas prácticas. Sin embargo, @peng_Reproducible_2011 sostiene que una de las principales barreras para promover estas prácticas ha sido la falta de mecanismos que faciliten la distribución de la investigación reproducible, como también la poca claridad respecto de los estándares asociados a ello. Siguiendo esta autocrítica de algunos sectores dentro de la comunidad científica, dentro de los últimos años han surgido iniciativas, por ejemplo, como el Open Science Framework, al alero del [Center for Open Science](https://www.cos.io/), desde donde se busca contribuir con herramientas para el entrenamiento y educación de la comunidad científica en general, como también proveer de una infraestructura tecnológica que facilite la transición cultural hacia una ciencia abierta, transparente y reproducible [@nosek_Promoting_2015]. Por este motivo, proponemos revisar tres iniciativas internacionales que han puesto sus esfuerzos en la promoción de estos principios, con particular atención en la transparencia y reproducibilidad de la investigación científica, y en particular de las ciencias sociales empíricas cuantitativas. Dentro de estas iniciativas encontraremos esfuerzos orientados a la educación y entrenamiento, herramientas tecnológicas y fortalecimiento de redes de colaboración.

## ¿Qué se ha hecho?

### Berkeley Initiative for Transparency in the Social Sciences

```{r, echo=FALSE, fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/BITSS_logo_horizontal.png")
```

#### Objetivos y visión {-}

Esta iniciativa busca promover la credibilidad en la evidencia generada por las ciencias sociales a través de mecanismos de avanzada para la transparencia, reproducibilidad y prácticas éticas en la investigación social empírica. Desde esta premisa, ha desarrollado y puesto a disposición de la comunidad científica una serie de herramientas en colaboración con estudiantes, investigadores, entidades académicas y fundaciones de la sociedad civil al alero de tres principios orientadores.

Generar evidencia en torno a problemas y soluciones a través de los investigadores y la comunidad de BITSS quienes han liderado investigaciones meta-analíticas con atención en las ciencias sociales.
Incrementar el acceso a la enseñanza de la ciencia abierta, a través del fortalecimiento de prácticas para reconocer y conducir investigación social transparente y reproducible a través del entrenamiento de investigadores jóvenes, acceso a materiales, apoyo financiero y la consolidación de una red de colaboración.
Fortalecer el ecosistema científico, estableciendo condiciones para investigadores e instituciones para contribuir a un cambio efectivo y equitativo en las normas que permitan una consolidación de una política interna orientada a la ciencia abierta y al desarrollo de protocolos en esta dirección.

Como se ha señalado, esta iniciativa se orienta bajo estos tres ámbitos o principios. Desde sus inicios, se han desarrollado una serie de componentes que buscan promover y dar soluciones a los problemas de transparencia y reproducibilidad en las ciencias sociales. En particular, nos interesa destacar algunas de las contribuciones en este ámbito que serán presentadas a continuación las cuales se pueden resumir en Evidencia, Educación y Recursos.

#### Contribución {-}

En el ámbito de Evidencia, desde BITSS se ha realizado un esfuerzo por producir y sistematizar evidencia centralizadamente. En este contexto existe la [Research Library](https://www.bitss.org/research-library/), una base de datos de publicaciones científicas que engloba una serie de investigaciones meta-analíticas en el ámbito de las ciencias sociales, contribuyendo con un cuerpo de evidencia sistemática en torno a los problemas y soluciones sobre transparencia y reproducibilidad en las ciencias sociales sin precedentes. En este apartado, tanto los colaboradores como investigadores de BITSS ponen a disposición de la comunidad científica las investigaciones que han sido financiadas a través de las Social Science Meta-Analysis and Research Transparency ([SSMART](https://www.bitss.org/ssmart-grants/)) grants, las cuales constituyen fondos orientados a contribuir a la investigación empírica en torno a la transparencia y reproducibilidad en disciplinas como la economía, ciencia política, psicología y ciencias sociales afines.

Desde la Educación y Entrenamiento podemos identificar la articulación de una serie de _Training activities_ desarrolladas por BITSS. Dentro de los objetivos de estas actividades podemos encontrar dos aspectos que se buscan abordar desde esta dimensión. Por un lado se encuentra el promover una visión crítica de los investigadores en las ciencias sociales, esto considera un entendimiento de los principales problemas asociados a la investigación social de calidad al alero de los principios de la ciencia abierta, dentro de lo cual podemos encontrar los sesgos y prácticas referidas a las presiones por publicar, prácticas cuestionables de investigación, reproducibilidad y privacidad de datos. Por otro lado, se han propuesto promover el manejo de técnicas de investigación para la transparencia y reproducibilidad, principalmente a través de actividades de entrenamiento con un foco en el aprendizaje e implementación de herramientas y métodos. En esta línea destacan dos contribuciones que se fundamentan en estos principios, las cuales serán descritas a continuación.

**Research Transparency and Reproducibility Training**

Una de las contribuciones señaladas es el Research Transparency and Reproducibility Training (RT2), el cual constituye uno de los principales eventos académicos realizados anualmente por BITSS, teniendo por objetivo el poner a disposición de estudiantes e investigadores una mirada general de las herramientas y prácticas actuales para la transparencia y la reproducibilidad en la investigación empírica en ciencias sociales. Los contenidos de RT2 abordan una serie de tópicos de manera transversal que pueden ilustrados en seis puntos:

* **Amenazas** para la credibilidad en la ciencia y la reproducibilidad, junto con su relación con el _ethos_ científico: Conducta y valores en la ciencia.
* **Mejoras** en las especificaciones de los diseños de investigación: pre-registros y plan de pre-analysis en investigación con datos experimentales y observacionales.
* **Ética e investigación abierta**: estándares éticos para la ciencia abierta, manejo de datos y autoría de fuentes de información abiertas (citación).
* **Herramientas y métodos** para la investigación reproducible y colaboración: control de versiones y reportes dinámicos.
* **Sistematización de evidencia**, reproducibilidad e interpretación: métodos para investigación meta-analítica y revisiones sistemáticas, transparencia y reproducibilidad usando datos administrativos; y  replicabilidad en la investigación.
* **Software** para la Ciencia Abierta e innovaciones metodológicas.

**MOOC: Transparent and Open Social Science Research**

Otra de las contribuciones es el Transparent and Open Social Science Research corresponde a un curso gratuito online de cinco semanas el cual aborda los fundamentos conceptuales y las principales herramientas para promover una ciencia social abierta y transparente. La Tabla \@ref(tab:mooc) muestra el contenido de las sesiones, las cuales se basan en un curso de nivel de grado dictado por el director de BITSS Ted Miguel en la Universidad de California Berkeley.

| Semana | Contenido                                                                                                                                     |
|--------|-----------------------------------------------------------------------------------------------------------------------------------------------|
| 1      | [Introducción a la transparencia y reproducibilidad de la investigación](http://bitss.org/week-1/)                                            |
| 2      | [Sesgo de publicación](http://www.bitss.org/week-2-publication-bias/)                                                                         |
| 3      | [Pre-registro, Plan de Pre-Análisis; y Meta-análisis](http://www.bitss.org/week-3-pre-registration-pre-analysis-plans-and-meta-analysis/)     |
| 4      | [Replicación y Datos Abiertos](http://www.bitss.org/week-4-replication-and-open-data/)                                                        |
| 5      | [Visualización de Datos transparente y Viendo hacia adelante](http://www.bitss.org/week-5-transparent-data-visualization-and-looking-forward) |
Table: `r as.character(paste("(\\#tab:mooc)", "Cursos por semana en el MOOC de BITSS"))`

Una de las principales características de este curso introductorio es la sistematización de aspectos claves para la ciencia abierta con un foco particular en las ciencias sociales. Adicionalmente, tiene el objetivo de introducir conceptualmente a los problemas que se han visto presentes en las ciencias y busca dar respuestas prácticas a través de herramientas y métodos concretos para solucionarlo. Finalmente, constituye un esfuerzo breve y preciso, dado que las sesiones semanales poseen una duración promedio de unos treinta minutos y se encuentran dosificadas en videos de corta duración subtitulados.

En el ámbito de los Recursos que provee BITTS, podemos encontrar librería de recursos o simplemente la [_Resource Library_](https://www.bitss.org/resource-library/ ), la cual incluye una multiplicidad de recursos de aprendizaje digitales en torno a la transparencia y reproducibilidad, ordenados según (i) Tópico, (ii) Tipo y (iii) Disciplina de las ciencias sociales. La Figura \@ref(fig:resources) muestra cómo se visualizan los tópicos disponibles en la librería, lo cual puede ser ordenado según tipo y disciplina.


```{r resources, echo=FALSE, fig.cap="Librería de Recursos de BITSS", fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/resource-library.PNG")
```

### Proyecto TIER (Teaching Integrity in Empirical Research)

```{r, echo=FALSE, fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/tier-logo.jpg")
```

#### Objetivos y visión {-}

El proyecto TIER es una iniciativa respaldada por la [Fundación Alfred Sloan](https://sloan.org/) que se propone contribuir a un cambio en las normas y conducta profesionales en torno a la transparencia y reproducibilidad en la investigación empírica en las ciencias sociales.

Uno de los principios orientadores de sus actividades es el proveer formación en herramientas para la documentación oportuna de procedimientos que involucren datos estadísticos a través de rutinas y referencias que garanticen la **reproducibilidad** de estos. La idea subyacente que motiva estas acciones es que los autores puedan concebir la documentación como un componente esencial de la **comunicación** de sus resultados con sus pares, como también el público no especializado, de modo tal que estas medidas contribuyan a incrementar la confianza y credibilidad en la evidencia científica. En esta línea, su declaración de principios sostiene que su objetivo se puede considerar como logrado cuando:

> (...) no proporcionar documentación de replicación para un estudio empírico se considere tan **aberrante** como escribir un artículo teórico que no contenga pruebas de las proposiciones, un artículo experimental que no describa las condiciones de tratamiento o un artículo de revisión de leyes que no cite los estatutos legales o las decisiones judiciales. (traducción propia)

#### Contribución {-}

Es necesario tener presente que uno de los principales campos de acción del proyecto TIER es la **Educación** y **Entrenamiento**, hacia cientistas sociales en formación, tomando en consideración que es en el ciclo formativo inicial donde se deben impulsar la adopción de prácticas integrales para la investigación social empírica. En esta línea, uno de los elementos destacables es la sección de herramientas para la enseñanza titulada “TIER in the Classroom”, sus contenidos referidos a temas de **reproducibilidad** pueden resumir de la siguiente manera:

* [**_Soup-to-Nuts Exercises_**](https://www.projecttier.org/tier-classroom/soup-nuts-exercises/): No existe una traducción en el español, no obstante la expresión “Soup-to-Nuts” refiere a un proceso de “inicio-a-fin”. Como lo dice, esta sección muestra ejercicios orientados a la reproducibilidad de los análisis pasando por (1) los datos, (2) procesamiento, (3) análisis y (4) reporte. La idea fuerza de este ejercicio es introducir a estudiantes a los principios y prácticas fundamentales de la investigación social transparente y reproducible para que los implementen en sus tareas o informes.
* [**Materiales para clases**](https://www.projecttier.org/tier-classroom/course-materials/): Esta sección está fuertemente orientada al análisis estadístico y a los métodos cuantitativos. Se presentan una serie de veinticuatro cursos de pregrado y postgrado que incorporan en su currículum los principios de transparencia y reproducibilidad en la enseñanza de los métodos de manera transversal. Los materiales de cada curso se encuentran disponibles para libre descarga, incorporando ejercicios de análisis estadístico (R, Stata, SPSS), reportes dinámicos (R Markdown, Markstat) y sus respectivos _ syllabus_.

* [**Trabajos estudiantiles**](https://www.projecttier.org/tier-classroom/student-work/#student-papers): En este sección se incorporan una serie de trabajos estudiantiles/papers, los cuales están acompañados de una completa documentación basada en el [Protocolo TIER (ver detalle abajo)](https://www.projecttier.org/tier-protocol/). El objetivo es presentar modelos de trabajos realizados con análisis reproducibles, de modo tal que quien esté interesado en emplear la estructura de un proyecto pueda observar un trabajo real e, idealmente, logre reproducir completamente sus resultados.

Una de las contribuciones más relevantes del proyecto TIER es la elaboración de **estándares** para la **organización**, **publicación** y **comunicación** de proyectos de investigación empírica cuantitativa reproducible. Al respecto, existen dos esfuerzos orientados a este fin:

Por un lado tenemos el [Protocolo TIER](https://www.projecttier.org/tier-protocol/specifications-3-0/#overview-of-the-documentation), el cual constituye una serie de especificaciones respecto a los contenidos de la documentación para la replicación de un estudio, el cual está orientado a ser empleado para la enseñanza de la investigación que incorpore la reproducibilidad de los análisis. En este caso es importante precisar, como ya hemos identificado en un principio, que el concepto de **replicación** se emplea como sinónimo de **reproducibilidad**, entendiendo este último como la conjunción de datos y métodos originales que nos permitan **regenerar** los resultados de un estudio que ha sido publicado. Por lo tanto, cuando en TIER se habla de replicación se refiere a esta idea. La documentación debe incluir una serie de elementos descritos a continuación.

* Datos empleados por el proyecto
* Rutinas de código escrito en el software empleado para la preparación y análisis estadístico. Esto se incluye dado que el objetivo es proveer los datos brutos a procesar, junto con todas las instrucciones que permiten **regenerar** los resultados reportados en el estudio.
* Fuentes de información que contribuyan a comprender detalladamente cada sección del estudio de inicio a fin.

Por otro lado tenemos el [Protocolo DRESS](https://www.projecttier.org/tier-protocol/dress-protocol/) (Documenting Research in the Empirical Social Sciences). Al igual que el Protocolo TIER, se incorporan los mismos estándares para la documentación para una investigación transparente que incorpore la reproducibilidad de los análisis. Sin embargo, este se encuentra adaptado a los propósitos de los **investigadores profesionales**, más que para el uso de los estudiantes durante su formación en investigación.

### UK Reproducibility Network (UKRN)

```{r, echo=FALSE, fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path ="docs/images/UKRN-Logo.png")
```

#### Objetivos y visión {-}

La UK Reproducibility Network (UKRN) es un consorcio institucional del Reino Unido que tiene por objetivo promover los principios y prácticas de la ciencia abierta con una mirada local, es decir, en las instituciones nacionales y sus investigadores. Para contribuir a este objetivo se realizan esfuerzos en torno a la investigación de los factores que determinan una investigación abierta y robusta, promoviendo el entrenamiento a través de actividades abiertas y diseminando las buenas prácticas para una ciencia abierta. En particular, se proponen a profundizar en los factores que determinan la carencia de **reproducibilidad** y **replicabilidad**, para lo cual se busca:

* Desarrollar aproximaciones que contrarresten esta falta de transparencia.
* Incrementar la confianza y la calidad de la investigación científica.
* Abordar de manera transversal estos problemas en las distintas disciplinas científicas.
* Avanzar hacia un cambio cultural en la ciencia y transformar las prácticas de quienes la desarrollan.

En la UKRN se caracteriza por un trabajo en red, es decir por un importante componente de vinculación entre instituciones de investigación vinculadas a universidades como también a oficinas gubernamentales que desarrollan investigación (ver [External Stakeholders](https://www.ukrn.org/stakeholders/))    . En esta línea, existen diversas iniciativas apoyadas por la UKRN que promueven el entrenamiento, metodologías y recursos tecnológicos para la ciencia abierta. A continuación se presentarán algunas de las contribuciones más relevantes realizadas por la red, como también algunas de las iniciativas externas que han sido respaldadas por la UKRN.

#### Contribución {-}

En el ámbito de la **Educación** y **Entrenamiento**, es posible identificar, por un lado, las contribuciones realizadas directamente por la UKRN, y por otro lado, las iniciativas que son respaldadas por la red y que promueven la formación en torno a los principios y prácticas de la ciencia abierta, particularmente en la etapa temprana de la carrera de investigación.

Respecto a una de las iniciativas elaboradas por los académicos e investigadores involucrados en la UKRN, encontramos unos de los principales recursos virtuales en un breve curso online que aborda una serie de tópicos relevantes para la promoción de la ciencia abierta, dentro de lo cual encontramos el uso de pre-prints, autorías, registered reports, datos abiertos y reproducibilidad. A continuación se puede observar la lista de sesiones que han sido desarrolladas en torno a estos temas.

<iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLehgGZrvxReSisRauEJ2DxPAIYVVEr1qC" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
Junto con las sesiones, existe una serie de recursos compartidos a través de un proyecto abierto en el [Open Science Framework](https://osf.io/x8j9q/). Aquí es posible acceder a documentos breves que abordan los tópicos de cada sesión, además de [recursos adicionales](https://osf.io/qw9ck/) sobre uso de software de código abierto y repositorios.

Un ámbito de desarrollo ha sido la disposición de **recursos tecnológicos** que promuevan y faciliten las prácticas en ciencia abierta. Una de las iniciativas impulsadas es el [**Open Research Calendar**](https://openresearchcalendar.org/), el cual consiste en una instrumento colaborativo y abierto que busca brindar a la comunidad de investigadores interesados en temas relacionados a la ciencia abierta un flujo constante de actualizaciones en torno a workshops y conferencias a nivel mundial que abordan tópicos sobre ciencia abierta unificados en un calendario. El carácter **colaborativo** de esta herramienta permite que usuarios previamente registrados y validados puedan contribuir con información que se centraliza en el calendario de eventos, precisando los contenidos y redireccionando a la inscripción y/o enlace para las actividades que se realizan a través de internet. Para facilitar la experiencia de usuario, el calendario se integra con Google Calendar el cual puede sincronizarse con la agenda personal, los cuales se van actualizando automáticamente.

Otra herramienta tecnológica patrocinada por la UKRN es la plataforma [Octopus](https://science-octopus.org/). A la fecha, la plataforma se presenta como una aplicación en desarrollo y abierta a comentarios de los usuarios. En términos generales se propone ser una alternativa para contribuir a la apertura de publicaciones. El detalle se presenta así:

> (...) sustituir a las revistas y los artículos como lugar para establecer la prioridad y registrar su trabajo con todo detalle, Octopus es de uso gratuito y publica todo tipo de trabajos científicos, ya sea una hipótesis, un método, datos, un análisis o una revisión por pares (traducción propia).

La Figura \@ref(fig:octopus) ilustra un ejemplo de cómo se ve un proyecto en Octopus. Vemos que existen siete componentes que buscan representar el flujo de una investigación. Entendiendo que los procesos de investigación no son lineales y tienden a existir iteraciones en entre teoría y métodos, la virtud de la registro y publicación de un proyecto permite que otros puedan conocer y evaluar nuestras hipótesis, plan de análisis, resultados y versiones de un artículo, así como también la vinculación entre cada sección.

```{r octopus, echo=FALSE, fig.cap="Ejemplo de un trabajo registrado en desarrollo en octopus.org", fig.align = 'center', out.width = '75%'}
knitr::include_graphics(path = "docs/images/octopus.PNG")
```
Para publicar debemos [logearnos](https://science-octopus.org/publish) con una cuenta de ORCID. Si no tienes una cuenta puedes crear un perfil  [aquí](https://orcid.org/). Luego, se deben seguir tres pasos. El primero es elegir qué tipo de componente se desea publicar (Problema, Hipótesis, Métodos, etc). Segundo, dar detalles sobre el componente y con qué otros proyectos se relaciona. Y finalmente, contribuir con un borrador de escritura que luego será publicado.



## Herramientas para los análisis reproducibles

```{r include=FALSE}
if (!require("pacman")) install.packages("pacman") # instalar pacman
pacman::p_load(dplyr,       # Manipulacion de datos 
               sjmisc,      # descriptivos y frecuencias
               sjPlot,      # tablas, plots y descriptivos
               summarytools,# resumen de dataframe
               texreg,      # tablas de regresion
               knitr,       # tablas kable
               kableExtra,  # tablas kable personalizadas
               ggplot2,     # plots
               corrplot,    # matrices correlaciones
               webshot     # tomar screenshot de html
               )

load("input/data/proc/datos_proc.RData") # Cargar la base de datos directo desde dataverse
```

### Introducción

Por un lado tenemos todos los materiales que nos facilitan la reproducibilidad en términos computacionales, no obstante, la mera existencia de estos elementos no nos garantiza que un proyecto sea reproducible _per se_, dado que es importante tener en consideración _cómo_ se relacionan entre sí, para *regenerar* los resultados de un trabajo publicado. 

**Propósitos:**

* Primero, introducir un flujo de trabajo para los análisis reproducibles a través de un ejemplo práctico. 

* Segundo, ofrecer una guía de buenas prácticas referentes estándares de documentación de “inicio-a-fin” para una publicación en ciencias sociales (inspirado en [_Soup-to-Nuts_](https://www.projecttier.org/tier-classroom/soup-nuts-exercises/#shorter-exercises-for-teaching-transparency-and-reproducibility) de TIER).


**Principios:**

(i): _Reproducibilidad_: La documentación debe permitir regenerar completamente los resultados del estudio original. En primer lugar, se debe comenzar con los datos originales  brutos idénticos a aquellos con los que el autor comenzó la investigación, Luego, la posibilidad de realizar las mismas rutinas de código para preparar los datos finales para el análisis. Finalmente, se debe disponer de las rutinas de código que permitan regenerar los mismos resultados publicados, por ejemplo, las tablas o figuras presentes en la investigación.

(ii) _Independencia_: Toda la información necesaria para regenerar los resultados del estudio debe estar presente en la documentación. Esto refiere a que no debe ser necesario solicitar ninguna información adicional al autor. 

(iii) _Realismo_: La documentación debe estar organizada y presentada con suficiente claridad para que bajo un criterio realista, sea factible que un investigador independiente con un nivel de expertise razonable tenga la posibilidad de regenerar completa e independientemente los resultados del estudio sin mayores dificultades.

### Estructura de carpetas y documentación

El esquema de trabajo se basa en la estructura de proyectos del Protocolo [IPO](). Adicionalmente, se tomarán en consideración los estándares propuestos por el Protocolo [DRESS](), principalmente en lo que refiere a la documentación de cada uno de los componentes del proyecto. Para ello, trabajaremos en base a tres secciones:

I. Input
II. Procesamiento
III. Output


#### Software

Siguiendo los principios orientadores para una ciencia abierta, el uso de software de código abierto es una dimensión que contribuye a la apertura de un proyecto de investigación, dado que no requiere la adquisición de un software de pago. Por este motivo, la propuesta de trabajo se realizará utilizando el paquete estadístico R.

### Secciones de un proyecto

Debe ser pensado como un proyecto autocontenido, con una estructura de carpetas jerárquicas con archivos para cada función. 


####  Nivel principal

_Contenido_

El nivel principal corresponde al nivel base donde se encuentra toda la documentación de referencia general para el proyecto. Primero, el objetivo de documentar este nivel es exponer ordenadamente el contenido del proyecto completo de manera jerárquica, es decir, el contenido de subcarpetas y su función. Segundo, se proveen orientaciones para conducir a una correcta ejecución de las rutinas que permitan regenerar los resultados de la investigación. Los contenidos principales son:

1. Detalle del nivel principal y las subcarpetas organizadas según su contenido. Una manera amigable de representar esta estructura es a través de un “árbol de directorios”, el cual ilustra la jerarquía de las carpetas y los principales archivos contenidos. 


```
repro-lisa/
│
│   readme.md 
│   paper.Rmd 
│
├───input: (archivos de datos y utilidades)
│   │
│   ├───bib (subcarpeta  de input con documentos de bibliografía)
│   │
│   ├───data (subcarpeta de input con datos originales y procesados, junto con documentación)
│   │   ├───original (datos originales del estudio)
│   │   │   │   
│   │   │   └───documentacion (documentación de datos originales)
│   │   │
│   │   └───proc
│   │       │   
│   │       └───documentacion (documentación de datos procesados)
│   │
│   ├───images (subcarpeta de input con imágenes externas)
│   │
│   └───prereg (subcarpeta de input con documentación para preregistro)
│
├───procesamiento: (rutinas de código de preparación y análisis de datos)
│
└───output: (resultados de análisis en figuras y tablas)  
    ├───imagenes (subcarpeta de output para guardar figuras)
    │
    └───tablas (subcarpeta de output para guardar tablas)
```



> Tip: Cómog enerar un directory tree automatizado en [Windows](t.ly/c58k),[linux](t.ly/WlMC) y [MacOS](t.ly/ZCXK)

2. Instrucciones para la configuración (setup) del paquete estadístico necesario para ejecutar las rutinas de código. Esto considera el número de versión del software, los complementos necesarios que sean adicionales al paquete estándar y cualquier otra información especial sobre el software que el lector necesite conocer para reproducir los resultados del estudio. 

3. Instrucciones de “inicio-a-fin” para regenerar los resultados a través de referencias directas al uso de los archivos de procesamiento de datos en la preparación y análisis. En este apartado se incluye el detalle de los objetivos de cada rutina de código de manera independiente.



_Presentación_

Los contenidos descritos se deben incluir en un archivo que lleve de nombre “readme.md/txt/pdf”. Una sugerencia de estructura interna de este documento es la siguiente:

1. Estructura y contenido del proyecto reproducible
    * Esquema tipo “Árbol de directorios”
    * Descripción de cada subcarpeta, sus archivo y roles
2. Instrucciones y rutinas de ejecución de resultados
    * Instrucciones para configuración del software
    * Instrucciones para la ejecución de rutinas de código de “inicio-a-fin”.
  
  
#### I. Input

##### a) Explicación de Input 

La carpeta de input tiene la función de albergar todos los archivos necesarios para la elaboración del procesamiento y el análisis de los datos. El protocolo IPO propone cuatro subcarpetas: _data_ para los datos originales, _bib_ para los archivos de citado, _imageness_ para las imagenes que se vayan a incluir en el documento de preparación o el paper y _prereg_ donde se albergan todos los archivos necesarios para documentar un pre registro.

Separar los archivos en distintas carpetas permite, por una parte, ordenar mejor el flujo de trabajo ya que sabemos con certeza dónde está cada archivo y no tenemos que navegar en las carpetas para encontrarlo y, por otra parte, hace más reproducible el trabajo para terceros al facilitar la documentación del flujo.

##### b) Documentación de Input 

La descripción de los contenidos de la subcarpeta Input deben estar adecuadamente identificados y documentados. Como se ha indicado, existen cuatro subcarpetas que incluyen datos, bibliografía, imágenes y documentación de pre-registro. A continuación se mostrarán una serie de sugerencias de documentación de los archivos y subcarpetas de Input.

##### Datos (input/data)

###### Datos originales (input/data/original). 

Para toda fuente de datos original, se debe proveer la siguiente información:


a. Citación bibliográfica en un formato estándar (p. ej. American Psychological Association, Chicago, etc). Sugerimos revisar el componente de [“Datos Abiertos”](https://lisa-coes.netlify.app/02componentes/ ) para la publicación de datos. 
b. La fecha de creación de la base de datos o el día en que se accedió por primera vez por parte del autor.

c. Una descripción respecto a cómo se puede acceder a una copia de esta base de datos. Se debe ser lo suficientemente claro como para que un usuario independiente pueda acceder a los datos sin requerir información adicional.

d. Un libro de códigos de todas las variables de la base de datos. Sugerimos revisar el apartado [“¿Cómo hacer un libro de códigos?”](https://lisa-coes.netlify.app/como-hacer-codebook/).  


###### Datos procesados (input/data/proc).


Para toda fuente de datos procesada, es posible identificar dos tipos:

* Base de datos intermedia, la cual contiene información que, por un lado, puede ser complementaria con una base de datos principal. Por ejemplo, tenemos una base de datos con información de individuos pertenecientes a zonas/territorios (regiones o países), a la cual necesitamos incorporar información adicional que proviene de fuentes externas. En este caso, podemos generar una base procesada intermedia, para luego proceder a combinar ambas fuentes de datos.
* Base de datos final, es una versión final de una base de datos que contiene las variables completamente procesadas para realizar los análisis.

En estos casos se sugiere proveer la siguiente información:


a. Libro de códigos de la base procesada. Para ello, las variables deben estar correctamente etiquetadas.
b. Fecha de creación y versión de la base de datos procesada.


##### Referencias bibliográficas (input/bib)

Para toda fuente de referencia bibliográfica, se sugiere incorporar un archivo único en formato BibTeX (.bib) creado a través de algún gestor de referencias (p. ej. Zotero) el cual incluya todas las referencias empleadas en la publicación. Para la presentación del archivo se sugiere emplear un nombre breve, como por ejemplo “referencias.bib”. Además, se sugiere incorporar un archivo único en formato _Citation Style Language_ (.csl). Este archivo es un insumo básico para la citación en formato reproducible, ya que entrega el estilo de citado al documento. Generalmente se utilizan estilos de la _American Psychological Association_ o la _American Sociological Association_, sin embargo existen más de 10.000 estilos distintos. En el siguiente repositorio se pueden descargar los archivos .csl de distintos tipos de estilos: https://www.zotero.org/styles.

En el caso de no usar un gestor de referencias, simplemente se puede omitir esta sección. 

##### Imágenes (input/images)

Para las imágenes o figuras empleadas en la publicación, sugerimos emplear formatos o extensiones estándar como Joint Photographic Experts Group (JPEG) o Portable Graphics Format (PNG). En el caso de usar imágenes o fotografías con copyright, se debe referenciar correctamente o administrar permisos de uso de este material visual.

En el caso de no emplear imágenes externas, simplemente se puede omitir esta sección.

##### Preregistro (input/prereg)

Para toda la documentación que refiere al pre-registro de un estudio, se sugiere emplear una plantilla preestablecida para dicho propósito (ver Preregistros [LINK]). Para la presentación de la documentación referida al pre-registro se sugiere emplear un documento que lleve de nombre “preregistro.pdf”. 

En el caso de no haber pre-registrado el estudio, simplemente se puede omitir esta sección.


**Resumen de presentación**

```
├───input: 
│   │   readme-input.md 
│   │
│   ├───bib 
│   │       referencias.bib
│   │       apa6.csl
│   │
│   ├───data 
│   │   ├───original 
│   │   │   │   ELSOC_W01_v4.01_R.RData
│   │   │   └───documentacion 
│   │   │                   codebook_W01_S2016_ESP.pdf
│   │   │                   Questionnaire_W01_S2016_ESP.pdf
│   │   │                   User_Manual_ELSOC_Wave_01.pdf        
│   │   │
│   │   └───proc
│   │       │   datos_proc.RData
│   │       └───documentacion 
│   │                       codebook_datos_proc.pdf
│   │
│   ├───images 
│   │       logo-elsoc.png
│   │
│   └───prereg 
│           preregistro.Rmd 
│           preregistro.pdf 
```



#### II. Procesamiento

##### a) Explicación de Procesamiento 

En la sección de procesamiento, se espera albergar al menos dos documentos, uno que contenga el procesamiento de los datos y otro documento de análisis de datos. La principal razón para separar ambas actividades en documentos distintos es hacer más clara la lectura del código para la reproducibilidad. Esto quiere decir que, cualquier tercero que vaya a leer el código pueda comprender cómo se llegó a los resultados de forma paulatina, evitando a toda costa que, por ejemplo, en la mitad de la revisión del código emerja una pregunta tipo _¿y de dónde salió esta variable?_ En esta sección propondremos un flujo de trabajo para la generación de ambos documentos, así cómo también dejaremos planteadas algunas buenas prácticas para hacer estos documentos reproducibles.


###### Documento de procesamiento de los datos {-}

Esta sección cumple una función muy importante para el desarrollo de un artículo: la de procesar los datos que darán paso a los análisis del estudio. Considerando eso, el objetivo final de este documento es generar una **base de datos procesada**, que contenga solamente los datos importantes para analizar. El flujo que proponemos consta de dos partes, una de aspectos generales y otra sobre los procedimientos a realizar por cada variable:

###### Flujo para el documento de procesamiento de datos {-}

**Aspectos generales:**
**Cargar los paquetes estadísticos: el primer paso para comenzar un procesamiento de datos es instalar y activar los paquetes estadísticos que vamos a utilizar. Generalmente, los paquetes que necesitamos para el procesamiento de datos están contenidos en la colección de `tidyverse` (más información en https://www.tidyverse.org/). Recomendamos comentar cada paquete instalado con una frase corta que represente las principales funciones del paquete, con tal de que cualquier persona que quiera reproducir el código entienda por qué se está instalando este paquete sin tener la necesidad de acudir al manual.

Existe un paquete llamado `pacman`, el cual tiene la función de administrar los paquetes instalados. Recomendamos utilizar este paquete debido a su función `p_load`, la cual permite juntar tanto la instalación cómo la activación de distintos paquetes en una sola línea de código. Específicamente, esta función discrimina sí los paquetes están instalados o no, en el caso de no estarlo, los instala y sí ya están instalados, los activa. Un ejemplo a continuación:

```{r, eval=FALSE}
# Instalar paquetes usando R base
install.packages(“tidyverse”) # Instala el paquete
library(tidyverse)                   # Activa el paquete

# Instalar paquetes usando libreria “pacman” 
pacman::p_load(tidyverse, # Paquetes para el procesamiento de datos
               ggplot2    # Gráficos
              )
```
Cómo `pacman` también es un paquete, para poder utilizar sus funciones debemos instalarlo. Si bien podemos instalarlo de la forma clásica, recomendamos el siguiente código basado en un argumento condicional, donde si no está instalado le solicitamos a R que lo instale, y sí ya estaba instalado, que no haga nada. Ejemplo:

```{r, eval=FALSE}
# Instalar pacman a partir de un argumento condicional
if (!require("pacman")) install.packages("pacman")  #Si falta pacman, instalar
```

**Cargar la base de datos original:** Cargar la base de datos original es el punto de partida para el procesamiento de los datos, y cómo tal, es muy importante que esta acción sea reproducible. Cargar la base de datos original de forma que no se pueda reproducir abre la posibilidad de que todo el código que elaboremos a posterior sea inutilizable. De manera breve, dejamos estipulado cuál sería una forma no reproducible de cargar la base de datos, y una forma que sí es reproducible. 

Cargar la base de datos de forma no reproducible consiste en cargar la base de datos incluyendo la ruta completa hacia el archivo, esto quiere decir que, tenemos que especificar la ruta desde el disco duro que estamos trabajando hasta el archivo de la base de datos. Esta manera no es reproducible ya que solo aplica para el computador personal de quien está trabajando. Ejemplo:

```{r, eval=FALSE}
# Cargar base de datos forma no reproducible:

load("C:/Usuario/Documentos/repro-lisa/input/data/original/ELSOC_W01_v4.01_R.RData")

# Nota: Con “root” nos referimos a la carpeta raíz del proyecto, por lo que el nombre puede cambiar dependiendo del proyecto.
```

En cambio, la forma reproducible consiste en utilizar las direcciones basándonos en una carpeta raíz (forma 1) o cargarla directamente desde la web (forma 2). Primero, para poder establecer una carpeta raíz tenemos dos opciones; una opción es establecer manualmente un directorio de trabajo. Un directorio de trabajo es una ruta en la cual R asume que están los archivos que nos interesa trabajar, por lo que no es necesario especificar la ruta completa cada vez que necesitemos cargar un archivo. Para conocer cuál es el directorio de trabajo en el que está fijado R podemos utilizar el comando `getwd()`. Si queremos cambiar este directorio utilizamos el comando `setwd(“ruta hacia el archivo”)`. Para que esta opción sea reproducible, es importante **documentar** y explicar el proceso de establecer un directorio de trabajo. Una segunda opción para trabajar con una carpeta raíz es a través de  un documento .Rproj, estos son una forma reproducible de establecer una dirección de trabajo a través de RStudio. Es un archivo que solo tiene la finalidad de indicarle a R que la carpeta asociada al .Rproj es la carpeta raíz, por lo que todos los archivos estarán comprendidos dentro (o en subcarpetas). Este archivo es transferible, por lo que sí un tercero lo abre en su computador, no tendrá problemas en cargar la base de datos ya que R asumirá que la carpeta raíz es la asociada al .rproj. En el caso de trabajar con RStudio, recomendamos el uso de documentos .rproj.

La segunda forma de cargar la base de datos de forma reproducible es directamente desde la web, al hacer esto nos ahorramos el tener que descargar los datos. Sin embargo, es importante especificar que, en caso de cargar los datos directamente desde la web, estos deben estar albergados en un repositorio estable en el tiempo, ya que en caso de dejar de funcionar el URL el código deja de ser reproducible. También, es importante agregar que el link que utilicemos debe ser uno que lleve directamente a la descarga del archivo. En este caso, se están cargando los datos de ELSOC desde el repositorio Harvard Dataverse. A continuación, un ejemplo del código de ambas formas reproducibles utilizando ELSOC:

```{r, eval=FALSE}
# Cargar base de datos forma reproducible 1

getwd() # Para conocer cuál es el directorio de trabajo actualmente fijado

setwd("C:/Usuario/Documentos/root") # Para fijar un nuevo directorio de trabajo. Acá lo fijamos en la carpeta raíz del proyecto.

# Si se utiliza un documento .rproj se pueden omitir los pasos relacionados a establecer un directorio de trabajo

load("repro-lisa/input/data/original/ELSOC_W01_v4.01_R.RData") # Cargar la base de datos mientras estamos trabajando sobre un archivo .Rproj

# Cargar base de datos forma reproducible 2

load(url("https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/0KIRBJ/DWXZL1")) # Cargar la base de datos directo desde dataverse
```

**Revisar la base de datos:** Una vez cargada la base de datos original, recomendamos siempre revisar para que todo esté en orden. Esto lo podemos hacer con el comando `View()`, poniendo entre las comillas el nombre del objeto que le hemos dado a la base de datos. Cuando decimos “ver que todo esté en orden” nos referimos a diagnosticar si la base ha sido correctamente cargada. Por ejemplo, a veces podría suceder que la base de datos está en formato .csv con las columnas separadas por punto y coma (“;”), por lo que sí no lo especificamos en el código, tendríamos una base de datos con toda la información colapsada en una sola columna.

**Seleccionar las variables que se utilizarán:** Generalmente no ocupamos todas las variables dentro de una base de datos, en especial en la investigación basada en encuestas con datos secundarios. Es por eso que el comienzo del procesamiento de datos consta de seleccionar las variables que utilizaremos para los análisis. Aquí utilizamos el comando `select()` del paquete `dplyr`, tal y cómo se ve a continuación:

``` {r, eval=FALSE}
# Cargamos nuestra base de datos

load("input/data/original/ELSOC_W01_v4.01_R.RData") # Cargar la base de datos desde dirección local

# Revisamos que todo esté en orden

names(elsoc_2016l)
View(elsoc_2016l)

# Seleccionamos las variables

elsoc_proc<- 
  elsoc_2016 %>%
  dplyr::select(
    idencuesta, #identificador individual
    m0_sexo, #sexo
    m0_edad, #edad
    m01, #nivel de educación
    m13, # ingresos
    d01_01 #estatus social subjetivo
)
```

Del ejemplo destacamos dos buenas prácticas en lo que respecta a reproducibilidad. La primera es especificar que queremos llamar la función `select()` del paquete `dplyr` a través de los dos puntos `::`. Esto es especialmente útil cuando distintos paquetes comparten los nombres de las funciones. La segunda práctica se relaciona a separar cada variable seleccionada con un espacio, con tal de que cada variable sea una línea. Dentro de cada línea, comentar el nombre sustantivo de la variable. Por ejemplo, especificar que `d01_01` corresponde al estatus social subjetivo. 

**Renombrar las variables:** Si bien no es estrictamente necesario renombrar las variables, sí se recomienda para facilitar tanto el propio trabajo cómo el de alguien que vaya a emplear el mismo código. Generalmente, en la investigación de encuestas con datos secundarios nos encontramos con grandes bases de datos, con nombres técnicos y poco autoexplicativos. La principal recomendación aquí es cambiar estos nombres por nombres **cortos** y **autoexplicativos**. Por ejemplo, cambiar `d01_01` por `ess`, aludiendo a que es un indicador sobre estatus social subjetivo. Un ejemplo de renombrar se ve a continuación:

``` {r, eval=FALSE}

# Renombramos las variables

elsoc_proc <- 
  elsoc_proc %>%
  dplyr::rename(
    id = idencuesta, #identificador individual
    sexo = m0_sexo, #sexo
    edad = m0_edad, #edad
    educ = m01, #nivel de educación
    ingresos = m13, #ingresos
    ess = d01_01 #estatus social subjetivo
)
```

El proceso de renombrar variables también se puede hacer en conjunto al de seleccionar variables, sin embargo acá lo presentamos de forma separada para ser más esquemáticos.

**Procedimientos a realizar por cada variable:**

Una vez hemos cumplido con los aspectos generales del procesamiento, podemos pasar a la revisión de variable a variable. Aquí proponemos el siguiente flujo:

* Descriptivo incial: calcular una tabla de frecuencias o de medidas de tendencia central y dispersión para conocer el estado de la variable previo a cualquier modificación. 

*Recodificación: aquí se toman las decisiones respecto a la recodificación de los datos perdidos y otro tipo de valores a modificar  (e.g. errores de tipeo). Es importante que las decisiones sobre la recodificación queden bien estipuladas y transparentadas. Por ejemplo, en caso de hacer imputación en alguna variable, dejarlo comentado en el código.

* Etiquetado: el etiquetado es una forma simple y eficiente de poder dar más información acerca de una variable. En el caso de R, generalmente se usa el paquete `sjlabelled` para etiquetar tanto una variable (una columna de la base de datos) cómo una categoría de respuesta de la variable. En el caso de bases de datos sobre encuestas, generalmente una base bien documentada trae etiquetas predeterminadas que hacen alusión a las preguntas del cuestionario.

* Descriptivo final: recomendamos que, posterior a haber hecho las recodificaciones correspondientes, revisar de nuevo las frecuencias o las medidas de tendencia central de las variables, para diagnosticar que no hemos cometido errores en el procesamiento. Un ejemplo común, es que etiquetemos de forma errónea cada categoría de la variable. Esto tendría un impacto directo en la interpretación de los datos.

* Otros ajustes: en esta última parte del flujo por variable, recomendamos efectuar toda modificación específica y relevante para la forma que analizaremos los datos. Por ejemplo, si fuésemos a construir un índice con algunas de las variables.

Para esta sección de flujo de trabajo, también sugerimos, a modo de práctica de orden, que todo título y subtítulo estén especificados y jerarquizados. En detalle, proponemos que por cada título correspondiente a la variable a recodificar, cada aspecto del flujo sea un subtítulo, algo cómo:

- Título: Estatus social subjetivo
    - Subtítulo 1: Descriptivo inicial
    - Subtítulo 2: Recodificación
    - Subtítulo 3: Etiquetado
    - Subtítulo 4: Descriptivo final
    - Subtítulo 5: Otros ajustes
    
    
En R, esto lo podemos hacer de dos maneras. La primera es que, cuando trabajamos con scripts (.R) usar gato “#” para comentar, y cuatro guiones (“----”) entre el texto que queremos denominar cómo un título, ejemplo:

```{r, eval=FALSE}
# ---- 1. Estatus social subjetivo ----
# ---- 1.1 Descriptivo inicial----
# ---- 1.2 Recodificación ----
# ---- 1.3 Etiquetado ----
# ---- 1.4 Descriptivos final ----
# ---- 1.5 Otros ajustes ----
```
Al hacer esto, R irá ordenando los títulos de forma en la que vayan apareciendo en el script, como se ve en la Figura N° \@ref(fig:titulosscript).

```{r titulosscript, echo=FALSE, fig.cap="Ventana de script con el recuadro de títulos", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "docs/images/titulosscript.png")
```
    
La segunda forma de ordenar el flujo a través del trabajo con documentos dinámicos, específicamente R Markdown. R Markdown es un lenguaje que combina código en R y escritura en texto plano Markdown. Para ordenar los títulos del flujo, podríamos usar los gatos ("#") que denotan jerarquía de títulos en Markdown. Recomendamos usar los gatos "#" para subtitular las variables, y los pasos del flujo especificarlos con un comentario dentro del chunk. Ejemplo:


###### Sexo {-}

```{r}
# Descriptivo inicial
sjmisc::frq(elsoc_proc$sexo)

# Recodificación
elsoc_proc$sexo <- factor(elsoc_proc$sexo,labels = c('Hombre', 'Mujer'))

# Etiquetado
elsoc_proc$sexo <- sjlabelled::set_label(elsoc_proc$sexo, label = c("Tipo de sexo"))

# Descriptivo final
sjmisc::frq(elsoc_proc$sexo)

# Otros ajustes
# No aplica
```

En resumen, es una buena práctica contar con un orden óptimo para el documento de procesamiento de datos -y para cualquier documento en general-. En R, se puede lograr esto de dos formas. Cuando se trabaja con scripts (.R) se puede usar la nomenclatura "# ---- Título ----", y cuando se trabaja con documentos R Markdown (.Rmd) se pueden usar las jerarquías de títulos con los gatos ("#"). 

Para finalizar esta sección, en la Figura N° \@ref(fig:flujovar) esquematizamos el flujo propuesto.

```{r flujovar, echo=FALSE, fig.cap="Esquema de flujo de trabajo por cada variable", fig.align = 'center', out.width = '100%'}
# knitr::include_graphics(path = "docs/images/flujovar.png")
```


El último momento de la sección de procesamiento consiste en guardar la base de datos con los cambios realizados. En el caso de R, esto se reduce solamente a una línea de código, sin embargo, queremos aprovechar el momento para explicar una práctica muy importante para la reproducibilidad: **las rutas relativas**

Cómo hemos visto, el protocolo IPO busca proponer una estructura de carpetas simple, eficiente y reproducible para el procesamiento y el análisis de los datos. Este se basa en una carpeta raíz con tres subcarpetas: _input:_, _procesamiento_ y _output_, a lo cual, si le sumamos un documento .rproj, tenemos una estructura transferible entre computadores. Sin embargo, ¿qué ocurre cuándo necesitamos movernos entre carpetas para cargar archivos? Por ejemplo, si estamos trabajando en el documento de procesamiento y necesitamos insertar una imagen. Acá es donde entran en juego las rutas relativas, estas son una forma simple de moverse entre carpetas asumiendo una carpeta raíz. En la práctica, requiere solamente dos nociones:

* Si queremos avanzar entre carpetas, debemos usar _forward slashes_ (“/”) por cada subcarpeta que avancemos (e.g. input/data/archivo.R)
* Si queremos retroceder entre carpetas, debemos usar _forward slashes_ más dos puntos por cada nivel que retrocedamos (e.g. ../archivo.R)


Retomemos el ejemplo, si estamos trabajando en el documento de procesamiento (el cual se encuentra en la carpeta "procesamiento" y tenemos que cargar alguna imagen, podemos utilizar la siguiente ruta: "../input/images/imagen.png".

Estando en conocimiento del funcionamiento de las rutas relativas, el código para guardar la base de datos sería algo así:

```{r, eval=FALSE}
save(elsoc_proc,file = "../input/data/proc/datos_proc.Rdata")
```

###### Documento de análisis de datos {-}

Una vez contamos con nuestra base de datos procesada, es hora de la acción. En la sección del análisis de datos se procede a elaborar todas las tablas, gráficos, pruebas estadísticas etc. que vayan a ser introducidos en el artículo final. Es importante que se piense en este documento cómo un reporte de análisis en sí mismo, es decir, debe estar dirigido al público y no solo ser un documento de trabajo interno para el equipo de investigación. 

Al igual que para la sección de procesamiento de datos, aquí también recomendamos un flujo de trabajo para hacer el código reproducible y eficiente. Dividimos el flujo en dos secciones, primero, una que contenga los análisis necesarios para probar las hipótesis de investigación. Segundo, una sección con análisis secundarios y/o exploratorios que sean relevantes para lo que el artículo busca plantear. Veremos esto con un poco más de detalle.

###### Flujo para el documento de procesamiento de datos {-}

**Análisis para el artículo**

En esta parte del flujo, se espera trabajar con las variables que forman parte de las hipótesis de investigación, efectuando dos importantes pasos. El primer paso consiste en la descripción de variables y el segundo en el contraste de hipótesis de las mismas.

** Paso 1: Descripción de las variables:** En concreto, en este paso efectuamos al menos dos actividades. Primero, comenzamos por elaborar la **tabla general de descriptivos** que suele introducirse en la sección de método en un reporte de investigación. Recomendamos introducir esta tabla para que el lector conozca en detalle cómo se distribuyen las variables importantes de la muestra. En R, existen muchos paquetes que permiten elaborar este tipo de tabla, de los cuales mencionaremos tres y uno de ellos será el que recomendamos.

La función `stargazer` del paquete con el mismo nombre permite mostrar las medidas de tendencia central y las medidas de dispersión de la base de datos que introducimos. El código y una demostración del output es el siguiente:

```{r}
stargazer::stargazer(elsoc_proc,type = "text")
```
La función `descr` de la librería `sjmisc` también muestra los descriptivos de una base de datos:

```{r}
sjmisc::descr(elsoc_proc$ess)
```
Una forma de crearla de forma más estética es especificar los estadísticos que queremos visualizar y combinar la función `descr` con la función `kable` de la librería del mismo nombre. Esto permite elaborar una tabla apta para formato HTML.
```{r}
sjmisc::descr(elsoc_proc$ess,
      show = c("label","range", "mean", "sd", "NA.prc", "n"))%>%
      kable(.,"markdown")
```

La última forma de elaborar una tabla de descriptivos general es utilizar la función `dfsummary` de la librería `summarytools`. En contraste a las otras dos tablas, esta tabla abarca no solo medidas de tendencia central o dispersión, sino que también frecuencias de variables categóricas. Dicho de otra forma, esta función discrimina si las variables que estamos introduciendo son cuantitativas o categóricas y muestra los estadísticos correspondientes. Además, entrega una pequeña visualización de los datos: un gráfico de barras si las variables son categóricas y un histograma sí son cuantitativas. El código es el siguiente:

```{r}
df<- summarytools::dfSummary(elsoc_proc,
               plain.ascii = FALSE,
               style = "grid",
               tmp.img.dir = "/tmp",
               graph.magnif = 0.75,
               headings = F,  # encabezado
               varnumbers = F, # num variable
               labels.col = T, # etiquetas
               na.col = F,    # missing
               graph.col = T, # plot
               valid.col = T, # n valido
               col.widths = c(5,10,10,10,10)
               )
df$Variable <- NULL        # Borrar variable column
view(df,method = "render") # Visualizar tabla
```

La segunda actividad que podemos hacer en este paso del análisis de datos es **explorar las relaciones entre variables**. Acá las tablas o gráficos que elaboremos dependen de la naturaleza de las variables, donde:

* Relación entre dos variables categóricas: tabla de contingencia
* Relación entre una variable categórica y una continua: tabla de promedios por cada categoría
* Relación entre dos variables continuas: correlaciones.

La función `sjt.xtab` de la librería `sjPlot` construye de forma eficiente y estética una tabla de contingencia entre las dos variables señaladas. Además, muestra el valor relativo a la prueba de Chi2 en caso de que sea importante efectuar una prueba de hipótesis entre las variables expuestas en la tabla. 

```{r}
sjt.xtab(elsoc_proc$educ, elsoc_proc$sexo)
```
Se le pueden agregar los porcentajes si se considera necesario haciendo la siguiente modificación al código:

```{r}
sjt.xtab(elsoc_proc$educ, elsoc_proc$sexo, show.col.prc = TRUE)
```
La función `plot_grpfrq` de la librería `sjPlot` es una forma simple de graficar la distribución de una variable cuantitativa por cada categoría de la variable categórica. En el siguiente código se muestra cómo elaborar un gráfico de cajas por categoría:

```{r}
sjPlot::plot_grpfrq(elsoc_proc$ess,elsoc_proc$educ,
            type = "box")
```

Por último, tenemos varias funciones para representar la relación entre dos variables cuantitativas (correlaciones). La función `sjt.corr()` de `sjPlot` es una forma eficiente y estética de presentar una tabla de correlaciones:

```{r, eval = FALSE}
sjt.corr(elsoc_proc)
```
Además, podemos representar una correlación a través de matrices de correlación con la función `corrplot.mixed()` de la librería `corrplot`, agregando un paso previo que es crear un objeto que contenga las correlaciones a graficar. Esta matriz contribuye a gráficar de forma más digerible la información al introducir colores y formas. Color rojo significa correlaciones negativas y color azul correlaciones positivas, a su vez, mientras más grande el círculo más grande el coeficiente de correlación.

```{r, eval = FALSE}
M <- cor(elsoc_proc) # Paso previo: crear un objeto que albergue las correlaciones con la función base de R “cor”.

corrplot.mixed(M) # Graficar una matriz de correlación
```
Por último, también se puede visualizar la correlación entre dos variables cuantitativas a través de nubes de puntos. La función `plot_scatter()` de `sjPlot` es una buena opción para efectuar esta tarea:

```{r}
plot_scatter(elsoc_proc, edad, sexo)
```

**Paso 2: Contraste de hipótesis:**

El segundo paso para el documento de análisis de datos es escribir el código que permitirá producir y reproducir las técnicas de análisis inferencial. 

**Análisis secundario y/o exploratorio**

Una vez concluidos los análisis que son necesarios para reportar en el artículo, podemos dedicar nuestro tiempo y esfuerzos en una sección secundaria o exploratoria. La existencia de esta sección depende de sí, efectivamente, es relevante para efectos de la investigación el efectuar algún análisis adicional. Un artículo eminentemente confirmatorio podría no necesitar una sección específica. Sin embargo, nuestro punto es que, para efectos de claridad y transparencia del proceso de investigación, es importante dejar por separado todo análisis que sea adicional al análisis principal. Además, esto permite ser más eficiente en la preparación del material suplementario en caso de que una revista lo requiera.

Recomendamos el mismo flujo que vimos para la sección de análisis principal: descriptivos y contrastes de hipótesis.

```{r produccion2, echo=FALSE, fig.cap="Flujo de trabajo para procesamiento y análisis de datos", fig.align = 'center', out.width = '100%'}
knitr::include_graphics(path = "images/produccion2.png")
```

###### Buenas prácticas {-}

Terminaremos esta sección de procesamiento listando algunas buenas prácticas necesarias para asegurar la reproducibilidad de ambos documentos descritos:

* Nunca hacer trabajo manual, siempre automatizar el proceso en código fácilmente leíble. Esto implica: evitar a toda costa el uso de softwares que no permitan la reproducibilidad (e.g. Microsoft Excel)

* Asegurarse que el código siempre produzca el mismo resultado. Un ejemplo es cuando por algún tipo de análisis se necesitan generar números aleatorios. En R, para poder reproducir la generación de esos números aleatorios se utiliza la función `set.seed()`.

* Trabajar con scripts. Para poder automatizar el procesamiento y análisis de los datos, la principal recomendación es trabajar con documentos “script” que albergan el código y permiten su rápida ejecución. En el caso de R, se pueden utilizar documentos .R.

* Escribir con minúscula, sin espacios, sin ñ y sin tildes. Dos razones para esto, primero es que R está construido en base al idioma inglés, por lo que el utilizar “ñ” o tildes puede generar errores en la reproducción del código. Segundo, R es _case sensitive_, lo que significa que reconoce si el código está escrito con mayúsculas o con minúsculas. Sin embargo, no todos los softwares cumplen con esta característica, por lo que a modo de recomendación general no se incluyen mayúsculas en partes importantes del código. Por ejemplo, que lo único que diferencia dos variables sea una mayúscula.

* Indentar el código. La indentación es una característica del trabajo con código en general (no solo a nivel de software estadístico) y se refiere a la jerarquía en los niveles del código. En R, la recomendación es que por cada jerarquía de código se añaden dos espacios. Indentar permite una lectura más fácil del código. Uno de los ejemplos más conocidos es la elaboración de funciones condicionales de tipo `if-else`.

* Comentar el código. Cómo señalamos a lo largo de la explicación, comentar el código es sustancial para que cualquier persona no asociada al proyecto (o incluso uno mismo en el futuro) pueda entender para qué sirve cada función y reproducir los documentos sin problemas.

* Especificar las versiones de paquetes. Los paquetes están mejorando día a día, es por eso que a veces un código elaborado bajo cierta versión podría no funcionar con versiones futuras (e.g. que cambie el nombre de una función para la elaboración de tablas). Para que esto no sea un problema, siempre se recomienda utilizar la función `sessionInfo()` la cual entrega toda la información de versiones, tanto del software cómo de los paquetes. La recomendación es poner el output de esta función cómo parte del script, con tal de que quien lee el código pueda saber en detalle con qué paquetes y qué versiones se construyó el código. Otra recomendación un tanto más avanzada es fijar las versiones de los paquetes utilizados en el script a través de paquetes especializados. Un ejemplo es `groundhog`: https://groundhogr.com/.

* Elaborar código autocontenido. El código autocontenido es quizás el ápice de la reproducibilidad en el código, ya que no solamente es el documento el que es reproducible en sí mismo, sino que cada bloque de código. Esto implica que cada bloque de código no depende de otro: por ejemplo, elaborar una tabla con la función `stargazer()` no depende de que hayamos cargado el paquete al principio del documento, sino que el comando para cargar el paquete está dentro del mismo bloque de código. Veremos esto con más detalle en el ejemplo reproducible.

* Nombrar variables: nombres sustantivos y cortos. Esto es una recomendación que dimos durante la explicación, pero es bueno recordarla. Para que el código sea lo más fácilmente trabajable, debemos renombrar correctamente las variables que estamos trabajando.

* Etiquetado o buen diccionario de variables. Además de renombrar las variables, recomendamos etiquetar de forma sustantiva las variables que se utilizarán y/o hacer un buen diccionario de ellas.

* Utilizar UTF8. Si bien el lenguaje nativo de R es el inglés, sí se está escribiendo en español estipular siempre que se pueda que el formato del código sea UTF-8. El formato UTF-8 acepta caracteres especiales del español (cómo tildes y “ñ”), lo cual es especialmente relevante que funcione cuando se visualizan tablas o gráficos.

* Documentos dinámicos. Los documentos dinámicos son textos que combinan tanto código cómo texto en formato plano. En el caso de R, esto se logra mediante los documentos R Markdown. Recomendamos utilizar este formato para el flujo de trabajo propuesto acá ya que más compatible con la reproducibilidad y la eficiencia en el trabajo con datos, en contraste al uso de scripts (.R)

* Trabajar con rutas relativas. Cómo vimos, las rutas relativas permiten cargar o guardar archivos en directorios específicos sin necesidad de estipular la dirección local del computador. Esto contribuye a la reproducibilidad.

* Usar StackOverflow. Stack Overflow es un foro donde programadores, ingenieros y en general cualquier que utiliza código en su día a día puede hacer o responder preguntas respecto a código. Es una gran herramienta para cuando los códigos no funcionan.

##### b) Documentación de Procesamiento 

Para una correcta comprensión de la subcarpeta de procesamiento, sus archivos y roles, es importante tener una descripción adecuada de cada una de sus partes. Al estar mayormente orientado a la programación de rutinas de código, los documentos de preparación y análisis debieran contener la mayor parte de la información para una correcta comprensión del procedimiento.

No obstante, es relevante precisar de qué manera estos documentos se vinculan con otros archivos dentro del proyecto. Por un lado, el documento de preparación requiere de una fuente de datos inicial, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos originales (`input/data/original`). Por otro lado, el documento de análisis requiere de una fuente de datos procesada, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos procesados (`input/data/proc`). Además, se debe tener en consideración que los productos del análisis, es decir, los resultados de la investigación, pueden ser reportados en forma de figuras o tablas, las cuales son almacenadas en la carpeta Output y en las subcarpetas imágenes y tablas, respectivamente.

Para una correcta ejecución de las rutinas de código, es importante describir adecuadamente la relación entre los archivos de preparación y análisis. Para ello, se sugiere incorporar un archivo de nombre “readme-proc.md/txt/pdf”, en donde se describa brevemente dicha vinculación. Para ello sugerimos los siguientes puntos a describir:

1. Para la ejecución de la preparación, precisar la ubicación de la o las fuentes de datos originales. (p.ej. “input/data/original/original-data.dta”)
2. Para el cierre de la preparación, precisar la ruta donde se deben almacenar la base de datos procesada y su extensión (p.ej. “input/data/original/proc-data.RData”)
3. Para la ejecución de los análisis se debe precisar el origen de la base procesada que fue creada en el punto 2.
. Para los archivos de resultados provenientes del análisis de los datos, tales como figuras o tablas, debemos precisar la ruta donde se almacenarán y su nombre. 

**Resumen de presentación** 

```
├───procesamiento: 
        readme-proc.md 
        proc_analisis.Rmd
        proc_preparacion.Rmd
```

#### III. Output

##### a) Explicación de Output 

En la sección de output se espera albergar toda tabla, figura o gráfico relevante producto del código de análisis de datos. Para esto, el protocolo IPO propone dos carpetas, una de imágenes y otra de tablas. La idea de esta carpeta es que podamos guardar toda figura que vaya a ser parte del documento final del artículo.

##### b) Documentación de Output 

Como se ha señalado anteriormente, tenemos dos tipos de archivos contenidos dentro de las subcarpetas de Output. Para una correcta identificación de cada uno de estos elementos sugerimos seguir las siguientes indicaciones:

a. Para las imágenes, sugerimos usar nombres breves e incorporar numeración. Por ejemplo “figura01.png”, según el orden de aparición en la publicación.
b. Para el caso de los cuadros o tablas, existen distintas extensiones para almacenarlas como archivos independientes (tex/txt/md/html/xls). Para ello, sugerimos emplear nombres cortos e incorporar numeración. Por ejemplo, “tabla01.xls”, según el orden de aparición en la publicación. 

**Resumen de presentación**

```
└───output:  
    ├───imagenes 
    │       figura01.png
    │       figura02.png
    │
    └───tablas 
            tabla01.xls
            tabla02.xls

```
